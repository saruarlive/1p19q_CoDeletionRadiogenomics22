{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3964998a",
   "metadata": {},
   "source": [
    "# MRI based brain tumor' 1p19q status classification with MONAI (3D multiparametric MRI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579385e5",
   "metadata": {},
   "source": [
    "This tutorial shows how to construct a training workflow of binary classification task.  \n",
    "And it contains below features:\n",
    "1. Transforms for Monai dictionary format data.\n",
    "2. Define a new transform according MONAI transform API.\n",
    "3. Load Nifti image with metadata, load a list of images and stack them.\n",
    "5. 3D Voxel DynUNet model, Dice loss, cross entropy loss function for IDH classification task.\n",
    "6. Deterministic training for reproducibility.\n",
    "\n",
    "The Brain tumor dataset can be downloaded from \n",
    "https://ipp.cbica.upenn.edu/ and  http://medicaldecathlon.com/.  \n",
    "\n",
    "Target: IDH classification based on whole brain, tumour core, whole tumor, and enhancing tumor from MRI \n",
    "Modality: Multimodal multisite MRI data (FLAIR, T1w, T1gd,T2w)  \n",
    "training: 368 3D MRI \\\n",
    "validation:  \\\n",
    "testing: Not revealed\n",
    "\n",
    "Source: BRATS 2020/2021 datasets.  \n",
    "Challenge: RSNA-MICCAI Brain Tumor Radiogenomic Classification\n",
    "\n",
    "Below figure shows image patches with the tumor sub-regions that are annotated in the different modalities (top left) and the final labels for the whole dataset (right). (Figure taken from the [BraTS IEEE TMI paper](https://ieeexplore.ieee.org/document/6975210/))  \n",
    "![image](https://ieeexplore.ieee.org/mediastore_new/IEEE/content/media/42/7283692/6975210/6975210-fig-3-source-large.gif)\n",
    "\n",
    "The image patches show from left to right:\n",
    "1. the whole tumor (yellow) visible in T2-FLAIR (Fig.A).\n",
    "2. the tumor core (red) visible in T2 (Fig.B).\n",
    "3. the enhancing tumor structures (light blue) visible in T1Gd, surrounding the cystic/necrotic components of the core (green) (Fig. C).\n",
    "4. The segmentations are used to generate the final labels of the tumor sub-regions (Fig.D): edema (yellow), non-enhancing solid core (red), necrotic/cystic core (green), enhancing core (blue)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35511034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 0.9.0\n",
      "Numpy version: 1.22.3\n",
      "Pytorch version: 1.10.1\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False\n",
      "MONAI rev id: af0e0e9f757558d144b655c63afcea3a4e0a06f5\n",
      "MONAI __file__: /home/mmiv-ml/anaconda3/envs/sa_tumorseg22/lib/python3.9/site-packages/monai/__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: 0.4.9\n",
      "Nibabel version: 4.0.1\n",
      "scikit-image version: 0.19.3\n",
      "Pillow version: 9.0.1\n",
      "Tensorboard version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "gdown version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "TorchVision version: 0.11.2\n",
      "tqdm version: 4.64.0\n",
      "lmdb version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "psutil version: 5.9.1\n",
      "pandas version: 1.4.2\n",
      "einops version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "transformers version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "mlflow version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "pynrrd version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Copyright 2020 MONAI Consortium\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "import sys\n",
    "import gc\n",
    "import logging\n",
    "import copy\n",
    "import pdb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from scipy import ndimage\n",
    "from sklearn.model_selection import KFold\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from monai.networks.nets import DynUNet, EfficientNetBN, DenseNet121, SegResNet, SegResNetVAE, AttentionUnet\n",
    "from monai.data import CacheDataset, Dataset, DataLoader, ThreadDataLoader, list_data_collate\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "import monai\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    AsDiscrete,\n",
    "    CastToTyped,\n",
    "    Compose, \n",
    "    CropForegroundd,\n",
    "    ResizeWithPadOrCrop,\n",
    "    ResizeWithPadOrCropd,\n",
    "    Spacingd,\n",
    "    RandRotate90d,\n",
    "    Resized,\n",
    "    EnsureChannelFirstd, \n",
    "    Orientationd,\n",
    "    LoadImaged,\n",
    "    CopyItemsd,\n",
    "    NormalizeIntensity,\n",
    "    HistogramNormalize,\n",
    "    NormalizeIntensityd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    RandCropByLabelClassesd,\n",
    "    RandAffined,\n",
    "    RandFlipd,\n",
    "    Flipd,\n",
    "    RandGaussianNoised,\n",
    "    RandGaussianSmoothd,\n",
    "    RandGibbsNoised,\n",
    "    RandStdShiftIntensityd,\n",
    "    RandScaleIntensityd,\n",
    "    RandZoomd, \n",
    "    SpatialCrop, \n",
    "    SpatialPadd, \n",
    "    MapTransform,\n",
    "    CastToType,\n",
    "    ToTensord,\n",
    "    AddChanneld,\n",
    "    MapTransform,\n",
    "    Orientationd,\n",
    "    ScaleIntensityd,\n",
    "    ScaleIntensity,\n",
    "    ScaleIntensityRangePercentilesd,\n",
    "    KeepLargestConnectedComponentd,\n",
    "    KeepLargestConnectedComponent,\n",
    "    ScaleIntensityRange,\n",
    "    RandShiftIntensityd,\n",
    "    RandAdjustContrastd,\n",
    "    AdjustContrastd,\n",
    "    Rotated,\n",
    "    ToNumpyd,\n",
    "    ToDeviced,\n",
    "    EnsureType,\n",
    "    EnsureTyped,\n",
    "    DataStatsd,\n",
    ")\n",
    "\n",
    "from monai.config import KeysCollection\n",
    "from monai.transforms.compose import MapTransform, Randomizable\n",
    "from collections.abc import Iterable\n",
    "from typing import Any, Dict, Hashable, Mapping, Optional, Sequence, Tuple, Union\n",
    "from monai.utils import set_determinism\n",
    "from monai.utils import (\n",
    "    ensure_tuple,\n",
    "    ensure_tuple_rep,\n",
    "    ensure_tuple_size,\n",
    ")\n",
    "\n",
    "from monai.optimizers import LearningRateFinder\n",
    "\n",
    "from monai.transforms.compose import MapTransform\n",
    "from monai.transforms.utils import generate_spatial_bounding_box\n",
    "from skimage.transform import resize\n",
    "from monai.losses import DiceCELoss, DiceLoss\n",
    "from monai.utils import set_determinism\n",
    "from monai.inferers import sliding_window_inference\n",
    "\n",
    "\n",
    "from monai.metrics import DiceMetric, ROCAUCMetric, HausdorffDistanceMetric\n",
    "from monai.data import decollate_batch\n",
    "import glob\n",
    "import monai\n",
    "from monai.metrics import compute_meandice\n",
    "import random\n",
    "import pickle\n",
    "from collections import OrderedDict\n",
    "from typing import Sequence, Optional\n",
    "import ipywidgets as widgets\n",
    "from itertools import compress\n",
    "import SimpleITK as sitk\n",
    "import torchio as tio\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score, accuracy_score, recall_score, \\\n",
    "accuracy_score, precision_score, f1_score, make_scorer,balanced_accuracy_score \n",
    "\n",
    "from monai.utils import ensure_tuple_rep\n",
    "from monai.networks.layers.factories import Conv, Dropout, Norm, Pool\n",
    "import matplotlib.pyplot as plt\n",
    "from ranger21 import Ranger21\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "from itkwidgets import view\n",
    "import random\n",
    "monai.config.print_config()\n",
    "#from sliding_window_inference_classes import sliding_window_inference_classes"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d7b2e615",
   "metadata": {},
   "source": [
    "# Pipelines implemented here\n",
    "#[image](ProposedArchImgPath =250x250)\\\n",
    "<img src=\"assets/ProposedIDHClass.png\" align=\"left\" width=\"1024\" height=\"1800\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d74fc81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bbf90d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_THREADS =2\n",
    "sitk.ProcessObject.SetGlobalDefaultNumberOfThreads(MAX_THREADS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72e04935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jul 19 14:54:39 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.172.01   Driver Version: 450.172.01   CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-DGXS...  On   | 00000000:07:00.0 Off |                    0 |\n",
      "| N/A   43C    P0    43W / 300W |    108MiB / 32505MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-DGXS...  On   | 00000000:08:00.0 Off |                    0 |\n",
      "| N/A   47C    P0   120W / 300W |  18386MiB / 32508MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-DGXS...  On   | 00000000:0E:00.0 Off |                    0 |\n",
      "| N/A   44C    P0    38W / 300W |     13MiB / 32508MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-DGXS...  On   | 00000000:0F:00.0 Off |                    0 |\n",
      "| N/A   49C    P0    65W / 300W |  15767MiB / 32508MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      2917      G   /usr/lib/xorg/Xorg                 86MiB |\n",
      "|    0   N/A  N/A      3284      G   /usr/bin/gnome-shell               16MiB |\n",
      "|    1   N/A  N/A      2917      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    1   N/A  N/A    344939      C   .../sa_tumorseg22/bin/python     1609MiB |\n",
      "|    1   N/A  N/A    419185      C   .../sa_tumorseg22/bin/python     8945MiB |\n",
      "|    2   N/A  N/A      2917      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    3   N/A  N/A      2917      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    3   N/A  N/A    427418      C   .../sa_tumorseg22/bin/python     7715MiB |\n",
      "|    3   N/A  N/A    429873      C   .../sa_tumorseg22/bin/python     8039MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "seeds = 40961024\n",
    "set_determinism(seed=seeds)\n",
    "##np.random.seed(seeds) np random seed does not work here\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9384138",
   "metadata": {},
   "outputs": [],
   "source": [
    "#patch_size = (128, 128, 128)\n",
    "spacing = (1.0, 1.0, 1.0)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] =\"0\"\n",
    "device = torch.device('cuda:0')\n",
    "deviceName = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "215620ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "data_rpath = '/home/mmiv-ml/data'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a84ebd62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BraTS2021</th>\n",
       "      <th>t1wPath</th>\n",
       "      <th>t1cwPath</th>\n",
       "      <th>t1cw_N4CorrectPath</th>\n",
       "      <th>t2wPath</th>\n",
       "      <th>t2w_N4CorrectPath</th>\n",
       "      <th>flairPath</th>\n",
       "      <th>segPath</th>\n",
       "      <th>brain_maskPath</th>\n",
       "      <th>brain_mask_ch2Path</th>\n",
       "      <th>...</th>\n",
       "      <th>ET_CoordX</th>\n",
       "      <th>ET_CoordY</th>\n",
       "      <th>ET_CoordZ</th>\n",
       "      <th>ED_CoordX</th>\n",
       "      <th>ED_CoordY</th>\n",
       "      <th>ED_CoordZ</th>\n",
       "      <th>NEC_CoordX</th>\n",
       "      <th>NEC_CoordY</th>\n",
       "      <th>NEC_CoordZ</th>\n",
       "      <th>is_merged_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BraTS2021_00140</td>\n",
       "      <td>/raid/brats2021/RSNA_ASNR_MICCAI_BraTS2021_TrainingData/BraTS2021_00140/BraTS2021_00140_t1.nii.gz</td>\n",
       "      <td>/raid/brats2021/RSNA_ASNR_MICCAI_BraTS2021_TrainingData/BraTS2021_00140/BraTS2021_00140_t1ce.nii.gz</td>\n",
       "      <td>/raid/brats2021/RSNA_ASNR_MICCAI_BraTS2021_TrainingData/BraTS2021_00140/BraTS2021_00140_t1ce_afterN4Correct.nii.gz</td>\n",
       "      <td>/raid/brats2021/RSNA_ASNR_MICCAI_BraTS2021_TrainingData/BraTS2021_00140/BraTS2021_00140_t2.nii.gz</td>\n",
       "      <td>/raid/brats2021/RSNA_ASNR_MICCAI_BraTS2021_TrainingData/BraTS2021_00140/BraTS2021_00140_t2_afterN4Correct.nii.gz</td>\n",
       "      <td>/raid/brats2021/RSNA_ASNR_MICCAI_BraTS2021_TrainingData/BraTS2021_00140/BraTS2021_00140_flair.nii.gz</td>\n",
       "      <td>/raid/brats2021/RSNA_ASNR_MICCAI_BraTS2021_TrainingData/BraTS2021_00140/BraTS2021_00140_seg.nii.gz</td>\n",
       "      <td>/raid/brats2021/T1wx4Brain_ROIs/BraTS2021_00140/ROI_BraTS2021_00140.nii.gz</td>\n",
       "      <td>/raid/brats2021/T1wx2Brain_ROIs_BraTS21_Training/BraTS2021_00140/BraTS2021_00140_BrainROIT1cwx2.nii.gz</td>\n",
       "      <td>...</td>\n",
       "      <td>168.685087</td>\n",
       "      <td>167.653671</td>\n",
       "      <td>79.886450</td>\n",
       "      <td>162.346647</td>\n",
       "      <td>173.396768</td>\n",
       "      <td>87.441763</td>\n",
       "      <td>168.083333</td>\n",
       "      <td>167.200000</td>\n",
       "      <td>78.066667</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BraTS2021_01283</td>\n",
       "      <td>/raid/brats2021/RSNA_ASNR_MICCAI_BraTS2021_TrainingData/BraTS2021_01283/BraTS2021_01283_t1.nii.gz</td>\n",
       "      <td>/raid/brats2021/RSNA_ASNR_MICCAI_BraTS2021_TrainingData/BraTS2021_01283/BraTS2021_01283_t1ce.nii.gz</td>\n",
       "      <td>/raid/brats2021/RSNA_ASNR_MICCAI_BraTS2021_TrainingData/BraTS2021_01283/BraTS2021_01283_t1ce_afterN4Correct.nii.gz</td>\n",
       "      <td>/raid/brats2021/RSNA_ASNR_MICCAI_BraTS2021_TrainingData/BraTS2021_01283/BraTS2021_01283_t2.nii.gz</td>\n",
       "      <td>/raid/brats2021/RSNA_ASNR_MICCAI_BraTS2021_TrainingData/BraTS2021_01283/BraTS2021_01283_t2_afterN4Correct.nii.gz</td>\n",
       "      <td>/raid/brats2021/RSNA_ASNR_MICCAI_BraTS2021_TrainingData/BraTS2021_01283/BraTS2021_01283_flair.nii.gz</td>\n",
       "      <td>/raid/brats2021/RSNA_ASNR_MICCAI_BraTS2021_TrainingData/BraTS2021_01283/BraTS2021_01283_seg.nii.gz</td>\n",
       "      <td>/raid/brats2021/T1wx4Brain_ROIs/BraTS2021_01283/ROI_BraTS2021_01283.nii.gz</td>\n",
       "      <td>/raid/brats2021/T1wx2Brain_ROIs_BraTS21_Training/BraTS2021_01283/BraTS2021_01283_BrainROIT1cwx2.nii.gz</td>\n",
       "      <td>...</td>\n",
       "      <td>145.484701</td>\n",
       "      <td>134.678620</td>\n",
       "      <td>59.585174</td>\n",
       "      <td>152.096980</td>\n",
       "      <td>146.947874</td>\n",
       "      <td>73.214571</td>\n",
       "      <td>147.219848</td>\n",
       "      <td>134.146249</td>\n",
       "      <td>59.135090</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BraTS2021_01528</td>\n",
       "      <td>/raid/brats2021/RSNA_ASNR_MICCAI_BraTS2021_TrainingData/BraTS2021_01528/BraTS2021_01528_t1.nii.gz</td>\n",
       "      <td>/raid/brats2021/RSNA_ASNR_MICCAI_BraTS2021_TrainingData/BraTS2021_01528/BraTS2021_01528_t1ce.nii.gz</td>\n",
       "      <td>/raid/brats2021/RSNA_ASNR_MICCAI_BraTS2021_TrainingData/BraTS2021_01528/BraTS2021_01528_t1ce_afterN4Correct.nii.gz</td>\n",
       "      <td>/raid/brats2021/RSNA_ASNR_MICCAI_BraTS2021_TrainingData/BraTS2021_01528/BraTS2021_01528_t2.nii.gz</td>\n",
       "      <td>/raid/brats2021/RSNA_ASNR_MICCAI_BraTS2021_TrainingData/BraTS2021_01528/BraTS2021_01528_t2_afterN4Correct.nii.gz</td>\n",
       "      <td>/raid/brats2021/RSNA_ASNR_MICCAI_BraTS2021_TrainingData/BraTS2021_01528/BraTS2021_01528_flair.nii.gz</td>\n",
       "      <td>/raid/brats2021/RSNA_ASNR_MICCAI_BraTS2021_TrainingData/BraTS2021_01528/BraTS2021_01528_seg.nii.gz</td>\n",
       "      <td>/raid/brats2021/T1wx4Brain_ROIs/BraTS2021_01528/ROI_BraTS2021_01528.nii.gz</td>\n",
       "      <td>/raid/brats2021/T1wx2Brain_ROIs_BraTS21_Training/BraTS2021_01528/BraTS2021_01528_BrainROIT1cwx2.nii.gz</td>\n",
       "      <td>...</td>\n",
       "      <td>77.531023</td>\n",
       "      <td>144.899230</td>\n",
       "      <td>82.371416</td>\n",
       "      <td>94.469503</td>\n",
       "      <td>140.150948</td>\n",
       "      <td>66.994481</td>\n",
       "      <td>71.698179</td>\n",
       "      <td>136.327992</td>\n",
       "      <td>62.269723</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BraTS2021_01503</td>\n",
       "      <td>/raid/brats2021/RSNA_ASNR_MICCAI_BraTS2021_TrainingData/BraTS2021_01503/BraTS2021_01503_t1.nii.gz</td>\n",
       "      <td>/raid/brats2021/RSNA_ASNR_MICCAI_BraTS2021_TrainingData/BraTS2021_01503/BraTS2021_01503_t1ce.nii.gz</td>\n",
       "      <td>/raid/brats2021/RSNA_ASNR_MICCAI_BraTS2021_TrainingData/BraTS2021_01503/BraTS2021_01503_t1ce_afterN4Correct.nii.gz</td>\n",
       "      <td>/raid/brats2021/RSNA_ASNR_MICCAI_BraTS2021_TrainingData/BraTS2021_01503/BraTS2021_01503_t2.nii.gz</td>\n",
       "      <td>/raid/brats2021/RSNA_ASNR_MICCAI_BraTS2021_TrainingData/BraTS2021_01503/BraTS2021_01503_t2_afterN4Correct.nii.gz</td>\n",
       "      <td>/raid/brats2021/RSNA_ASNR_MICCAI_BraTS2021_TrainingData/BraTS2021_01503/BraTS2021_01503_flair.nii.gz</td>\n",
       "      <td>/raid/brats2021/RSNA_ASNR_MICCAI_BraTS2021_TrainingData/BraTS2021_01503/BraTS2021_01503_seg.nii.gz</td>\n",
       "      <td>/raid/brats2021/T1wx4Brain_ROIs/BraTS2021_01503/ROI_BraTS2021_01503.nii.gz</td>\n",
       "      <td>/raid/brats2021/T1wx2Brain_ROIs_BraTS21_Training/BraTS2021_01503/BraTS2021_01503_BrainROIT1cwx2.nii.gz</td>\n",
       "      <td>...</td>\n",
       "      <td>110.542553</td>\n",
       "      <td>73.074468</td>\n",
       "      <td>70.808511</td>\n",
       "      <td>107.090113</td>\n",
       "      <td>82.676138</td>\n",
       "      <td>76.029439</td>\n",
       "      <td>105.099771</td>\n",
       "      <td>65.077985</td>\n",
       "      <td>76.992437</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BraTS2021_01453</td>\n",
       "      <td>/raid/brats2021/RSNA_ASNR_MICCAI_BraTS2021_TrainingData/BraTS2021_01453/BraTS2021_01453_t1.nii.gz</td>\n",
       "      <td>/raid/brats2021/RSNA_ASNR_MICCAI_BraTS2021_TrainingData/BraTS2021_01453/BraTS2021_01453_t1ce.nii.gz</td>\n",
       "      <td>/raid/brats2021/RSNA_ASNR_MICCAI_BraTS2021_TrainingData/BraTS2021_01453/BraTS2021_01453_t1ce_afterN4Correct.nii.gz</td>\n",
       "      <td>/raid/brats2021/RSNA_ASNR_MICCAI_BraTS2021_TrainingData/BraTS2021_01453/BraTS2021_01453_t2.nii.gz</td>\n",
       "      <td>/raid/brats2021/RSNA_ASNR_MICCAI_BraTS2021_TrainingData/BraTS2021_01453/BraTS2021_01453_t2_afterN4Correct.nii.gz</td>\n",
       "      <td>/raid/brats2021/RSNA_ASNR_MICCAI_BraTS2021_TrainingData/BraTS2021_01453/BraTS2021_01453_flair.nii.gz</td>\n",
       "      <td>/raid/brats2021/RSNA_ASNR_MICCAI_BraTS2021_TrainingData/BraTS2021_01453/BraTS2021_01453_seg.nii.gz</td>\n",
       "      <td>/raid/brats2021/T1wx4Brain_ROIs/BraTS2021_01453/ROI_BraTS2021_01453.nii.gz</td>\n",
       "      <td>/raid/brats2021/T1wx2Brain_ROIs_BraTS21_Training/BraTS2021_01453/BraTS2021_01453_BrainROIT1cwx2.nii.gz</td>\n",
       "      <td>...</td>\n",
       "      <td>86.031397</td>\n",
       "      <td>128.011381</td>\n",
       "      <td>67.940149</td>\n",
       "      <td>81.830275</td>\n",
       "      <td>119.381631</td>\n",
       "      <td>64.750845</td>\n",
       "      <td>83.705329</td>\n",
       "      <td>127.626959</td>\n",
       "      <td>65.589342</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/raid/brats2021/LGG_1p19q_rawNifti/LGG_1p19q_BraTSLikeProcess_mnibet/LGG-651/LGG-651_t1Gd.nii.gz</td>\n",
       "      <td>/raid/brats2021/LGG_1p19q_rawNifti/LGG_1p19q_BraTSLikeProcess_mnibet/LGG-651/LGG-651_t1Gd_afterN4Correct.nii.gz</td>\n",
       "      <td>/raid/brats2021/LGG_1p19q_rawNifti/LGG_1p19q_BraTSLikeProcess_mnibet/LGG-651/LGG-651_t2.nii.gz</td>\n",
       "      <td>/raid/brats2021/LGG_1p19q_rawNifti/LGG_1p19q_BraTSLikeProcess_mnibet/LGG-651/LGG-651_t2_afterN4Correct.nii.gz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/raid/brats2021/LGG_1p19q_rawNifti/4Ensemble_LGG_1p19q_Infer/LGG-651/LGG-651_pred.nii.gz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/raid/brats2021/LGG_1p19q_rawNifti/T1wx2Brain_ROIs_LGG_1p19q/LGG-651/LGG-651_BrainROIT1cwx2.nii.gz</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.500422</td>\n",
       "      <td>115.393242</td>\n",
       "      <td>68.151900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/raid/brats2021/LGG_1p19q_rawNifti/LGG_1p19q_BraTSLikeProcess_mnibet/LGG-658/LGG-658_t1Gd.nii.gz</td>\n",
       "      <td>/raid/brats2021/LGG_1p19q_rawNifti/LGG_1p19q_BraTSLikeProcess_mnibet/LGG-658/LGG-658_t1Gd_afterN4Correct.nii.gz</td>\n",
       "      <td>/raid/brats2021/LGG_1p19q_rawNifti/LGG_1p19q_BraTSLikeProcess_mnibet/LGG-658/LGG-658_t2.nii.gz</td>\n",
       "      <td>/raid/brats2021/LGG_1p19q_rawNifti/LGG_1p19q_BraTSLikeProcess_mnibet/LGG-658/LGG-658_t2_afterN4Correct.nii.gz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/raid/brats2021/LGG_1p19q_rawNifti/4Ensemble_LGG_1p19q_Infer/LGG-658/LGG-658_pred.nii.gz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/raid/brats2021/LGG_1p19q_rawNifti/T1wx2Brain_ROIs_LGG_1p19q/LGG-658/LGG-658_BrainROIT1cwx2.nii.gz</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>136.202745</td>\n",
       "      <td>166.640807</td>\n",
       "      <td>107.448810</td>\n",
       "      <td>140.095694</td>\n",
       "      <td>173.392344</td>\n",
       "      <td>97.712919</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/raid/brats2021/LGG_1p19q_rawNifti/LGG_1p19q_BraTSLikeProcess_mnibet/LGG-659/LGG-659_t1Gd.nii.gz</td>\n",
       "      <td>/raid/brats2021/LGG_1p19q_rawNifti/LGG_1p19q_BraTSLikeProcess_mnibet/LGG-659/LGG-659_t1Gd_afterN4Correct.nii.gz</td>\n",
       "      <td>/raid/brats2021/LGG_1p19q_rawNifti/LGG_1p19q_BraTSLikeProcess_mnibet/LGG-659/LGG-659_t2.nii.gz</td>\n",
       "      <td>/raid/brats2021/LGG_1p19q_rawNifti/LGG_1p19q_BraTSLikeProcess_mnibet/LGG-659/LGG-659_t2_afterN4Correct.nii.gz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/raid/brats2021/LGG_1p19q_rawNifti/4Ensemble_LGG_1p19q_Infer/LGG-659/LGG-659_pred.nii.gz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/raid/brats2021/LGG_1p19q_rawNifti/T1wx2Brain_ROIs_LGG_1p19q/LGG-659/LGG-659_BrainROIT1cwx2.nii.gz</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>131.580447</td>\n",
       "      <td>105.934087</td>\n",
       "      <td>122.249243</td>\n",
       "      <td>130.666667</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/raid/brats2021/LGG_1p19q_rawNifti/LGG_1p19q_BraTSLikeProcess_mnibet/LGG-660/LGG-660_t1Gd.nii.gz</td>\n",
       "      <td>/raid/brats2021/LGG_1p19q_rawNifti/LGG_1p19q_BraTSLikeProcess_mnibet/LGG-660/LGG-660_t1Gd_afterN4Correct.nii.gz</td>\n",
       "      <td>/raid/brats2021/LGG_1p19q_rawNifti/LGG_1p19q_BraTSLikeProcess_mnibet/LGG-660/LGG-660_t2.nii.gz</td>\n",
       "      <td>/raid/brats2021/LGG_1p19q_rawNifti/LGG_1p19q_BraTSLikeProcess_mnibet/LGG-660/LGG-660_t2_afterN4Correct.nii.gz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/raid/brats2021/LGG_1p19q_rawNifti/4Ensemble_LGG_1p19q_Infer/LGG-660/LGG-660_pred.nii.gz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/raid/brats2021/LGG_1p19q_rawNifti/T1wx2Brain_ROIs_LGG_1p19q/LGG-660/LGG-660_BrainROIT1cwx2.nii.gz</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88.208202</td>\n",
       "      <td>185.948429</td>\n",
       "      <td>73.406706</td>\n",
       "      <td>88.338498</td>\n",
       "      <td>194.035995</td>\n",
       "      <td>76.130393</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/raid/brats2021/LGG_1p19q_rawNifti/LGG_1p19q_BraTSLikeProcess_mnibet/LGG-766/LGG-766_t1Gd.nii.gz</td>\n",
       "      <td>/raid/brats2021/LGG_1p19q_rawNifti/LGG_1p19q_BraTSLikeProcess_mnibet/LGG-766/LGG-766_t1Gd_afterN4Correct.nii.gz</td>\n",
       "      <td>/raid/brats2021/LGG_1p19q_rawNifti/LGG_1p19q_BraTSLikeProcess_mnibet/LGG-766/LGG-766_t2.nii.gz</td>\n",
       "      <td>/raid/brats2021/LGG_1p19q_rawNifti/LGG_1p19q_BraTSLikeProcess_mnibet/LGG-766/LGG-766_t2_afterN4Correct.nii.gz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/raid/brats2021/LGG_1p19q_rawNifti/4Ensemble_LGG_1p19q_Infer/LGG-766/LGG-766_pred.nii.gz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/raid/brats2021/LGG_1p19q_rawNifti/T1wx2Brain_ROIs_LGG_1p19q/LGG-766/LGG-766_BrainROIT1cwx2.nii.gz</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>145.203497</td>\n",
       "      <td>93.599896</td>\n",
       "      <td>80.739451</td>\n",
       "      <td>144.431587</td>\n",
       "      <td>91.927287</td>\n",
       "      <td>82.874902</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>368 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           BraTS2021  \\\n",
       "0    BraTS2021_00140   \n",
       "1    BraTS2021_01283   \n",
       "2    BraTS2021_01528   \n",
       "3    BraTS2021_01503   \n",
       "4    BraTS2021_01453   \n",
       "..               ...   \n",
       "363              NaN   \n",
       "364              NaN   \n",
       "365              NaN   \n",
       "366              NaN   \n",
       "367              NaN   \n",
       "\n",
       "                                                                                               t1wPath  \\\n",
       "0    /raid/brats2021/RSNA_ASNR_MICCAI_BraTS2021_TrainingData/BraTS2021_00140/BraTS2021_00140_t1.nii.gz   \n",
       "1    /raid/brats2021/RSNA_ASNR_MICCAI_BraTS2021_TrainingData/BraTS2021_01283/BraTS2021_01283_t1.nii.gz   \n",
       "2    /raid/brats2021/RSNA_ASNR_MICCAI_BraTS2021_TrainingData/BraTS2021_01528/BraTS2021_01528_t1.nii.gz   \n",
       "3    /raid/brats2021/RSNA_ASNR_MICCAI_BraTS2021_TrainingData/BraTS2021_01503/BraTS2021_01503_t1.nii.gz   \n",
       "4    /raid/brats2021/RSNA_ASNR_MICCAI_BraTS2021_TrainingData/BraTS2021_01453/BraTS2021_01453_t1.nii.gz   \n",
       "..                                                                                                 ...   \n",
       "363                                                                                                NaN   \n",
       "364                                                                                                NaN   \n",
       "365                                                                                                NaN   \n",
       "366                                                                                                NaN   \n",
       "367                                                                                                NaN   \n",
       "\n",
       "                                                                                                t1cwPath  \\\n",
       "0    /raid/brats2021/RSNA_ASNR_MICCAI_BraTS2021_TrainingData/BraTS2021_00140/BraTS2021_00140_t1ce.nii.gz   \n",
       "1    /raid/brats2021/RSNA_ASNR_MICCAI_BraTS2021_TrainingData/BraTS2021_01283/BraTS2021_01283_t1ce.nii.gz   \n",
       "2    /raid/brats2021/RSNA_ASNR_MICCAI_BraTS2021_TrainingData/BraTS2021_01528/BraTS2021_01528_t1ce.nii.gz   \n",
       "3    /raid/brats2021/RSNA_ASNR_MICCAI_BraTS2021_TrainingData/BraTS2021_01503/BraTS2021_01503_t1ce.nii.gz   \n",
       "4    /raid/brats2021/RSNA_ASNR_MICCAI_BraTS2021_TrainingData/BraTS2021_01453/BraTS2021_01453_t1ce.nii.gz   \n",
       "..                                                                                                   ...   \n",
       "363     /raid/brats2021/LGG_1p19q_rawNifti/LGG_1p19q_BraTSLikeProcess_mnibet/LGG-651/LGG-651_t1Gd.nii.gz   \n",
       "364     /raid/brats2021/LGG_1p19q_rawNifti/LGG_1p19q_BraTSLikeProcess_mnibet/LGG-658/LGG-658_t1Gd.nii.gz   \n",
       "365     /raid/brats2021/LGG_1p19q_rawNifti/LGG_1p19q_BraTSLikeProcess_mnibet/LGG-659/LGG-659_t1Gd.nii.gz   \n",
       "366     /raid/brats2021/LGG_1p19q_rawNifti/LGG_1p19q_BraTSLikeProcess_mnibet/LGG-660/LGG-660_t1Gd.nii.gz   \n",
       "367     /raid/brats2021/LGG_1p19q_rawNifti/LGG_1p19q_BraTSLikeProcess_mnibet/LGG-766/LGG-766_t1Gd.nii.gz   \n",
       "\n",
       "                                                                                                     t1cw_N4CorrectPath  \\\n",
       "0    /raid/brats2021/RSNA_ASNR_MICCAI_BraTS2021_TrainingData/BraTS2021_00140/BraTS2021_00140_t1ce_afterN4Correct.nii.gz   \n",
       "1    /raid/brats2021/RSNA_ASNR_MICCAI_BraTS2021_TrainingData/BraTS2021_01283/BraTS2021_01283_t1ce_afterN4Correct.nii.gz   \n",
       "2    /raid/brats2021/RSNA_ASNR_MICCAI_BraTS2021_TrainingData/BraTS2021_01528/BraTS2021_01528_t1ce_afterN4Correct.nii.gz   \n",
       "3    /raid/brats2021/RSNA_ASNR_MICCAI_BraTS2021_TrainingData/BraTS2021_01503/BraTS2021_01503_t1ce_afterN4Correct.nii.gz   \n",
       "4    /raid/brats2021/RSNA_ASNR_MICCAI_BraTS2021_TrainingData/BraTS2021_01453/BraTS2021_01453_t1ce_afterN4Correct.nii.gz   \n",
       "..                                                                                                                  ...   \n",
       "363     /raid/brats2021/LGG_1p19q_rawNifti/LGG_1p19q_BraTSLikeProcess_mnibet/LGG-651/LGG-651_t1Gd_afterN4Correct.nii.gz   \n",
       "364     /raid/brats2021/LGG_1p19q_rawNifti/LGG_1p19q_BraTSLikeProcess_mnibet/LGG-658/LGG-658_t1Gd_afterN4Correct.nii.gz   \n",
       "365     /raid/brats2021/LGG_1p19q_rawNifti/LGG_1p19q_BraTSLikeProcess_mnibet/LGG-659/LGG-659_t1Gd_afterN4Correct.nii.gz   \n",
       "366     /raid/brats2021/LGG_1p19q_rawNifti/LGG_1p19q_BraTSLikeProcess_mnibet/LGG-660/LGG-660_t1Gd_afterN4Correct.nii.gz   \n",
       "367     /raid/brats2021/LGG_1p19q_rawNifti/LGG_1p19q_BraTSLikeProcess_mnibet/LGG-766/LGG-766_t1Gd_afterN4Correct.nii.gz   \n",
       "\n",
       "                                                                                               t2wPath  \\\n",
       "0    /raid/brats2021/RSNA_ASNR_MICCAI_BraTS2021_TrainingData/BraTS2021_00140/BraTS2021_00140_t2.nii.gz   \n",
       "1    /raid/brats2021/RSNA_ASNR_MICCAI_BraTS2021_TrainingData/BraTS2021_01283/BraTS2021_01283_t2.nii.gz   \n",
       "2    /raid/brats2021/RSNA_ASNR_MICCAI_BraTS2021_TrainingData/BraTS2021_01528/BraTS2021_01528_t2.nii.gz   \n",
       "3    /raid/brats2021/RSNA_ASNR_MICCAI_BraTS2021_TrainingData/BraTS2021_01503/BraTS2021_01503_t2.nii.gz   \n",
       "4    /raid/brats2021/RSNA_ASNR_MICCAI_BraTS2021_TrainingData/BraTS2021_01453/BraTS2021_01453_t2.nii.gz   \n",
       "..                                                                                                 ...   \n",
       "363     /raid/brats2021/LGG_1p19q_rawNifti/LGG_1p19q_BraTSLikeProcess_mnibet/LGG-651/LGG-651_t2.nii.gz   \n",
       "364     /raid/brats2021/LGG_1p19q_rawNifti/LGG_1p19q_BraTSLikeProcess_mnibet/LGG-658/LGG-658_t2.nii.gz   \n",
       "365     /raid/brats2021/LGG_1p19q_rawNifti/LGG_1p19q_BraTSLikeProcess_mnibet/LGG-659/LGG-659_t2.nii.gz   \n",
       "366     /raid/brats2021/LGG_1p19q_rawNifti/LGG_1p19q_BraTSLikeProcess_mnibet/LGG-660/LGG-660_t2.nii.gz   \n",
       "367     /raid/brats2021/LGG_1p19q_rawNifti/LGG_1p19q_BraTSLikeProcess_mnibet/LGG-766/LGG-766_t2.nii.gz   \n",
       "\n",
       "                                                                                                    t2w_N4CorrectPath  \\\n",
       "0    /raid/brats2021/RSNA_ASNR_MICCAI_BraTS2021_TrainingData/BraTS2021_00140/BraTS2021_00140_t2_afterN4Correct.nii.gz   \n",
       "1    /raid/brats2021/RSNA_ASNR_MICCAI_BraTS2021_TrainingData/BraTS2021_01283/BraTS2021_01283_t2_afterN4Correct.nii.gz   \n",
       "2    /raid/brats2021/RSNA_ASNR_MICCAI_BraTS2021_TrainingData/BraTS2021_01528/BraTS2021_01528_t2_afterN4Correct.nii.gz   \n",
       "3    /raid/brats2021/RSNA_ASNR_MICCAI_BraTS2021_TrainingData/BraTS2021_01503/BraTS2021_01503_t2_afterN4Correct.nii.gz   \n",
       "4    /raid/brats2021/RSNA_ASNR_MICCAI_BraTS2021_TrainingData/BraTS2021_01453/BraTS2021_01453_t2_afterN4Correct.nii.gz   \n",
       "..                                                                                                                ...   \n",
       "363     /raid/brats2021/LGG_1p19q_rawNifti/LGG_1p19q_BraTSLikeProcess_mnibet/LGG-651/LGG-651_t2_afterN4Correct.nii.gz   \n",
       "364     /raid/brats2021/LGG_1p19q_rawNifti/LGG_1p19q_BraTSLikeProcess_mnibet/LGG-658/LGG-658_t2_afterN4Correct.nii.gz   \n",
       "365     /raid/brats2021/LGG_1p19q_rawNifti/LGG_1p19q_BraTSLikeProcess_mnibet/LGG-659/LGG-659_t2_afterN4Correct.nii.gz   \n",
       "366     /raid/brats2021/LGG_1p19q_rawNifti/LGG_1p19q_BraTSLikeProcess_mnibet/LGG-660/LGG-660_t2_afterN4Correct.nii.gz   \n",
       "367     /raid/brats2021/LGG_1p19q_rawNifti/LGG_1p19q_BraTSLikeProcess_mnibet/LGG-766/LGG-766_t2_afterN4Correct.nii.gz   \n",
       "\n",
       "                                                                                                flairPath  \\\n",
       "0    /raid/brats2021/RSNA_ASNR_MICCAI_BraTS2021_TrainingData/BraTS2021_00140/BraTS2021_00140_flair.nii.gz   \n",
       "1    /raid/brats2021/RSNA_ASNR_MICCAI_BraTS2021_TrainingData/BraTS2021_01283/BraTS2021_01283_flair.nii.gz   \n",
       "2    /raid/brats2021/RSNA_ASNR_MICCAI_BraTS2021_TrainingData/BraTS2021_01528/BraTS2021_01528_flair.nii.gz   \n",
       "3    /raid/brats2021/RSNA_ASNR_MICCAI_BraTS2021_TrainingData/BraTS2021_01503/BraTS2021_01503_flair.nii.gz   \n",
       "4    /raid/brats2021/RSNA_ASNR_MICCAI_BraTS2021_TrainingData/BraTS2021_01453/BraTS2021_01453_flair.nii.gz   \n",
       "..                                                                                                    ...   \n",
       "363                                                                                                   NaN   \n",
       "364                                                                                                   NaN   \n",
       "365                                                                                                   NaN   \n",
       "366                                                                                                   NaN   \n",
       "367                                                                                                   NaN   \n",
       "\n",
       "                                                                                                segPath  \\\n",
       "0    /raid/brats2021/RSNA_ASNR_MICCAI_BraTS2021_TrainingData/BraTS2021_00140/BraTS2021_00140_seg.nii.gz   \n",
       "1    /raid/brats2021/RSNA_ASNR_MICCAI_BraTS2021_TrainingData/BraTS2021_01283/BraTS2021_01283_seg.nii.gz   \n",
       "2    /raid/brats2021/RSNA_ASNR_MICCAI_BraTS2021_TrainingData/BraTS2021_01528/BraTS2021_01528_seg.nii.gz   \n",
       "3    /raid/brats2021/RSNA_ASNR_MICCAI_BraTS2021_TrainingData/BraTS2021_01503/BraTS2021_01503_seg.nii.gz   \n",
       "4    /raid/brats2021/RSNA_ASNR_MICCAI_BraTS2021_TrainingData/BraTS2021_01453/BraTS2021_01453_seg.nii.gz   \n",
       "..                                                                                                  ...   \n",
       "363            /raid/brats2021/LGG_1p19q_rawNifti/4Ensemble_LGG_1p19q_Infer/LGG-651/LGG-651_pred.nii.gz   \n",
       "364            /raid/brats2021/LGG_1p19q_rawNifti/4Ensemble_LGG_1p19q_Infer/LGG-658/LGG-658_pred.nii.gz   \n",
       "365            /raid/brats2021/LGG_1p19q_rawNifti/4Ensemble_LGG_1p19q_Infer/LGG-659/LGG-659_pred.nii.gz   \n",
       "366            /raid/brats2021/LGG_1p19q_rawNifti/4Ensemble_LGG_1p19q_Infer/LGG-660/LGG-660_pred.nii.gz   \n",
       "367            /raid/brats2021/LGG_1p19q_rawNifti/4Ensemble_LGG_1p19q_Infer/LGG-766/LGG-766_pred.nii.gz   \n",
       "\n",
       "                                                                 brain_maskPath  \\\n",
       "0    /raid/brats2021/T1wx4Brain_ROIs/BraTS2021_00140/ROI_BraTS2021_00140.nii.gz   \n",
       "1    /raid/brats2021/T1wx4Brain_ROIs/BraTS2021_01283/ROI_BraTS2021_01283.nii.gz   \n",
       "2    /raid/brats2021/T1wx4Brain_ROIs/BraTS2021_01528/ROI_BraTS2021_01528.nii.gz   \n",
       "3    /raid/brats2021/T1wx4Brain_ROIs/BraTS2021_01503/ROI_BraTS2021_01503.nii.gz   \n",
       "4    /raid/brats2021/T1wx4Brain_ROIs/BraTS2021_01453/ROI_BraTS2021_01453.nii.gz   \n",
       "..                                                                          ...   \n",
       "363                                                                         NaN   \n",
       "364                                                                         NaN   \n",
       "365                                                                         NaN   \n",
       "366                                                                         NaN   \n",
       "367                                                                         NaN   \n",
       "\n",
       "                                                                                         brain_mask_ch2Path  \\\n",
       "0    /raid/brats2021/T1wx2Brain_ROIs_BraTS21_Training/BraTS2021_00140/BraTS2021_00140_BrainROIT1cwx2.nii.gz   \n",
       "1    /raid/brats2021/T1wx2Brain_ROIs_BraTS21_Training/BraTS2021_01283/BraTS2021_01283_BrainROIT1cwx2.nii.gz   \n",
       "2    /raid/brats2021/T1wx2Brain_ROIs_BraTS21_Training/BraTS2021_01528/BraTS2021_01528_BrainROIT1cwx2.nii.gz   \n",
       "3    /raid/brats2021/T1wx2Brain_ROIs_BraTS21_Training/BraTS2021_01503/BraTS2021_01503_BrainROIT1cwx2.nii.gz   \n",
       "4    /raid/brats2021/T1wx2Brain_ROIs_BraTS21_Training/BraTS2021_01453/BraTS2021_01453_BrainROIT1cwx2.nii.gz   \n",
       "..                                                                                                      ...   \n",
       "363      /raid/brats2021/LGG_1p19q_rawNifti/T1wx2Brain_ROIs_LGG_1p19q/LGG-651/LGG-651_BrainROIT1cwx2.nii.gz   \n",
       "364      /raid/brats2021/LGG_1p19q_rawNifti/T1wx2Brain_ROIs_LGG_1p19q/LGG-658/LGG-658_BrainROIT1cwx2.nii.gz   \n",
       "365      /raid/brats2021/LGG_1p19q_rawNifti/T1wx2Brain_ROIs_LGG_1p19q/LGG-659/LGG-659_BrainROIT1cwx2.nii.gz   \n",
       "366      /raid/brats2021/LGG_1p19q_rawNifti/T1wx2Brain_ROIs_LGG_1p19q/LGG-660/LGG-660_BrainROIT1cwx2.nii.gz   \n",
       "367      /raid/brats2021/LGG_1p19q_rawNifti/T1wx2Brain_ROIs_LGG_1p19q/LGG-766/LGG-766_BrainROIT1cwx2.nii.gz   \n",
       "\n",
       "     ...   ET_CoordX   ET_CoordY  ET_CoordZ   ED_CoordX   ED_CoordY  \\\n",
       "0    ...  168.685087  167.653671  79.886450  162.346647  173.396768   \n",
       "1    ...  145.484701  134.678620  59.585174  152.096980  146.947874   \n",
       "2    ...   77.531023  144.899230  82.371416   94.469503  140.150948   \n",
       "3    ...  110.542553   73.074468  70.808511  107.090113   82.676138   \n",
       "4    ...   86.031397  128.011381  67.940149   81.830275  119.381631   \n",
       "..   ...         ...         ...        ...         ...         ...   \n",
       "363  ...         NaN         NaN        NaN  150.500422  115.393242   \n",
       "364  ...         NaN         NaN        NaN  136.202745  166.640807   \n",
       "365  ...         NaN         NaN        NaN  131.580447  105.934087   \n",
       "366  ...         NaN         NaN        NaN   88.208202  185.948429   \n",
       "367  ...         NaN         NaN        NaN  145.203497   93.599896   \n",
       "\n",
       "      ED_CoordZ  NEC_CoordX  NEC_CoordY  NEC_CoordZ  is_merged_3  \n",
       "0     87.441763  168.083333  167.200000   78.066667         both  \n",
       "1     73.214571  147.219848  134.146249   59.135090         both  \n",
       "2     66.994481   71.698179  136.327992   62.269723         both  \n",
       "3     76.029439  105.099771   65.077985   76.992437         both  \n",
       "4     64.750845   83.705329  127.626959   65.589342         both  \n",
       "..          ...         ...         ...         ...          ...  \n",
       "363   68.151900         NaN         NaN         NaN         both  \n",
       "364  107.448810  140.095694  173.392344   97.712919         both  \n",
       "365  122.249243  130.666667  116.000000  123.000000         both  \n",
       "366   73.406706   88.338498  194.035995   76.130393         both  \n",
       "367   80.739451  144.431587   91.927287   82.874902         both  \n",
       "\n",
       "[368 rows x 52 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BraTS20Subjectsp1q19WithMetaDF  = pd.read_csv('assets/BraTS_TCGA_LGG_GBM_LGG_1p19qDFMoreMeta_N4CorrectLatDF.csv')\n",
    "BraTS20Subjectsp1q19WithMetaDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debc21ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7faac25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b94cce8",
   "metadata": {},
   "source": [
    "## Cearing a list of dictionaries in order to feed into Monai's Dataset\n",
    "Keys:\n",
    "- ***image:*** T1, T1c, T2, and flair image\n",
    "- ***label:*** Segmented mask GT\n",
    "- ***brain_mask:*** Whole brain area (brain area=1 and Non brain area=0)\n",
    "- ***IDH_value:*** 1p19q_co_deletion class corresponding to the subject/images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f9fadc",
   "metadata": {},
   "source": [
    "### Creating/extracting 3 splits for cross validaion (3 cross validaion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9f2d3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_val_test_df(BraTS20SubjectsIDHWithMetaDF):\n",
    "    \n",
    "    \n",
    "    BraTS20SubjectsIDHTrainDCT = {}\n",
    "    BraTS20SubjectsIDHValDCT = {}\n",
    "    BraTS20SubjectsIDHTestDCT = {}\n",
    "    \n",
    "    aDCT = {'fold0':[1, 2, 3], 'fold1':[2, 3, 1], 'fold3': [3, 1, 2]}\n",
    "    \n",
    "    for indx, (akey, aval) in enumerate(aDCT.items()):\n",
    "        \n",
    "    \n",
    "        BraTS20SubjectsIDHWithMetaDFTrain = BraTS20SubjectsIDHWithMetaDF.loc[BraTS20SubjectsIDHWithMetaDF['CV_group']==aval[0]]\n",
    "        BraTS20SubjectsIDHWithMetaDFVal = BraTS20SubjectsIDHWithMetaDF.loc[BraTS20SubjectsIDHWithMetaDF['CV_group']==aval[1]]\n",
    "        BraTS20SubjectsIDHWithMetaDFTest = BraTS20SubjectsIDHWithMetaDF.loc[BraTS20SubjectsIDHWithMetaDF['CV_group']==aval[2]]\n",
    "\n",
    "        train_files = [{'image': (image_nameT1ce, image_nameT2), 'label': label_name, 'brain_mask':brain_mask, 'IDH_label':np.array(IDH_label_name).astype(np.float32)} \n",
    "                       for image_nameT1ce, image_nameT2, label_name, brain_mask, IDH_label_name \n",
    "                       in zip(BraTS20SubjectsIDHWithMetaDFTrain['t1cwPath'], BraTS20SubjectsIDHWithMetaDFTrain['t2wPath'], BraTS20SubjectsIDHWithMetaDFTrain['segPath'], \\\n",
    "                              BraTS20SubjectsIDHWithMetaDFTrain['brain_mask_ch2Path'], BraTS20SubjectsIDHWithMetaDFTrain['1p19q_co_deletion_bin'].values)]\n",
    "        \n",
    "        val_files =[{'image': (image_nameT1ce, image_nameT2), 'label': label_name, 'brain_mask':brain_mask, 'IDH_label':np.array(IDH_label_name).astype(np.float32)} \n",
    "                    for image_nameT1ce, image_nameT2, label_name, brain_mask, IDH_label_name \n",
    "                    in zip(BraTS20SubjectsIDHWithMetaDFVal['t1cwPath'], BraTS20SubjectsIDHWithMetaDFVal['t2wPath'],BraTS20SubjectsIDHWithMetaDFVal['segPath'],\\\n",
    "                           BraTS20SubjectsIDHWithMetaDFVal['brain_mask_ch2Path'], BraTS20SubjectsIDHWithMetaDFVal['1p19q_co_deletion_bin'].values)]\n",
    "        \n",
    "        test_files = [{'image': (image_nameT1ce, image_nameT2), 'label': label_name, 'brain_mask':brain_mask, 'IDH_label':np.array(IDH_label_name).astype(np.float32)} \n",
    "                      for image_nameT1ce, image_nameT2, label_name, brain_mask, IDH_label_name \n",
    "                      in zip(BraTS20SubjectsIDHWithMetaDFTest['t1cwPath'], BraTS20SubjectsIDHWithMetaDFTest['t2wPath'], BraTS20SubjectsIDHWithMetaDFTest['segPath'], \\\n",
    "                             BraTS20SubjectsIDHWithMetaDFTest['brain_mask_ch2Path'], BraTS20SubjectsIDHWithMetaDFTest['1p19q_co_deletion_bin'].values)]\n",
    "        \n",
    "        \n",
    "        BraTS20SubjectsIDHTrainDCT[f'fold{indx}'] = copy.deepcopy(train_files)\n",
    "        BraTS20SubjectsIDHValDCT[f'fold{indx}'] = copy.deepcopy(val_files)\n",
    "        BraTS20SubjectsIDHTestDCT[f'fold{indx}'] = copy.deepcopy(test_files)\n",
    "        \n",
    "        \n",
    "        \n",
    "    return BraTS20SubjectsIDHTrainDCT, BraTS20SubjectsIDHValDCT, BraTS20SubjectsIDHTestDCT\n",
    "        \n",
    "        \n",
    "        \n",
    "BraTS20SubjectsIDHTrainDCT, BraTS20SubjectsIDHValDCT, BraTS20SubjectsIDHTestDCT =  get_train_val_test_df(BraTS20Subjectsp1q19WithMetaDF)    \n",
    "        \n",
    "        \n",
    "\n",
    "# train_files_image = [(image_nameT1, image_nameT1ce, image_nameT2, image_nameFl) \n",
    "#                      for image_nameT1,image_nameT1ce, image_nameT2, image_nameFl \n",
    "#                      in zip(dfTrainLbl['t1wPath'], dfTrainLbl['t1cwPath'], dfTrainLbl['T2wPath'], dfTrainLbl['FlairPath'])]\n",
    "# train_files_label = dfTrainLbl['segPath'].tolist()\n",
    "# train_files_brain_mask = dfTrainLbl['brain_maskPath'].tolist()\n",
    "# train_files_IDH_label = dfTrainLbl['IDH_value'].values.ravel().tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb19397",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4f85ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_splits = 3\n",
    "# #train_index = np.linspace(0, train_features.shape[0]-1, num = train_features.shape[0], dtype = np.uint16, endpoint=True)\n",
    "# #partition_data = monai.data.utils.partition_dataset_classes(train_index, train_labels.values.ravel().tolist(), shuffle=True, num_partitions=n_splits) \n",
    "# #partition_data = monai.data.utils.partition_dataset_classes(train_files, dfTrainLbl['IDH_value'].values.ravel().tolist(), shuffle=True, num_partitions=n_splits)\n",
    "# partition_data = monai.data.partition_dataset_classes(train_files, BraTS20SubjectsIDHWithMetaDF['IDH_value'].values.ravel().tolist(), shuffle=True, num_partitions=n_splits)\n",
    "# print(len(partition_data), len(partition_data[0]), len(partition_data[1]), len(partition_data[2]))\n",
    "\n",
    "\n",
    "# # val_folds = {}\n",
    "# # train_folds = {}\n",
    "# # flds = np.linspace(0, n_splits, num=n_splits, dtype = np.int8)\n",
    "# # for cfold in range(n_splits):\n",
    "# #     not_cfold = np.delete(flds, cfold)\n",
    "# #     val_folds[cfold] = partition_data[cfold]\n",
    "# # #     train_folds[cfold] = \n",
    "# # # sub_flds = flds[..., ~0]   \n",
    "# # # sub_flds\n",
    "\n",
    "# val_folds = {}\n",
    "# train_folds = {}\n",
    "# flds = np.linspace(0, n_splits, num=n_splits, dtype = np.uint8)\n",
    "# for cfold in range(n_splits):\n",
    "#     #val_folds[f\"fold{cfold}\"] = train_features.values[partition_data[cfold],:]\n",
    "#     #train_folds[f\"fold{cfold}\"] = np.delete(train_features.values, partition_data[cfold], axis=0)\n",
    "#     #not_cfold = np.delete(flds, cfold)\n",
    "    \n",
    "#     val_folds[f\"fold{cfold}\"] = copy.deepcopy(partition_data[cfold])\n",
    "#     val_folds[f\"fold{cfold}_IDH_label\"] = copy.deepcopy([adct['IDH_label'].item() for adct in partition_data[cfold]])\n",
    "#     train_folds_masks = [1]*n_splits\n",
    "#     train_folds_masks[cfold] = 0\n",
    "#     partition_data_non_cfold = list()\n",
    "#     for aDctLstitem in compress(partition_data, train_folds_masks):\n",
    "#         partition_data_non_cfold.extend(aDctLstitem)\n",
    "        \n",
    "        \n",
    "#     train_folds[f\"fold{cfold}\"] = copy.deepcopy(partition_data_non_cfold)\n",
    "#     train_folds[f\"fold{cfold}_IDH_label\"] = copy.deepcopy([adct['IDH_label'].item() for adct in partition_data_non_cfold])\n",
    "\n",
    "# for i in range(n_splits):\n",
    "#     print('val: ', len(val_folds[f'fold{i}']), 'train: ', len(train_folds[f'fold{i}']), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecd9b91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(train_folds[\"fold0\"]), len(train_files)\n",
    "\n",
    "# for i_cv in range(n_splits):\n",
    "#     print('Training classes\\n')\n",
    "#     print(np.unique([train_folds[f'fold{i_cv}'][i]['IDH_label'].item() for i in range(len(train_folds[f'fold{i_cv}']))], return_counts = True))\n",
    "#     print('\\nValidation classes\\n')\n",
    "#     print(np.unique([val_folds[f'fold{i_cv}'][i]['IDH_label'].item() for i in range(len(val_folds[f'fold{i_cv}']))], return_counts = True))\n",
    "#     print('#'*4, '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b6697ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classes\n",
      "\n",
      "(array([0., 1.]), array([79, 43]))\n",
      "\n",
      "Validation classes\n",
      "\n",
      "(array([0., 1.]), array([80, 44]))\n",
      "\n",
      "Testing classes\n",
      "\n",
      "(array([0., 1.]), array([79, 43]))\n",
      "######################################## \n",
      "\n",
      "\n",
      "Training classes\n",
      "\n",
      "(array([0., 1.]), array([80, 44]))\n",
      "\n",
      "Validation classes\n",
      "\n",
      "(array([0., 1.]), array([79, 43]))\n",
      "\n",
      "Testing classes\n",
      "\n",
      "(array([0., 1.]), array([79, 43]))\n",
      "######################################## \n",
      "\n",
      "\n",
      "Training classes\n",
      "\n",
      "(array([0., 1.]), array([79, 43]))\n",
      "\n",
      "Validation classes\n",
      "\n",
      "(array([0., 1.]), array([79, 43]))\n",
      "\n",
      "Testing classes\n",
      "\n",
      "(array([0., 1.]), array([80, 44]))\n",
      "######################################## \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_splits = 3\n",
    "dfFolds = BraTS20SubjectsIDHTrainDCT\n",
    "for i_cv in range(n_splits):\n",
    "    print('Training classes\\n')\n",
    "    print(np.unique([BraTS20SubjectsIDHTrainDCT[f'fold{i_cv}'][i]['IDH_label'].item() for i in range(len(BraTS20SubjectsIDHTrainDCT[f'fold{i_cv}']))], return_counts = True))\n",
    "    print('\\nValidation classes\\n')\n",
    "    print(np.unique([BraTS20SubjectsIDHValDCT[f'fold{i_cv}'][i]['IDH_label'].item() for i in range(len(BraTS20SubjectsIDHValDCT[f'fold{i_cv}']))], return_counts = True))\n",
    "    #print('#'*4, '\\n')\n",
    "    print('\\nTesting classes\\n')\n",
    "    print(np.unique([BraTS20SubjectsIDHTestDCT[f'fold{i_cv}'][i]['IDH_label'].item() for i in range(len(BraTS20SubjectsIDHTestDCT[f'fold{i_cv}']))], return_counts = True))\n",
    "    print('#'*40, '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbd4181",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3deeadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_folds['fold0'][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede8000f",
   "metadata": {},
   "source": [
    "***HistogramStandardization***\n",
    "\n",
    "Implementing histogram standardization from [torchIO](https://github.com/fepegar/torchio) library\n",
    "\n",
    "Bases: [torchio.transforms.preprocessing.intensity.normalization_transform.NormalizationTransform](https://torchio.readthedocs.io/transforms/preprocessing.html#torchio.transforms.preprocessing.intensity.NormalizationTransform)\n",
    "\n",
    "Perform histogram standardization of intensity values.\n",
    "\n",
    "Implementation of [New variants of a method of MRI scale standardization](https://ieeexplore.ieee.org/document/836373).\n",
    "\n",
    "We can visit in [torchio.transforms.HistogramStandardization.train()]((https://torchio.readthedocs.io/transforms/preprocessing.html#torchio.transforms.HistogramStandardization.train)) for more details.\n",
    "\n",
    "PARAMETERS\n",
    "landmarks – Dictionary (or path to a PyTorch file with .pt or .pth extension in which a dictionary has been saved) whose keys are image names in the subject and values are NumPy arrays or paths to NumPy arrays defining the landmarks after training with [torchio.transforms.HistogramStandardization.train()](https://torchio.readthedocs.io/transforms/preprocessing.html#torchio.transforms.HistogramStandardization.train).\n",
    "\n",
    "Here, ***save_dir*** is a path where the trained histogram files for four channels (T1w, T1cw, T2w, and Flair), and trained model's weights will be saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b17020a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'t1cw': '/home/mmiv-ml/saruarlive/IDHRadiogenomics2022/assets/histeq_t1cw_DynUnetCommon_OnlyBrats21_Full.npy',\n",
       " 't2w': '/home/mmiv-ml/saruarlive/IDHRadiogenomics2022/assets/histeq_t2w_DynUnetCommon_OnlyBrats21_Full.npy'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_prefix = 'DynUnetCommon_OnlyBrats21_Full'\n",
    "hist_save_dir = '/home/mmiv-ml/saruarlive/IDHRadiogenomics2022/assets'\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "hiseq_t1cnpyfile =  os.path.join(hist_save_dir, f\"histeq_t1cw_{file_prefix}.npy\")\n",
    "t1cw_landmarks = (hiseq_t1cnpyfile if os.path.isfile(hiseq_t1cnpyfile) else \\\n",
    "                  tio.HistogramStandardization.train(image_t1cwpaths, output_path = hiseq_t1cnpyfile))\n",
    "\n",
    "\n",
    "\n",
    "hiseq_t2npyfile = os.path.join(hist_save_dir, f\"histeq_t2w_{file_prefix}.npy\")\n",
    "t2w_landmarks = (hiseq_t2npyfile if os.path.isfile(hiseq_t2npyfile) else \\\n",
    "                 tio.HistogramStandardization.train(image_t2wpaths, output_path = hiseq_t2npyfile))\n",
    "\n",
    "\n",
    "landmarks_dict = {'t1cw': t1cw_landmarks, 't2w': t2w_landmarks}\n",
    "#tio_landmarktransform = tio.HistogramStandardization(landmarks_dict)\n",
    "landmarks_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2ca75e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_prefix = 'AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand'\n",
    "#file_prefix = 'AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_WeightSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand'\n",
    "savedirname = 'DynUNetVariants_TCGA'\n",
    "save_dir = os.path.join('/raid/brats2021/pthTCGA_1p19q_CoDeletion', savedirname)\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a36c6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5fd77a0f",
   "metadata": {},
   "source": [
    "## Classes for Monai/Pytorch compose class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3816b38d",
   "metadata": {},
   "source": [
    "A class to rearrange label mask array as \n",
    "- [0, :, :, :] = the multi class mask (class labels: 0 (background), 1, 2, and 4)\n",
    "- [1, :, :, :] = the whole tumor mask (class labels: 0 (background), and 1)\\\n",
    "Not using here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5696af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvertToMultiChannelPlusWT(MapTransform):\n",
    "    \n",
    "    \"\"\"\n",
    "     GD-enhancing tumor (ET — label 4), \n",
    "     the peritumoral edema (ED — label 2), and \n",
    "     the necrotic and non-enhancing tumor core (NCR/NET — label 1)\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    def __call__(self, data):\n",
    "        d = dict(data)\n",
    "        for key in self.keys:\n",
    "            result = []\n",
    "            \n",
    "            d[key]=np.squeeze(d[key], axis = 0) # Converting 1, H, W, D to H, W, D\n",
    "            result.append(d[key])\n",
    "\n",
    "            # merge labels 1, 2 and 4 to construct WT\n",
    "            result.append(\n",
    "                np.logical_or(\n",
    "                    np.logical_or(d[key] == 2, d[key] == 4), d[key] == 1\n",
    "                )\n",
    "            )\n",
    "            ## merge label 1 and label 4 to construct TC\n",
    "            #result.append(np.logical_or(d[key] == 1, d[key] == 4))\n",
    "            ## label 4 is ET\n",
    "            #result.append(d[key] == 4)\n",
    "            d[key] = np.stack(result, axis=0).astype(np.uint8)\n",
    "        return d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3ae723",
   "metadata": {},
   "source": [
    "#### Define a new transform to convert brain tumor labels\n",
    "Here we convert the multi-classes labels into multi-labels segmentation task in One-Hot format.\\\n",
    "Not using here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f22121fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvertToMultiChannelBasedOnBratsClassesd(MapTransform):\n",
    "    \n",
    "    \"\"\"\n",
    "     GD-enhancing tumor (ET — label 4), \n",
    "     the peritumoral edema (ED — label 2), and \n",
    "     the necrotic and non-enhancing tumor core (NCR/NET — label 1)\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    def __call__(self, data):\n",
    "        d = dict(data)\n",
    "        for key in self.keys:\n",
    "            result = []\n",
    "            \n",
    "            d[key]=np.squeeze(d[key], axis = 0) # Converting 1, H, W, D to H, W, D\n",
    "\n",
    "            # merge labels 1, 2 and 4 to construct WT\n",
    "            result.append(\n",
    "                np.logical_or(\n",
    "                    np.logical_or(d[key] == 2, d[key] == 4), d[key] == 1\n",
    "                )\n",
    "            )\n",
    "            # merge label 1 and label 4 to construct TC\n",
    "            result.append(np.logical_or(d[key] == 1, d[key] == 4))\n",
    "            # label 4 is ET\n",
    "            result.append(d[key] == 4)\n",
    "            d[key] = np.stack(result, axis=0).astype(np.float32)\n",
    "        return d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38a4712",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b18a678",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvertToIDHLabel2WTd(MapTransform):\n",
    "    \n",
    "    \"\"\"\n",
    "     GD-enhancing tumor (ET — label 4), \n",
    "     the peritumoral edema (ED — label 2), and \n",
    "     the necrotic and non-enhancing tumor core (NCR/NET — label 1)\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, keys: KeysCollection, IDH_label_key:str = 'IDH_label') -> None:\n",
    "\n",
    "        super().__init__(keys)\n",
    "        self.IDH_label_key = IDH_label_key\n",
    "       \n",
    "    def __call__(self, data):\n",
    "        d = dict(data)\n",
    "        for key in self.keys:\n",
    "            # merge labels 1, 2 and 4 to construct WT\n",
    "            #WT = np.logical_or(np.logical_or(d[key] == 2, d[key] == 4), d[key] == 1).astype(np.uint8)\n",
    "            result = []\n",
    "            WT = np.squeeze(d[key], axis = 0)\n",
    "            if d[self.IDH_label_key].item() == 1:\n",
    "                WT=np.multiply(WT, 2)\n",
    "                #WT = 2*WT\n",
    "            \n",
    "            result.append(WT==1)\n",
    "            result.append(WT==2)\n",
    "            \n",
    "            d[key] = np.stack(result, axis = 0).astype(np.float32)\n",
    "            \n",
    "    \n",
    "        return d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e5e568",
   "metadata": {},
   "source": [
    "#### A class to add new key having the tumor mask (GT) to the existing data dictionary\n",
    "The new key, ***label_mask*** will have the same dimension (size: 4,x,x,x) with image array (size: 4,x,x,x)\\\n",
    "Using in ***compose*** class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1a7b753",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convert2WTd(MapTransform):\n",
    "    \n",
    "    \"\"\"\n",
    "     GD-enhancing tumor (ET — label 4), \n",
    "     the peritumoral edema (ED — label 2), and \n",
    "     the necrotic and non-enhancing tumor core (NCR/NET — label 1)\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    def __call__(self, data):\n",
    "        d = dict(data)\n",
    "        for key in self.keys:\n",
    "            result = []\n",
    "            output_classes = 2\n",
    "            \n",
    "            # merge labels 1, 2 and 4 to construct WT\n",
    "            WT = np.logical_or(np.logical_or(d[key] == 2, d[key] == 4), d[key] == 1).astype(np.float32)\n",
    "            d[f'{key}'] = WT\n",
    "         \n",
    "            WT = np.expand_dims(ndimage.binary_dilation(np.squeeze(WT, axis=0), iterations=2), axis = 0)\n",
    "            #WT = np.stack(tuple([ndimage.binary_dilation((np.squeeze(WT, axis = 0)==_k).astype(WT.dtype), iterations=5).astype(WT.dtype) for _k in range(output_classes)]), axis = 0)\n",
    "            d[f'{key}_mask'] = WT\n",
    "            d[f'{key}_mask_meta_dict'] = copy.deepcopy(d[f\"{key}_meta_dict\"])\n",
    "            \n",
    "        \n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e22b05eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatialCropWTCOMd(MapTransform):\n",
    "    \n",
    "    \"\"\"\n",
    "     GD-enhancing tumor (ET — label 4), \n",
    "     the peritumoral edema (ED — label 2), and \n",
    "     the necrotic and non-enhancing tumor core (NCR/NET — label 1)\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, keys: KeysCollection, roi_size, COM_label_key:str = 'label_mask') -> None:\n",
    "\n",
    "        super().__init__(keys)\n",
    "        self.COM_label_key = COM_label_key\n",
    "        self.roi_size = roi_size\n",
    "    \n",
    "    def __call__(self, data):\n",
    "        d = dict(data)\n",
    "        for key in self.keys:\n",
    "            result = []\n",
    "            Coms = np.array([ndimage.measurements.center_of_mass(lbl) for lbl in list(d[self.COM_label_key])])\n",
    "            Coms[np.isnan(Coms)] = 70\n",
    "            Coms=Coms[0].astype(np.uint16).tolist()\n",
    "        \n",
    "            sc_com= SpatialCrop(roi_center= Coms, roi_size=self.roi_size)\n",
    "            d[key] = sc_com(d[key])\n",
    "                \n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53333788",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConcatLabelBrainmaskd(MapTransform):\n",
    "    \"\"\"\n",
    "          we do not need labels as it is a generative problem\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, keys: KeysCollection, image_key = 'image', label_key = 'label', \n",
    "                 brain_mask_key = 'brain_mask') -> None:\n",
    "        \n",
    "        super().__init__(keys)\n",
    "        self.brain_mask_key = brain_mask_key\n",
    "        self.image_key = image_key\n",
    "        self.label_key = label_key\n",
    "    \n",
    "    \n",
    "    def __call__(self, data):\n",
    "     \n",
    "        d = dict(data)\n",
    "        #d[self.image_key] = np.concatenate((d[self.image_key], d[self.label_key], d[self.brain_mask_key][0:1]), axis = 0)\n",
    "        d[self.image_key] = np.concatenate((d[self.image_key], d[self.label_key][0:1]), axis = 0)\n",
    "        \n",
    "        return d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56b53e5",
   "metadata": {},
   "source": [
    "### Implementing channelwise histogram normalization\n",
    "(Not using here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "685aa101",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HistogramNormalizeChannelWised(MapTransform):\n",
    "    \"\"\"\n",
    "          we do not need labels as it is a generative problem\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, keys: KeysCollection, brain_mask_key = 'brain_mask', min=0, max=255) -> None:\n",
    "        \n",
    "        super().__init__(keys)\n",
    "        self.brain_mask_key = brain_mask_key\n",
    "        self.histnorms = HistogramNormalize(num_bins=256, min=min, max=max)\n",
    "    \n",
    "    \n",
    "    def __call__(self, data):\n",
    "     \n",
    "        d = dict(data)\n",
    "        for key in self.keys:\n",
    "            nchnl = d[key].shape[0]\n",
    "            for ch in range(nchnl):\n",
    "                d[key][ch] = self.histnorms(d[key][ch], d[self.brain_mask_key][ch])\n",
    "        \n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bfb8c06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class adapter_tio2monai(MapTransform):\n",
    "    \"\"\"\n",
    "    # wrapper for tio affine transformation\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        #keys: KeysCollection,\n",
    "        mode = 'train',\n",
    "        tiofn=None,\n",
    "        **mykwargs,\n",
    "    ) -> None:\n",
    "        \n",
    "        \"\"\"\n",
    "           Wrapper from torchio to monai\n",
    "        \"\"\"\n",
    "        \n",
    "        #super().__init__(keys)\n",
    "        #super().__init__(**mykwargs)\n",
    "        self.tiofn = tiofn(**mykwargs)\n",
    "        self.mode = mode\n",
    "        self.mykwargs = mykwargs\n",
    "        \n",
    "    \n",
    "    def __call__(self, data: Mapping[Hashable, np.ndarray]) -> Dict[Hashable, np.ndarray]:\n",
    "        d = dict(data)\n",
    "        \n",
    "        if self.mode =='train':\n",
    "            subject = tio.Subject(\n",
    "                image=tio.ScalarImage(tensor=d[\"image\"], affine = d['image_meta_dict']['affine']),  # this class is new\n",
    "                label=tio.LabelMap(tensor=d[\"label\"], affine = d['label_meta_dict']['affine']),\n",
    "                brain_mask = tio.LabelMap(tensor=d[\"brain_mask\"], affine = d['brain_mask_meta_dict']['affine'])\n",
    "            )\n",
    "            transformed = self.tiofn(subject)\n",
    "            d[\"image\"] = transformed[\"image\"].numpy()\n",
    "            d[\"label\"] = transformed[\"label\"].numpy()\n",
    "            d[\"brain_mask\"] = transformed[\"brain_mask\"].numpy()\n",
    "            d[\"image_meta_dict\"]['affine'] = transformed[\"image\"].affine.copy()\n",
    "            d[\"label_meta_dict\"]['affine'] = transformed[\"label\"].affine.copy()\n",
    "            d[\"brain_mask_meta_dict\"]['affine'] = transformed[\"brain_mask\"].affine.copy()\n",
    "            \n",
    "            \n",
    "        elif self.mode =='infer':\n",
    "            \n",
    "            subject = tio.Subject(\n",
    "                image=tio.ScalarImage(tensor=d[\"image\"], affine = d['image_meta_dict']['affine']),  # this class is new\n",
    "                brain_mask = tio.LabelMap(tensor=d[\"brain_mask\"], affine = d['brain_mask_meta_dict']['affine'])\n",
    "            )\n",
    "            \n",
    "            transformed = self.tiofn(subject)\n",
    "            d[\"image\"] = transformed[\"image\"].numpy()\n",
    "            d[\"brain_mask\"] = transformed[\"brain_mask\"].numpy()\n",
    "            d[\"image_meta_dict\"]['affine'] = transformed[\"image\"].affine.copy()\n",
    "            d[\"brain_mask_meta_dict\"]['affine'] = transformed[\"brain_mask\"].affine.copy()\n",
    "        \n",
    "        else:\n",
    "            print('Please select mode either train or infer')\n",
    "\n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ea6ddf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class adapter_tioChannelWise2monai(MapTransform):\n",
    "    \"\"\"\n",
    "    # wrapper for tio affine transformation\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        #keys: KeysCollection,\n",
    "        mode = 'train',\n",
    "        tiofn=None,\n",
    "        **mykwargs,\n",
    "    ) -> None:\n",
    "        \n",
    "        \"\"\"\n",
    "           Wrapper from torchio to monai\n",
    "        \"\"\"\n",
    "        \n",
    "        #super().__init__(keys)\n",
    "        #super().__init__(**mykwargs)\n",
    "        self.tiofn = tiofn(**mykwargs)\n",
    "        self.mode = mode\n",
    "        self.mykwargs = mykwargs\n",
    "        \n",
    "    \n",
    "    def __call__(self, data: Mapping[Hashable, np.ndarray]) -> Dict[Hashable, np.ndarray]:\n",
    "        d = dict(data)\n",
    "        if self.mode =='train':\n",
    "            subject = tio.Subject(\n",
    "               \n",
    "                t1cw=tio.ScalarImage(tensor=d[\"image\"][0:1,...], affine = d['image_meta_dict']['affine']),\n",
    "                t2w=tio.ScalarImage(tensor=d[\"image\"][1:2,...], affine = d['image_meta_dict']['affine']),\n",
    "               \n",
    "                label=tio.LabelMap(tensor=d[\"label\"], affine = d['label_meta_dict']['affine']),\n",
    "                brain_mask = tio.LabelMap(tensor=d[\"brain_mask\"], affine = d['brain_mask_meta_dict']['affine'])\n",
    "            )\n",
    "            transformed = self.tiofn(subject)\n",
    "            d[\"image\"] = np.concatenate([transformed[\"t1cw\"].numpy(), transformed[\"t2w\"].numpy()], axis = 0)\n",
    "            d[\"label\"] = transformed[\"label\"].numpy()\n",
    "            d[\"brain_mask\"] = transformed[\"brain_mask\"].numpy()\n",
    "            d[\"image_meta_dict\"]['affine'] = transformed[\"t1cw\"].affine.copy()\n",
    "            d[\"label_meta_dict\"]['affine'] = transformed[\"label\"].affine.copy()\n",
    "            d[\"brain_mask_meta_dict\"]['affine'] = transformed[\"brain_mask\"].affine.copy()\n",
    "            \n",
    "        \n",
    "        elif self.mode =='infer':\n",
    "            \n",
    "            subject = tio.Subject(\n",
    "                t1cw=tio.ScalarImage(tensor=d[\"image\"][0:1,...], affine = d['image_meta_dict']['affine']),\n",
    "                t2w=tio.ScalarImage(tensor=d[\"image\"][1:2,...], affine = d['image_meta_dict']['affine']),\n",
    "                brain_mask = tio.LabelMap(tensor=d[\"brain_mask\"], affine = d['brain_mask_meta_dict']['affine'])\n",
    "            )\n",
    "            \n",
    "            transformed = self.tiofn(subject)\n",
    "            d[\"image\"] = np.concatenate([transformed[\"t1cw\"].numpy(), transformed[\"t2w\"].numpy()], axis = 0)\n",
    "    \n",
    "            d[\"brain_mask\"] = transformed[\"brain_mask\"].numpy()\n",
    "            d[\"image_meta_dict\"]['affine'] = transformed[\"t1cw\"].affine.copy()\n",
    "            d[\"brain_mask_meta_dict\"]['affine'] = transformed[\"brain_mask\"].affine.copy()\n",
    "        \n",
    "        else:\n",
    "            print('Please select mode either train or infer')\n",
    "\n",
    "        return d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89055c6d",
   "metadata": {},
   "source": [
    "### Defining traning and validation transforms\n",
    "\n",
    "- Training transform includes:\n",
    "    - LoadImaged\n",
    "    - EnsureChannelFirstd\n",
    "    - HistogramNormalizeChannelWised: Histogram normalization channel wise (custom class defined aboove)\n",
    "    - NormalizeIntensityd\n",
    "    - RandRotate90d\n",
    "    - RandZoomd\n",
    "    - ConvertToIDHLabel2WTd (custom class defined above)\n",
    "    - CropForegroundd: Cropping foreground based on the whole tumor mask (WT GT)\n",
    "    - RandCropByPosNegLabeld: Randomly cropping 8 patches based on 3: 1 (WT : non tumor tissus) ratio\n",
    "    - RandGaussianNoised\n",
    "    - RandStdShiftIntensityd\n",
    "    - RandFlipd\n",
    "    \n",
    "- validation transform includes:\n",
    "    - LoadImaged\n",
    "    - EnsureChannelFirstd\n",
    "    - HistogramNormalizeChannelWised: Histogram normalization channel wise (custom class defined aboove)\n",
    "    - NormalizeIntensityd\n",
    "    - ConvertToIDHLabel2WTd (custom class defined above)\n",
    "    \n",
    "Most of transfroms are implemented using [Monai](https://docs.monai.io/en/latest/transforms.html#dictionary-transforms) library\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64eed214",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "52491dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_foreground(x):\n",
    "    # threshold at not equal to 0\n",
    "    return x == 1\n",
    "\n",
    "\n",
    "#Resized(keys=keys[0:-1], spatial_size=patch_size, mode = ('area','nearest','nearest')),\n",
    "\n",
    "# ConvertToMultiChannelBasedOnBratsClassesd(keys = ['label']),\n",
    "# ConcatLabelBrainmaskd(keys = None, image_key = 'image', label_key = 'label', brain_mask_key = 'brain_mask'),\n",
    "# CropForegroundd(keys=keys[0:-1], source_key=\"brain_mask\", select_fn = threshold_foreground, start_coord_key='fg_start_coord', end_coord_key='fg_end_coord'),\n",
    "# SpatialPadd(keys=keys[0:-1], spatial_size=patch_size),\n",
    "\n",
    "# RandGaussianSmoothd(\n",
    "#     keys=[\"image\"],\n",
    "#     sigma_x=(0.5, 1.15),\n",
    "#     sigma_y=(0.5, 1.15),\n",
    "#     sigma_z=(0.5, 1.15),\n",
    "#     prob=0.3,\n",
    "# ),\n",
    "\n",
    "# RandScaleIntensityd(keys=[\"image\"], factors=0.3, prob=0.3),\n",
    "# RandGibbsNoised(keys=[\"image\"], prob=0.3, alpha=(0.1, 0.5), as_tensor_output=False),\n",
    "\n",
    "          \n",
    "# DataStatsd(keys=keys[0:-1], prefix=\"Data\", data_type=True, data_shape=True, value_range=True, data_value=False),\n",
    "#DataStatsd(keys=keysExt[0:-1], prefix=\"Data\", data_type=True, data_shape=True, value_range=True, data_value=False),\n",
    "\n",
    "\n",
    "def get_task_transforms(patch_size, task='train', pos_sample_num=1, neg_sample_num=1, num_samples=1, num_classes = 2, cratio = [1, 3]):\n",
    "    \n",
    "    #spatial_size=(30, 30, 30)\n",
    "    orig_img_size = (240, 240, 155)\n",
    "\n",
    "    if task=='train':\n",
    "        keys = [\"image\", 'label', 'brain_mask', 'IDH_label']\n",
    "        keysExt = [\"image\", 'label', 'brain_mask', 'label_mask', 'IDH_label']\n",
    "        \n",
    "        all_transform = [\n",
    "            \n",
    "            LoadImaged(keys=keys[0:-1], reader = \"NibabelReader\"),\n",
    "            EnsureChannelFirstd(keys=keys[0:-1]),\n",
    "            adapter_tioChannelWise2monai(tiofn = tio.HistogramStandardization, mode = 'train', landmarks = landmarks_dict),\n",
    "            NormalizeIntensityd(keys=[\"image\"], nonzero=True, channel_wise=True),\n",
    "            #HistogramNormalizeChannelWised(keys = ['image'], brain_mask_key = 'brain_mask', min = 1, max = 65535),\n",
    "            \n",
    "            adapter_tio2monai(tiofn = tio.OneOf, transforms={tio.RandomAffine(scales=(0.9, 1.2),degrees=15, isotropic=True): 0.6, \\\n",
    "                                            tio.RandomElasticDeformation(): 0.4}, p = 0.4), #p = 0.4\n",
    "            #adapter_tio2monai(tiofn = tio.RandomAffine, scales=(0.9, 1.2), degrees=15, isotropic=True, p = 0.2), \n",
    "            \n",
    "\n",
    "            \n",
    "            #ConvertToIDHLabel2WTd(keys = [\"label\"]),\n",
    "            CopyItemsd(keys=[\"label\"], names=[\"label_mask\"], times=1),\n",
    "            Convert2WTd(keys = [\"label\"]),\n",
    "            ConvertToIDHLabel2WTd(keys = [\"label\"], IDH_label_key = 'IDH_label'),\n",
    "            CropForegroundd(keys=keysExt[0:-1], source_key=\"brain_mask\", select_fn = threshold_foreground, start_coord_key='fg_start_coord', end_coord_key='fg_end_coord'),\n",
    "            #Spacingd(keys = keysExt[0:-1], pixdim=(1.25, 1.25, 1.25), mode = ('bilinear','nearest', 'nearest', 'nearest')),\n",
    "            RandZoomd(\n",
    "                keys=keysExt[0:-1],\n",
    "                min_zoom=0.9,\n",
    "                max_zoom=1.1,\n",
    "                mode=(\"trilinear\", \"nearest\", \"nearest\", \"nearest\"),\n",
    "                align_corners=(True, None, None, None),\n",
    "                prob=0.15,\n",
    "            ),\n",
    "           \n",
    "            #ResizeWithPadOrCropd(keys = keysExt[0:-1], spatial_size = (128, 160, 128)),\n",
    "            RandGaussianNoised(keys=[\"image\"], std=0.01, prob=0.15),\n",
    "            RandGaussianSmoothd(\n",
    "                keys=[\"image\"],\n",
    "                sigma_x=(0.5, 1.15),\n",
    "                sigma_y=(0.5, 1.15),\n",
    "                sigma_z=(0.5, 1.15),\n",
    "                prob=0.15,\n",
    "            ),\n",
    "            RandStdShiftIntensityd(keys = [\"image\"], factors=0.3, nonzero=True, channel_wise=True, prob=0.15), \n",
    "            RandScaleIntensityd(keys=[\"image\"], factors=0.3, prob=0.15),\n",
    "            RandGibbsNoised(keys=[\"image\"], prob=0.15, alpha=(0.1, 0.5), as_tensor_output=False),\n",
    "            RandFlipd(keys=keysExt[0:-1], prob=0.5, spatial_axis=0),\n",
    "            RandFlipd(keys=keysExt[0:-1], prob=0.5, spatial_axis=1),\n",
    "            RandFlipd(keys=keysExt[0:-1], prob=0.5, spatial_axis=2),\n",
    "                        \n",
    "            CropForegroundd(keys=keysExt[0:-1], source_key=\"label_mask\", select_fn = threshold_foreground, start_coord_key='fg_start_coord', end_coord_key='fg_end_coord', margin=2),\n",
    "            #ResizeWithPadOrCropd(keys = keysExt[0:-1], spatial_size = patch_size),\n",
    "            SpatialPadd(keys = keysExt[0:-1], spatial_size = patch_size),\n",
    "#             RandCropByLabelClassesd(\n",
    "#                 keys=keysExt[0:-1],            \n",
    "#                 label_key = \"label_mask\",\n",
    "#                 spatial_size = patch_size,    \n",
    "#                 ratios= cratio,\n",
    "#                 num_classes=num_classes,              \n",
    "#                 num_samples=num_samples,\n",
    "#                 image_key=\"brain_mask\",\n",
    "#                 image_threshold=0.0,\n",
    "#                 #allow_smaller = True,\n",
    "#             ),\n",
    "            \n",
    "            RandCropByPosNegLabeld(\n",
    "                keys=keysExt[0:-1],\n",
    "                label_key=\"label_mask\",\n",
    "                spatial_size=patch_size,\n",
    "                pos=pos_sample_num,\n",
    "                neg=neg_sample_num,\n",
    "                num_samples=num_samples,\n",
    "                image_key=\"brain_mask\",\n",
    "                image_threshold=0.,\n",
    "            ),\n",
    "                        \n",
    "            #SpatialCropWTCOMd(keys=keysExt[0:-1], roi_size=patch_size, COM_label_key = \"label_mask\"),\n",
    "            SpatialPadd(keys = keysExt[0:-1], spatial_size = patch_size),\n",
    "        \n",
    "            #CastToTyped(keys=keysExt, dtype=(np.float32, np.uint8, np.uint8, np.uint8, np.float32)),\n",
    "            CastToTyped(keys=keysExt, dtype=(np.float32, np.float32, np.float32, np.float32, np.float32)),\n",
    "            #dtype = (torch.float32, torch.float32, torch.float32, torch.float32, torch.float32)\n",
    "            #ToTensord(keys=keysExt),\n",
    "\n",
    "#             #EnsureTyped(keys=keys, data_type = \"tensor\"),\n",
    "#             #ToDeviced(keys = keys, device = deviceName),\n",
    "        ]\n",
    "        \n",
    "        \n",
    "        \n",
    "    elif task=='validation':\n",
    "    \n",
    "        keys = [\"image\", 'label', 'brain_mask', 'IDH_label']\n",
    "        keysExt = [\"image\", 'label', 'brain_mask', 'label_mask', 'IDH_label']\n",
    "        all_transform = [\n",
    "            \n",
    "            LoadImaged(keys=keys[0:-1], reader = \"NibabelReader\"),\n",
    "            EnsureChannelFirstd(keys=keys[0:-1]),\n",
    "            adapter_tioChannelWise2monai(tiofn = tio.HistogramStandardization, mode = 'train', landmarks = landmarks_dict),\n",
    "            #HistogramNormalizeChannelWised(keys = ['image'], brain_mask_key = 'brain_mask', min = 1, max = 65535),\n",
    "            NormalizeIntensityd(keys=[\"image\"], nonzero=True, channel_wise=True),\n",
    "            #ConvertToIDHLabel2WTd(keys = [\"label\"]),\n",
    "           \n",
    "            CopyItemsd(keys=[\"label\"], names=[\"label_mask\"], times=1),\n",
    "            Convert2WTd(keys = [\"label\"]),\n",
    "            ConvertToIDHLabel2WTd(keys = [\"label\"], IDH_label_key = 'IDH_label'),\n",
    "            CropForegroundd(keys=keysExt[0:-1], source_key=\"brain_mask\", select_fn = threshold_foreground, start_coord_key='fg_start_coord', end_coord_key='fg_end_coord'),\n",
    "            \n",
    "            #Spacingd(keys = keysExt[0:-1], pixdim=(1.25, 1.25, 1.25), mode = ('bilinear','nearest', 'nearest', 'nearest')),\n",
    "            #ResizeWithPadOrCropd(keys = keysExt[0:-1], spatial_size = (128, 160, 128)),\n",
    "            CropForegroundd(keys=keysExt[0:-1], source_key=\"label_mask\", select_fn = threshold_foreground, start_coord_key='fg_start_coord', end_coord_key='fg_end_coord', margin=2), \n",
    "            #SpatialCropWTCOMd(keys=keysExt[0:-1], roi_size=patch_size, COM_label_key = \"label_mask\"),\n",
    "            SpatialPadd(keys = keysExt[0:-1], spatial_size = patch_size),\n",
    "#             RandCropByPosNegLabeld(\n",
    "#                 keys=keysExt[0:-1],\n",
    "#                 label_key=\"label_mask\",\n",
    "#                 spatial_size=patch_size,\n",
    "#                 pos=pos_sample_num,\n",
    "#                 neg=neg_sample_num,\n",
    "#                 num_samples=num_samples,\n",
    "#                 image_key=\"brain_mask\",\n",
    "#                 image_threshold=0,\n",
    "#             ),\n",
    "        \n",
    "#             RandCropByLabelClassesd(\n",
    "#                 keys=keysExt[0:-1],            \n",
    "#                 label_key = \"label_mask\",\n",
    "#                 spatial_size = patch_size,    \n",
    "#                 ratios= cratio,\n",
    "#                 num_classes=num_classes,              \n",
    "#                 num_samples=num_samples,\n",
    "#                 image_key=\"brain_mask\",\n",
    "#                 image_threshold=0.0,\n",
    "#                 #allow_smaller = True,\n",
    "#             ),\n",
    "\n",
    "            #CastToTyped(keys=keysExt, dtype=(np.float32, np.uint8, np.uint8, np.uint8, np.float32)),\n",
    "            CastToTyped(keys=keysExt, dtype=(np.float32, np.float32, np.float32, np.float32, np.float32)),\n",
    "            #ToTensord(keys=keysExt, dtype=(torch.float32, torch.float32, torch.float32, torch.float32, torch.float32)),\n",
    "            #EnsureTyped(keys=keys, data_type = \"tensor\"),\n",
    "            #ToDeviced(keys = keys, device = deviceName),\n",
    "        ]\n",
    "        \n",
    "    else:\n",
    "        print('print task either train or validation here')\n",
    "\n",
    "\n",
    "    return Compose(all_transform)\n",
    "\n",
    "# def create_cachedir(cache_dir):\n",
    "#     if not os.path.exists(cache_dir):\n",
    "#         os.makedirs(cache_dir)\n",
    "#     return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3390837",
   "metadata": {},
   "source": [
    "### Section for visual inspection and debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c12cef88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23, 11)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#patch_size=(128, 160, 128)\n",
    "#patch_size=(64, 80, 64)\n",
    "patch_size=(32, 32, 32)\n",
    "train_transforms = get_task_transforms(patch_size, task='train', pos_sample_num=3, neg_sample_num=1, num_samples=16, cratio = [1, 3])\n",
    "val_transforms = get_task_transforms(patch_size, task='validation', pos_sample_num=1, neg_sample_num=1, num_samples=1, cratio = [1, 3])\n",
    "len(train_transforms), len(val_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e217b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7fc79608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# investi_files = BraTS20SubjectsIDHTrainDCT['fold0']\n",
    "# all_train_dataset = monai.data.Dataset(data=investi_files, transform=train_transforms)\n",
    "# all_train_dataset[0][0]['label_meta_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4d0980c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub_patch = all_train_dataset[15][3]\n",
    "# view(image = sub_patch['image'][0], label_image = sub_patch['label_mask'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03499f27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "77f79282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vpatch = all_train_dataset[0][14]\n",
    "# view(image = vpatch['image'][1], label_image = vpatch['label'][1])\n",
    "\n",
    "\n",
    "#np.unique(all_train_dataset[0]['label'][1], return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c168aae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#view(image = vpatch['image'][1], label_image = vpatch['label_mask'][0])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "73fcc680",
   "metadata": {},
   "source": [
    "investi_files = BraTS20SubjectsIDHTrainDCT['fold0']\n",
    "#all_train_dataset = Dataset(data=investi_files, transform=val_transforms)\n",
    "all_train_dataset = monai.data.Dataset(data=investi_files, transform=train_transforms)\n",
    "print(all_train_dataset[0][0]['image'].shape)\n",
    "for kj in all_train_dataset:\n",
    "    #asub = kj\n",
    "    num_samples=15\n",
    "    pindx = random.choice(np.arange(num_samples, dtype = np.uint8))\n",
    "    kj = kj[pindx]\n",
    "    print('IDH_label:', kj['IDH_label'])\n",
    "    #print(kj['label'].shape, kj['label'].unique(return_counts = True))\n",
    "    #print(kj['label_mask'].shape, kj['label_mask'].unique(return_counts = True))\n",
    "    print(kj['label'].shape, np.unique(kj['label'], return_counts = True))\n",
    "    print(kj['label_mask'].shape, np.unique(kj['label_mask'], return_counts = True))\n",
    "    #unque = kj['label_mask'].unique(return_counts = True)[1]\n",
    "    #print('\\n Background ratio:', unque[0]/unque.sum(), ' Tumor(=1): ',  unque[1]/unque.sum())\n",
    "    print('#'*100)\n",
    "#print(asub['image'].shape)\n",
    "# print(asub['image'][0].min(),asub['image'][0].max(), asub['image'][0].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4329a3bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b79de6d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#investifiles = copy.deepcopy(BraTS20SubjectsIDHTrainDCT[\"fold0\"])\n",
    "\n",
    "# for i in range(len(investifiles)):\n",
    "#     investifiles[i]['IDH_label'] = investifiles[i]['IDH_label'].astype(np.float32) \n",
    "# all_train_dataset = monai.data.Dataset(data=investifiles, transform=train_transforms)\n",
    "#all_train_dataset[10][3]['IDH_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "13f38f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for cfold in tqdm(range(len(BraTS20SubjectsIDHTrainDCT))):\n",
    "#     all_train_dataset = monai.data.Dataset(data=copy.deepcopy(BraTS20SubjectsIDHTrainDCT[f\"fold{cfold}\"]), transform=train_transforms)\n",
    "#     dls = monai.data.DataLoader(all_train_dataset, batch_size=8, shuffle=False, collate_fn=list_data_collate)\n",
    "#     # abatch = next(iter(dls))\n",
    "#     # print(abatch['image'].shape)\n",
    "#     # print(abatch['label'].shape)\n",
    "#     for epoch in range(5):\n",
    "#         for abatch in dls:\n",
    "#             print(abatch['image'].shape)\n",
    "#             print(abatch['label'].shape)\n",
    "#             print(abatch['IDH_label'].shape)\n",
    "#             print(abatch['IDH_label'], '\\n', '###'*10, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8974b75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7679a0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#few_train_dataset = Dataset(data=train_files[0:10], transform=train_transforms)\n",
    "# asub = few_train_dataset[5] \n",
    "# view(image = asub['image'][3].cpu(), label_image = asub['label_mask'][0].cpu())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8cb10f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed2c319c",
   "metadata": {},
   "source": [
    "### Few investigation"
   ]
  },
  {
   "cell_type": "raw",
   "id": "88eca9e1",
   "metadata": {},
   "source": [
    "afold_train_dataset = monai.data.Dataset(data=BraTS20SubjectsIDHTrainDCT['fold0'], transform=train_transforms)\n",
    "#train_folds['fold0_IDH_label']\n",
    "i_cv = 2\n",
    "uval, ucnt = np.unique([BraTS20SubjectsIDHTrainDCT[f'fold{i_cv}'][i]['IDH_label'].item() for i in range(len(BraTS20SubjectsIDHTrainDCT[f'fold{i_cv}']))], return_counts = True)\n",
    "weight = 1./(ucnt/ucnt.min())\n",
    "#weight = np.array([0.55, 0.45])\n",
    "sample_weights = np.array([weight[int(t)] for t in [BraTS20SubjectsIDHTrainDCT[f'fold{i_cv}'][i]['IDH_label'].item() for i in range(len(BraTS20SubjectsIDHTrainDCT[f'fold{i_cv}']))]])\n",
    "sample_weights = torch.from_numpy(sample_weights)\n",
    "weight, ucnt, sample_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891e1b26",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b3b0f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a86c150f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#afold_train_dataset[200]['IDH_label'], afold_train_dataset[200]['label'].unique(return_counts = True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "33f73ddb",
   "metadata": {},
   "source": [
    "#sampler = WeightedRandomSampler(sample_weights, num_samples= len(samples_weight))\n",
    "sampler = WeightedRandomSampler(sample_weights, num_samples= len(sample_weights), replacement=True)\n",
    "\n",
    "afold_train_loader = monai.data.DataLoader(afold_train_dataset, batch_size=32, sampler=sampler)\n",
    "#afold_train_loader = torch.utils.data.DataLoader(afold_train_dataset, batch_size=32, sampler=sampler)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cfccd27f",
   "metadata": {},
   "source": [
    "for ibatch in afold_train_loader:\n",
    "    ibatch_IDH = ibatch['IDH_label']\n",
    "    print(torch.eq(ibatch_IDH, 0).sum(), torch.eq(ibatch_IDH, 1).sum())\n",
    "    print('#'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aee8a03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e8f041",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eaf79cff",
   "metadata": {},
   "source": [
    "## Defining model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5d7991d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownBasicBlock(nn.Module):\n",
    "\n",
    "        \n",
    "    def __init__(self, input_channels, output_channels,\n",
    "         conv_op=nn.Conv3d, conv_kwargs=None,\n",
    "         norm_op=nn.BatchNorm3d, norm_op_kwargs=None,\n",
    "         dropout_op=nn.Dropout3d, dropout_op_kwargs=None,\n",
    "         nonlin=nn.LeakyReLU, nonlin_kwargs=None):\n",
    "        super(DownBasicBlock, self).__init__()\n",
    "        \n",
    "        if nonlin_kwargs is None:\n",
    "            nonlin_kwargs = {'negative_slope': 1e-2, 'inplace': True}\n",
    "        if dropout_op_kwargs is None:\n",
    "            dropout_op_kwargs = {'p': 0.0, 'inplace': True}\n",
    "        if norm_op_kwargs is None:\n",
    "            norm_op_kwargs = {'eps': 1e-5, 'affine': True, 'momentum': 0.1}\n",
    "        if conv_kwargs is None:\n",
    "            conv_kwargs3x3_0 = {'kernel_size': 3, 'stride': 2, 'padding': 1, 'dilation': 1, 'bias': True}\n",
    "            conv_kwargs3x3_1 = {'kernel_size': 3, 'stride': 1, 'padding': 1, 'dilation': 1, 'bias': True}\n",
    "        else:\n",
    "            conv_kwargs3x3_0 = conv_kwargs\n",
    "            conv_kwargs3x3_1 = {'kernel_size': 3, 'stride': 1, 'padding': 1, 'dilation': 1, 'bias': True}\n",
    "            \n",
    "            \n",
    "\n",
    "        self.nonlin = nonlin\n",
    "        self.nonlin_kwargs = nonlin_kwargs\n",
    "\n",
    "        self.dropout_op = dropout_op\n",
    "        self.dropout_op_kwargs = dropout_op_kwargs\n",
    "        \n",
    "        self.conv_op = conv_op\n",
    "        self.conv_kwargs3x3_0 = conv_kwargs3x3_0\n",
    "        self.conv_kwargs3x3_1 = conv_kwargs3x3_1\n",
    "        self.conv_kwargs1x1 = {'kernel_size': 1, 'stride': 1, 'padding': 0, 'dilation': 1, 'bias': True}\n",
    "        \n",
    "        self.norm_op = norm_op\n",
    "        self.norm_op_kwargs = norm_op_kwargs\n",
    "        \n",
    "        \n",
    "\n",
    "        self.conv3x3_0 = self.conv_op(input_channels, output_channels, **self.conv_kwargs3x3_0)\n",
    "        self.instnorm3x3_0 = self.norm_op(output_channels, **self.norm_op_kwargs)\n",
    "        \n",
    "        self.conv3x3_1 = self.conv_op(output_channels, output_channels, **self.conv_kwargs3x3_1)\n",
    "        self.instnorm3x3_1 = self.norm_op(output_channels, **self.norm_op_kwargs)\n",
    "        \n",
    "        #self.conv1x1 = self.conv_op(input_channels, output_channels, **self.conv_kwargs1x1)\n",
    "        #self.instnorm1x1 = self.norm_op(output_channels, **self.norm_op_kwargs)\n",
    "        \n",
    "        if self.dropout_op is not None and self.dropout_op_kwargs['p'] is not None and self.dropout_op_kwargs['p'] > 0:\n",
    "            self.dropout = self.dropout_op(**self.dropout_op_kwargs)\n",
    "        else:\n",
    "            self.dropout = None\n",
    "        \n",
    "        self.lrelu = self.nonlin(**self.nonlin_kwargs)\n",
    "  \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        out = self.conv3x3_0(x)\n",
    "        out = self.instnorm3x3_0(out)\n",
    "        out = self.lrelu(out)\n",
    "\n",
    "        out = self.conv3x3_1(out)\n",
    "        out = self.instnorm3x3_1(out)\n",
    "        out = self.lrelu(out)\n",
    "        #print(out.shape)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2fd92ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpBasicBlock(nn.Module):\n",
    "\n",
    "        \n",
    "    def __init__(self, input_channels, output_channels,\n",
    "         conv_op=nn.Conv3d, conv_kwargs=None,\n",
    "         norm_op=nn.BatchNorm3d, norm_op_kwargs=None,\n",
    "         dropout_op=nn.Dropout3d, dropout_op_kwargs=None,\n",
    "         nonlin=nn.LeakyReLU, nonlin_kwargs=None):\n",
    "        super(UpBasicBlock, self).__init__()\n",
    "        \n",
    "        if nonlin_kwargs is None:\n",
    "            nonlin_kwargs = {'negative_slope': 1e-2, 'inplace': True}\n",
    "        if dropout_op_kwargs is None:\n",
    "            dropout_op_kwargs = {'p': 0.0, 'inplace': True}\n",
    "        if norm_op_kwargs is None:\n",
    "            norm_op_kwargs = {'eps': 1e-5, 'affine': True, 'momentum': 0.1}\n",
    "        if conv_kwargs is None:\n",
    "            conv_kwargs3x3_0 = {'kernel_size': 3, 'stride': 1, 'padding': 1, 'dilation': 1, 'bias': True}\n",
    "            conv_kwargs3x3_1 = {'kernel_size': 3, 'stride': 1, 'padding': 1, 'dilation': 1, 'bias': True}\n",
    "        else:\n",
    "            conv_kwargs3x3_0 = conv_kwargs\n",
    "            conv_kwargs3x3_1 = {'kernel_size': 3, 'stride': 1, 'padding': 1, 'dilation': 1, 'bias': True}\n",
    "            \n",
    "            \n",
    "        \n",
    "\n",
    "        self.nonlin = nonlin\n",
    "        self.nonlin_kwargs = nonlin_kwargs\n",
    "\n",
    "        self.dropout_op = dropout_op\n",
    "        self.dropout_op_kwargs = dropout_op_kwargs\n",
    "        \n",
    "        self.conv_op = conv_op\n",
    "        self.conv_kwargs3x3_0 = conv_kwargs3x3_0\n",
    "        self.conv_kwargs3x3_1 = conv_kwargs3x3_1\n",
    "        self.conv_kwargs1x1 = {'kernel_size': 1, 'stride': 1, 'padding': 0, 'dilation': 1, 'bias': True}\n",
    "        \n",
    "        self.norm_op = norm_op\n",
    "        self.norm_op_kwargs = norm_op_kwargs\n",
    "        \n",
    "        \n",
    "\n",
    "        self.conv3x3_0 = self.conv_op(input_channels, output_channels, **self.conv_kwargs3x3_0)\n",
    "        self.instnorm3x3_0 = self.norm_op(output_channels, **self.norm_op_kwargs)\n",
    "        \n",
    "        self.conv3x3_1 = self.conv_op(output_channels, output_channels, **self.conv_kwargs3x3_1)\n",
    "        self.instnorm3x3_1 = self.norm_op(output_channels, **self.norm_op_kwargs)\n",
    "        \n",
    "        #self.conv1x1 = self.conv_op(input_channels, output_channels, **self.conv_kwargs1x1)\n",
    "        #self.instnorm1x1 = self.norm_op(output_channels, **self.norm_op_kwargs)\n",
    "        \n",
    "        if self.dropout_op is not None and self.dropout_op_kwargs['p'] is not None and self.dropout_op_kwargs['p'] > 0:\n",
    "            self.dropout = self.dropout_op(**self.dropout_op_kwargs)\n",
    "        else:\n",
    "            self.dropout = None\n",
    "        \n",
    "        self.lrelu = self.nonlin(**self.nonlin_kwargs)\n",
    "  \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        out = self.conv3x3_0(x)\n",
    "        out = self.instnorm3x3_0(out)\n",
    "        out = self.lrelu(out)\n",
    "\n",
    "        out = self.conv3x3_1(out)\n",
    "        out = self.instnorm3x3_1(out)\n",
    "        out = self.lrelu(out)\n",
    "        #print(out.shape)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5c02d270",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvDropoutNormNonlin(nn.Module):\n",
    "    \"\"\"\n",
    "    fixes a bug in ConvDropoutNormNonlin where lrelu was used regardless of nonlin. Bad.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_channels, output_channels,\n",
    "                 conv_op=nn.Conv3d, conv_kwargs=None,\n",
    "                 norm_op=nn.BatchNorm3d, norm_op_kwargs=None,\n",
    "                 dropout_op=nn.Dropout3d, dropout_op_kwargs=None,\n",
    "                 nonlin=nn.LeakyReLU, nonlin_kwargs=None):\n",
    "        super(ConvDropoutNormNonlin, self).__init__()\n",
    "        if nonlin_kwargs is None:\n",
    "            nonlin_kwargs = {'negative_slope': 1e-2, 'inplace': True}\n",
    "        if dropout_op_kwargs is None:\n",
    "            dropout_op_kwargs = {'p': 0.0, 'inplace': True}\n",
    "        if norm_op_kwargs is None:\n",
    "            norm_op_kwargs = {'eps': 1e-5, 'affine': True, 'momentum': 0.1}\n",
    "        if conv_kwargs is None:\n",
    "            conv_kwargs = {'kernel_size': 3, 'stride': 1, 'padding': 1, 'dilation': 1, 'bias': True}\n",
    "\n",
    "        self.nonlin_kwargs = nonlin_kwargs\n",
    "        self.nonlin = nonlin\n",
    "        self.dropout_op = dropout_op\n",
    "        self.dropout_op_kwargs = dropout_op_kwargs\n",
    "        self.norm_op_kwargs = norm_op_kwargs\n",
    "        self.conv_kwargs = conv_kwargs\n",
    "        self.conv_op = conv_op\n",
    "        self.norm_op = norm_op\n",
    "\n",
    "        self.conv = self.conv_op(input_channels, output_channels, **self.conv_kwargs)\n",
    "        if self.dropout_op is not None and self.dropout_op_kwargs['p'] is not None and self.dropout_op_kwargs[\n",
    "            'p'] > 0:\n",
    "            self.dropout = self.dropout_op(**self.dropout_op_kwargs)\n",
    "        else:\n",
    "            self.dropout = None\n",
    "        self.instnorm = self.norm_op(output_channels, **self.norm_op_kwargs)\n",
    "        self.lrelu = self.nonlin(**self.nonlin_kwargs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        if self.dropout is not None:\n",
    "            x = self.dropout(x)\n",
    "        return self.lrelu(self.instnorm(x))\n",
    "    \n",
    "\n",
    "class ConvDropoutNonlinNorm(ConvDropoutNormNonlin):\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        if self.dropout is not None:\n",
    "            x = self.dropout(x)\n",
    "        return self.instnorm(self.lrelu(x))\n",
    "\n",
    "\n",
    "class ConvNonlinSeg(nn.Module):\n",
    "    \"\"\"\n",
    "    fixes a bug in ConvDropoutNormNonlin where lrelu was used regardless of nonlin. Bad.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_channels, output_channels,\n",
    "                 conv_op=nn.Conv3d, conv_kwargs=None,\n",
    "                 nonlin=nn.LeakyReLU, nonlin_kwargs=None):\n",
    "        super(ConvNonlinSeg, self).__init__()\n",
    "        if nonlin_kwargs is None:\n",
    "            nonlin_kwargs = {'negative_slope': 1e-2, 'inplace': True}\n",
    "\n",
    "        if conv_kwargs is None:\n",
    "            conv_kwargs = {'kernel_size': 1, 'stride': 1, 'padding': 0, 'dilation': 1, 'bias': False}\n",
    "\n",
    "        self.nonlin_kwargs = nonlin_kwargs\n",
    "        self.nonlin = nonlin\n",
    "        self.conv_kwargs = conv_kwargs\n",
    "        self.conv_op = conv_op\n",
    "\n",
    "\n",
    "        self.conv = self.conv_op(input_channels, output_channels, **self.conv_kwargs)\n",
    "\n",
    "        #self.lrelu = self.nonlin(**self.nonlin_kwargs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        #x = self.conv(self.lrelu(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4aad37a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UEncoder(nn.Module):\n",
    "    def __init__(self, num_input_channels, encodFilters, norm_op=nn.InstanceNorm3d):\n",
    "        super(UEncoder, self).__init__()\n",
    "        \n",
    "        \n",
    "        init_contexts_conv_kwargs = {'kernel_size': 3, 'stride': 1, 'padding': 1, 'dilation': 1, 'bias': True}        \n",
    "                \n",
    "        \"\"\" First block \"\"\"\n",
    "        \n",
    "        self.context0_encod =  DownBasicBlock(num_input_channels, encodFilters[0], conv_kwargs = init_contexts_conv_kwargs, norm_op=norm_op) \n",
    "        \n",
    "        \n",
    "        self.context1_encod =  DownBasicBlock(encodFilters[0], encodFilters[1], norm_op=norm_op) \n",
    "  \n",
    "        \n",
    "        self.context2_encod =  DownBasicBlock(encodFilters[1], encodFilters[2], norm_op=norm_op) \n",
    "             \n",
    "        self.context3_encod =  DownBasicBlock(encodFilters[2], encodFilters[3], norm_op=norm_op) \n",
    "      \n",
    "        self.context4_encod =  DownBasicBlock(encodFilters[3], encodFilters[4], norm_op=norm_op) \n",
    "      \n",
    "        #self.context5_encod =  DownBasicBlock(encodFilters[4], encodFilters[5], norm_op=norm_op)\n",
    "        \n",
    "        #self.context6_encod =  DownBasicBlock(encodFilters[5], encodFilters[6], norm_op=norm_op)\n",
    "        #self.reduced_pool = nn.MaxPool3d(3, stride=2, padding = 1)\n",
    "       \n",
    "                    \n",
    "                                                              \n",
    "    def forward(self, ax):\n",
    "        \n",
    "        ax = self.context0_encod(ax)\n",
    "        axdecod0 = ax\n",
    "        #ax=self.reduced_pool(ax)\n",
    "        \n",
    "    \n",
    "        ax = self.context1_encod(ax)\n",
    "        axdecod1 = ax\n",
    "        #ax=self.reduced_pool(ax)\n",
    "        \n",
    "        ax = self.context2_encod(ax)\n",
    "        axdecod2 = ax\n",
    "        #ax=self.reduced_pool(ax)\n",
    "        \n",
    "        ax = self.context3_encod(ax)\n",
    "        axdecod3 = ax\n",
    "        #ax=self.reduced_pool(ax)\n",
    "        \n",
    "        ax = self.context4_encod(ax)\n",
    "        #axdecod4 = ax\n",
    "        #ax=self.reduced_pool(ax)\n",
    "        \n",
    "        #ax = self.context5_encod(ax)\n",
    "        #axdecod5 = ax\n",
    "        \n",
    "        #ax = self.context6_encod(ax)\n",
    "\n",
    "        return ax, axdecod3, axdecod2, axdecod1, axdecod0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bef547c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention_block(nn.Module):\n",
    "    \n",
    "    def __init__(self, F_g, F_l, F_int,\n",
    "         conv_op=nn.Conv3d, conv_kwargs=None,\n",
    "         norm_op=nn.InstanceNorm3d, norm_op_kwargs=None,\n",
    "         nonlin=nn.LeakyReLU, nonlin_kwargs=None):\n",
    "        #norm_op=nn.BatchNorm3d\n",
    "        super(Attention_block, self).__init__()\n",
    "        \n",
    "        if nonlin_kwargs is None:\n",
    "            nonlin_kwargs = {'negative_slope': 1e-2, 'inplace': True}\n",
    "        if norm_op_kwargs is None:\n",
    "            norm_op_kwargs = {'eps': 1e-5, 'affine': True, 'momentum': 0.1}\n",
    "        if conv_kwargs is None:\n",
    "            conv_kwargs1x1 = {'kernel_size': 1, 'stride': 1, 'padding': 0, 'dilation': 1, 'bias': True}\n",
    "            \n",
    "        self.W_g = nn.Sequential(\n",
    "            conv_op(F_g, F_int, **conv_kwargs1x1),\n",
    "            norm_op(F_int, **norm_op_kwargs)\n",
    "            )\n",
    "        \n",
    "        self.W_x = nn.Sequential(\n",
    "            conv_op(F_l, F_int, **conv_kwargs1x1),\n",
    "            norm_op(F_int, **norm_op_kwargs)\n",
    "        )\n",
    "\n",
    "        self.psi = nn.Sequential(\n",
    "            conv_op(F_int, 1, **conv_kwargs1x1),\n",
    "            norm_op(1, **norm_op_kwargs),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.lrelu = nonlin(**nonlin_kwargs)\n",
    "        \n",
    "    def forward(self, gA, xA):\n",
    "        gA1 = self.W_g(gA)\n",
    "        xA1 = self.W_x(xA)\n",
    "        psi = self.lrelu(gA1+xA1)\n",
    "        psi = self.psi(psi)\n",
    "\n",
    "        return xA*psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f39380dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynUOneEncodAttn(nn.Module):\n",
    "    def __init__(self, num_classes=4, num_input_channels=4, base_filters=32, dropout_p=0.0,\n",
    "                 final_nonlin=None, leakiness=1e-2, conv_bias=True, inst_norm_affine=True,\n",
    "                 lrelu_inplace=True, do_ds=True):\n",
    "        super(DynUOneEncodAttn, self).__init__()\n",
    "\n",
    "        self.do_ds = do_ds\n",
    "        self.lrelu_inplace = lrelu_inplace\n",
    "        self.inst_norm_affine = inst_norm_affine\n",
    "        self.conv_bias = conv_bias\n",
    "        self.leakiness = leakiness\n",
    "        self.final_nonlin = final_nonlin\n",
    "        norm_op = nn.BatchNorm3d\n",
    "\n",
    "        \n",
    "        nonsymetry_loc_upTrans_kwargs = {'kernel_size': (2, 3, 2), 'stride': (2, 1, 2), 'padding': 0, 'dilation': 1, 'bias': False}\n",
    "        loc_upTrans_kwargs = {'kernel_size': 2, 'stride': 2, 'padding': 0, 'dilation': 1, 'bias': False}\n",
    "        loc_conv_kwargs = {'kernel_size': 3, 'stride': 1, 'padding': 1, 'dilation': 1, 'bias': True}\n",
    "        loc_seg_conv_kwargs = {'kernel_size': 1, 'stride': 1, 'padding': 0, 'dilation': 1, 'bias': False}\n",
    "        \n",
    "        \n",
    "        \n",
    "        dropout_op_kwargs = {'p': 0.0, 'inplace': True}\n",
    "        \n",
    "        #encodFilters = [base_filters, 32, 64, 128, 160, 160]\n",
    "        encodFilters = [base_filters, 64, 128, 256, 320]\n",
    "        #encodFilters = [base_filters, 128, 256, 384, 512]\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        self.get_skip_encodcontext_mtch4 = UEncoder(num_input_channels = num_input_channels, encodFilters = encodFilters, norm_op=norm_op)\n",
    "#        self.get_skip_encodcontext_mt0 = UEncoder(num_input_channels = num_input_channels-3, encodFilters = encodFilters, norm_op=norm_op)\n",
    "#         self.get_skip_encodcontext_mt1 = UEncoder(num_input_channels = num_input_channels-1, encodFilters = encodFilters)\n",
    "#         self.get_skip_encodcontext_mt2 = UEncoder(num_input_channels = num_input_channels-1, encodFilters = encodFilters)\n",
    "#         self.get_skip_encodcontext_mt3 = UEncoder(num_input_channels = num_input_channels-1, encodFilters = encodFilters)\n",
    "        \n",
    "        ch_mult = 1\n",
    "        #loc_upTrans_kwargs['kernel_size'], loc_upTrans_kwargs['stride'], bias = loc_upTrans_kwargs['bias']\n",
    "        self.upTrans1 =  nn.ConvTranspose3d(encodFilters[-1]*ch_mult, encodFilters[-2]*ch_mult, **loc_upTrans_kwargs)\n",
    "        self.att1 = Attention_block(encodFilters[-2]*ch_mult, encodFilters[-2]*ch_mult, encodFilters[-3]*ch_mult, norm_op=norm_op)\n",
    "        self.uploc1 = UpBasicBlock((encodFilters[-2]+encodFilters[-2])*ch_mult, encodFilters[-2]*ch_mult, norm_op=norm_op)\n",
    "        \n",
    "        self.upTrans2 =  nn.ConvTranspose3d(encodFilters[-2]*ch_mult, encodFilters[-3]*ch_mult, **loc_upTrans_kwargs)\n",
    "        self.att2 = Attention_block(encodFilters[-3]*ch_mult, encodFilters[-3]*ch_mult, encodFilters[-4]*ch_mult, norm_op=norm_op)\n",
    "        self.uploc2 = UpBasicBlock((encodFilters[-3]+encodFilters[-3])*ch_mult, encodFilters[-3]*ch_mult, norm_op=norm_op)\n",
    "        self.loc2_seg = ConvNonlinSeg(encodFilters[-3]*ch_mult, num_classes, conv_kwargs = loc_seg_conv_kwargs)\n",
    "        \n",
    "        self.upTrans3 =  nn.ConvTranspose3d(encodFilters[-3]*ch_mult, encodFilters[-4]*ch_mult, **loc_upTrans_kwargs) \n",
    "        self.att3 = Attention_block(encodFilters[-4]*ch_mult, encodFilters[-4]*ch_mult, encodFilters[-5]*ch_mult, norm_op=norm_op)\n",
    "        self.uploc3 = UpBasicBlock((encodFilters[-4]+encodFilters[-4])*ch_mult, encodFilters[-4]*ch_mult, norm_op=norm_op)\n",
    "        self.loc3_seg = ConvNonlinSeg(encodFilters[-4]*ch_mult, num_classes, conv_kwargs = loc_seg_conv_kwargs)\n",
    "        \n",
    "        \n",
    "        self.upTrans4 =  nn.ConvTranspose3d(encodFilters[-4]*ch_mult, encodFilters[-5]*ch_mult, **loc_upTrans_kwargs)\n",
    "        self.att4 = Attention_block(encodFilters[-5]*ch_mult, encodFilters[-5]*ch_mult, encodFilters[-5]*ch_mult//2, norm_op=norm_op)\n",
    "        self.uploc4 = UpBasicBlock((encodFilters[-5]+encodFilters[-5])*ch_mult, encodFilters[-5]*ch_mult, norm_op=norm_op)\n",
    "        self.loc4_seg = ConvNonlinSeg(encodFilters[-5]*ch_mult, num_classes, conv_kwargs = loc_seg_conv_kwargs)\n",
    "        \n",
    "#         self.upTrans5 =  nn.ConvTranspose3d(encodFilters[-5]*ch_mult, encodFilters[-6]*ch_mult, **loc_upTrans_kwargs)\n",
    "#         self.att5 = Attention_block(encodFilters[-6]*ch_mult, encodFilters[-6]*ch_mult, encodFilters[-6]*ch_mult//2, norm_op=norm_op)\n",
    "#         self.uploc5 = UpBasicBlock((encodFilters[-6]+encodFilters[-6])*ch_mult, encodFilters[-6]*ch_mult, norm_op=norm_op)\n",
    "#         self.loc5_seg = ConvNonlinSeg(encodFilters[-6]*ch_mult, num_classes, conv_kwargs = loc_seg_conv_kwargs)\n",
    "        \n",
    "        \n",
    "#         self.upTrans6 =  nn.ConvTranspose3d(encodFilters[-6]*ch_mult, encodFilters[-7]*ch_mult, **loc_upTrans_kwargs)\n",
    "#         self.att6 = Attention_block(encodFilters[-7]*ch_mult, encodFilters[-7]*ch_mult, (encodFilters[-7]*ch_mult)//2, norm_op=norm_op)\n",
    "#         self.uploc6 = UpBasicBlock((encodFilters[-7]+encodFilters[-7])*ch_mult, encodFilters[-7]*ch_mult, norm_op=norm_op)\n",
    "#         self.loc6_seg = ConvNonlinSeg(encodFilters[-7]*ch_mult, num_classes, conv_kwargs = loc_seg_conv_kwargs)\n",
    "        \n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv3d):\n",
    "                nn.init.kaiming_normal_(torch.as_tensor(m.weight), a=0.01)\n",
    "            elif isinstance(m, nn.BatchNorm3d):\n",
    "                nn.init.constant_(torch.as_tensor(m.weight), 1)\n",
    "                nn.init.constant_(torch.as_tensor(m.bias), 0)\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                nn.init.constant_(torch.as_tensor(m.weight), 1)\n",
    "                nn.init.constant_(torch.as_tensor(m.bias), 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.constant_(torch.as_tensor(m.bias), 0)\n",
    "                \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        seg_outputs = []\n",
    "        size = list(x.shape[2:])\n",
    "\n",
    "        \n",
    "        xyzh, xdecod3, xdecod2, xdecod1, xdecod0 = self.get_skip_encodcontext_mtch4(x)\n",
    "\n",
    "        \n",
    "        ##########################\n",
    "        ###Strating of up block ###\n",
    "        \n",
    "        xyzh = self.upTrans1(xyzh)\n",
    "        xdecod3 = self.att1(gA=xyzh, xA= xdecod3)\n",
    "        xyzh = torch.cat([xyzh, xdecod3], dim=1)\n",
    "        xyzh = self.uploc1(xyzh) \n",
    "        \n",
    "        xyzh = self.upTrans2(xyzh)\n",
    "        xdecod2 = self.att2(gA=xyzh, xA= xdecod2)\n",
    "        xyzh = torch.cat([xyzh, xdecod2], dim=1)\n",
    "        xyzh = self.uploc2(xyzh)\n",
    "        seg_outputs.append(F.interpolate(self.loc2_seg(xyzh), size = size))\n",
    "        \n",
    "        xyzh = self.upTrans3(xyzh)\n",
    "        xdecod1 = self.att3(gA=xyzh, xA= xdecod1)\n",
    "        xyzh = torch.cat([xyzh, xdecod1], dim=1)\n",
    "        xyzh = self.uploc3(xyzh)\n",
    "        seg_outputs.append(F.interpolate(self.loc3_seg(xyzh), size = size))\n",
    "        \n",
    "        xyzh = self.upTrans4(xyzh)\n",
    "        xdecod0 = self.att4(gA=xyzh, xA= xdecod0)\n",
    "        xyzh = torch.cat([xyzh,xdecod0], dim=1)\n",
    "        xyzh = self.uploc4(xyzh)\n",
    "        seg_outputs.append(F.interpolate(self.loc4_seg(xyzh), size = size))\n",
    "        \n",
    "        \n",
    "        if self.training:\n",
    "            return torch.stack([seg_outputs[-1], seg_outputs[-2], seg_outputs[-3]], dim=1)\n",
    "        else:\n",
    "            return seg_outputs[-1]\n",
    "        \n",
    "                 "
   ]
  },
  {
   "cell_type": "raw",
   "id": "8324c7d2",
   "metadata": {},
   "source": [
    "model = DynUOneEncodAttn(num_classes=2, num_input_channels=2, base_filters=32).to(device)\n",
    "inps = torch.randn(2, 2, 32, 32, 32).to(device)\n",
    "with torch.cuda.amp.autocast():\n",
    "    outs = model(inps)\n",
    "print(outs.shape)\n",
    "#print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6c5aba65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/raid/brats2021/pthBraTS2020_IDHGenomics/TwoEncodUNetVariants_TCGA/AttnDynUNet_BratsTCGA_HistStand_3CV_4Chnls1PatchSWIRngr21_2nclass_MorePatchBNormEp500_Fold0_0.8220_epoch287.pth'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transfer_model_save_dir = os.path.join('/raid/brats2021/pthBraTS2020_IDHGenomics/TwoEncodUNetVariants_TCGA')\n",
    "\n",
    "transfer_mode_DCTList = {'fold0': glob.glob(f'{transfer_model_save_dir}/AttnDynUNet_BratsTCGA_HistStand_3CV_4Chnls1PatchSWIRngr21_2nclass_MorePatchBNormEp500_Fold0_0.8220_epoch287.pt*'),\\\n",
    "               'fold1':glob.glob(f'{transfer_model_save_dir}/AttnDynUNet_BratsTCGA_HistStand_3CV_4Chnls1PatchSWIRngr21_2nclass_MorePatchBNormEp500_Fold1_0.8581_epoch296.pth*'),\\\n",
    "               'fold2':glob.glob(f'{transfer_model_save_dir}/AttnDynUNet_BratsTCGA_HistStand_3CV_4Chnls1PatchSWIRngr21_2nclass_MorePatchBNormEp500_Fold2_0.8866_epoch256.pth*')}\n",
    "transfer_modelPath = transfer_mode_DCTList['fold0'][0]\n",
    "transfer_modelPath"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d2a281e5",
   "metadata": {},
   "source": [
    "current_model_dict = model.state_dict()\n",
    "loaded_state_dict = torch.load(transfer_mode_DCTList[\"fold0\"][0], map_location=device)\n",
    "new_state_dict={k:v if v.size()==current_model_dict[k].size() else current_model_dict[k] for k,v in zip(current_model_dict.keys(), loaded_state_dict.values())}\n",
    "model.load_state_dict(new_state_dict, strict=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a134267d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "46944be6",
   "metadata": {},
   "source": [
    "## Custom editing of SegResNetVAE"
   ]
  },
  {
   "cell_type": "raw",
   "id": "936460dd",
   "metadata": {},
   "source": [
    "def get_kernels_strides(sizes, spacings):\n",
    "    #sizes, spacings = patch_size[task_id], spacing[task_id]\n",
    "    strides, kernels = [], []\n",
    "\n",
    "    while True:\n",
    "        spacing_ratio = [sp / min(spacings) for sp in spacings]\n",
    "        stride = [\n",
    "            2 if ratio <= 2 and size >= 8 else 1\n",
    "            for (ratio, size) in zip(spacing_ratio, sizes)\n",
    "        ]\n",
    "        kernel = [3 if ratio <= 2 else 1 for ratio in spacing_ratio]\n",
    "        if all(s == 1 for s in stride):\n",
    "            break\n",
    "        sizes = [i / j for i, j in zip(sizes, stride)]\n",
    "        spacings = [i * j for i, j in zip(spacings, stride)]\n",
    "        kernels.append(kernel)\n",
    "        strides.append(stride)\n",
    "    strides.insert(0, len(spacings) * [1])\n",
    "    kernels.append(len(spacings) * [3])\n",
    "    return kernels, strides\n",
    "#task_id = \"01\"\n",
    "kernels, strides = get_kernels_strides(patch_size, spacing)\n",
    "kernels.append([3, 3, 3])\n",
    "strides.append([2, 2, 2])\n",
    "\n",
    "print(kernels,'\\n', strides)\n",
    "\n",
    "print('strides length', len(strides))\n",
    "#filters = [32, 64, 128, 256, 320, 384, 512][: len(strides)]\n",
    "filters = [64, 96, 128, 192, 256, 384, 512, 768, 1024][: len(strides)]\n",
    "print(\"Filters:\", filters)\n",
    "strides = [s[0] for s in strides[1:]]\n",
    "print(\"Strides:\", strides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "483ff50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernels, strides = get_kernels_strides((128, 128, 128), spacing)\n",
    "# #kernels, strides\n",
    "# kernels = [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 6, 3]]\n",
    "# strides = [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b3e4dc58",
   "metadata": {},
   "source": [
    "model = DynUNet(    \n",
    "    spatial_dims=3,\n",
    "    in_channels=4,\n",
    "    out_channels=3,\n",
    "    kernel_size=kernels,\n",
    "    strides=strides,\n",
    "    filters = filters,\n",
    "    upsample_kernel_size=strides[1:],\n",
    "    norm_name=\"batch\",\n",
    "    deep_supervision=True,\n",
    "    res_block=True,\n",
    "    deep_supr_num=2,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1ba9d37d",
   "metadata": {},
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "278b47f9",
   "metadata": {},
   "source": [
    "inps = torch.randn(3, 4, 32, 32, 32).to(device)\n",
    "x = model(inps)\n",
    "# # model\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3274d1b2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "e29f06fd",
   "metadata": {},
   "source": [
    "from torchsummary import summary\n",
    "summary(model, (4, 32, 32, 32))\n",
    "# # inps = torch.randn(3, 4, 48, 64, 48)\n",
    "# # litConv = nn.Conv3d(4, 64, kernel_size=(7, 7, 7), stride=(2, 2, 2), padding=(3, 3, 3), bias=False)\n",
    "# # litConv(inps).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cca06f",
   "metadata": {},
   "source": [
    "### Defining loss functions\n",
    "- ***CrossEntropyLogitLoss*** Cross entropy logit loss from [PyTorch](https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html)\n",
    "- ***DiceCELoss*** Dice + Cross entropy loss from Monai\n",
    "https://docs.monai.io/en/latest/losses.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d4dfb301",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropyInstWLogitLoss(nn.Module):\n",
    "    def __init__(self, is_smooth=False, label_smoothing = 0.1):\n",
    "        super().__init__()\n",
    "        self.is_smooth = is_smooth\n",
    "        self.label_smoothing = label_smoothing\n",
    "        \n",
    "       \n",
    "    def forward(self, y_pred, y_true):\n",
    "\n",
    "        if self.is_smooth == True:\n",
    "            y_true = y_true.float() * (1 - self.label_smoothing) + 0.5 * self.label_smoothing\n",
    "\n",
    "        y_true=y_true.type_as(y_pred)   ### y_pred, and y_true should be same size and same data type\n",
    "        \n",
    "        \n",
    "        #deviceidx = y_pred.get_device()\n",
    "        #device = torch.device('cpu') if deviceidx == -1 else torch.device(f'cuda:{deviceidx}')\n",
    "        #loss = F.binary_cross_entropy_with_logits(y_pred.to(device), y_true.to(device), pos_weight = weight.to(device))  ##pos_weight = weight \n",
    "        loss = F.binary_cross_entropy_with_logits(y_pred, y_true) \n",
    "        return loss\n",
    "\n",
    "\n",
    "# class DeepDiceCELogitInstLoss(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         #self.volweight = torch.softmax(torch.tensor([0.12, 0.33, 0.55]), dim = 0)\n",
    "#         self.dice = DiceLoss(include_background=False, to_onehot_y=True, softmax=True, squared_pred=True, batch = False)  # reduction = \"none\", batch = True\n",
    "#         #self.smcross_entropy = CrossEntropyInstLoss()  ### was none torch.Tensor([0.66, 0.33, 1]), torch.tensor(self.volweight)\n",
    "\n",
    "#     def forward(self, y_pred, y_true):\n",
    "        \n",
    "#         y_true = y_true.unsqueeze(dim=0).expand(y_pred.shape[1],-1,-1,-1,-1, -1)\n",
    "#         #return sum([0.5 ** i * ((self.dice(p, l)) + self.smcross_entropy(p, l)) \\\n",
    "#         #            for i, (p, l) in enumerate(zip(torch.unbind(y_pred, dim=1), torch.unbind(y_true, dim=0)))])\n",
    "#         return sum([0.5 ** i * self.dice(p, l) for i, (p, l) in enumerate(zip(torch.unbind(y_pred, dim=1), torch.unbind(y_true, dim=0)))])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class DeepDiceCELogitInstLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #self.volweight = torch.softmax(torch.tensor([0.12, 0.33, 0.55]), dim = 0)\n",
    "        self.dice = DiceLoss(to_onehot_y=False, sigmoid=True, squared_pred=True, batch = True)  # reduction = \"none\", False\n",
    "        self.logitcross_entropy = CrossEntropyInstWLogitLoss()  ### was none torch.Tensor([0.66, 0.33, 1]), torch.tensor(self.volweight)\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        \n",
    "        y_true = y_true.unsqueeze(dim=0).expand(y_pred.shape[1],-1,-1,-1,-1, -1)\n",
    "        return sum([0.5 ** i * ((self.dice(p, l)) + self.logitcross_entropy(p, l)) \\\n",
    "                    for i, (p, l) in enumerate(zip(torch.unbind(y_pred, dim=1), torch.unbind(y_true, dim=0)))])\n",
    "    \n",
    "loss_function = DeepDiceCELogitInstLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5ca390fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.6448)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xxp = torch.randint(0,4,size=(6,3, 128, 128, 128))\n",
    "#pred = [torch.randn(6,3,8,8,6), torch.randn(6,3,8,8,6), torch.randn(6,3,8,8,6)]\n",
    "pred = torch.stack([torch.randn(6, 3, 128, 128, 128), torch.randn(6, 3, 128, 128, 128), torch.randn(6, 3, 128, 128, 128), torch.randn(6, 3, 128, 128, 128)], dim=1)\n",
    "loss_function(pred, xxp.float())\n",
    "#loss_function(pred, xxp.float())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c564efa6",
   "metadata": {},
   "source": [
    "#### A function to create ***cache_dir*** to save transformed outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "91dc1500",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeAndcreate_cachedir(cache_dir):\n",
    "    if not os.path.exists(cache_dir):\n",
    "        os.makedirs(cache_dir)\n",
    "    else:\n",
    "        #print(\"Pass\")\n",
    "        shutil.rmtree(cache_dir)\n",
    "        os.makedirs(cache_dir)\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fd0c93",
   "metadata": {},
   "source": [
    "### Pytorch training loop\n",
    "\n",
    "Following functionalities are added\n",
    "\n",
    "- Implemeting learning rate finder\n",
    "- Defining Ranger21 optimizer (learning rate scheduler attached to it)\n",
    "- Implementing mixed precision (AMP)\n",
    "- Saving the model weights based on the performance on validation data\n",
    "- Executing 5 fold cross validation (CV) training/validation pipeline, saving a few best model's weights at each fold\n",
    "- Defining train_dataset/train_loader, and val_dataset/val_loader at each fold\n",
    "- Defining a CNN based classification model (DenseNet, EfficientNet, etc.) at each fold to make sure that all accumulated gradients get vanished\n",
    "\n",
    "The key variables which are used here\n",
    "- ***val_cache_dir:*** The path where the transformed ouputs of validaion files will be cached/saved\n",
    "- ***train_cache_dir:*** The path where the transformed ouputs of training files will be cached/saved\n",
    "- ***max_epochs:*** Total number of epochs\n",
    "- ***save_dir:*** The path to save the checkpoints/weights of the model\n",
    "- ***file_prefix:*** The text file where loss/accuracy is recoded like\n",
    "\n",
    "```\n",
    "current fold: 0 current epoch: 1, acc_metric: 0.4579 accuracy: 0.5085, f1score: 0.5085 epoch 1 average training loss: 0.7250 average validation loss: 0.7128 \n",
    "current fold: 0 current epoch: 2, acc_metric: 0.4876 accuracy: 0.5424, f1score: 0.5424 epoch 2 average training loss: 0.6961 average validation loss: 0.6940 \n",
    "current fold: 0 current epoch: 3, acc_metric: 0.4870 accuracy: 0.4915, f1score: 0.4915 epoch 3 average training loss: 0.6862 average validation loss: 0.6965 \n",
    "current fold: 0 current epoch: 4, acc_metric: 0.4882 accuracy: 0.5593, f1score: 0.5593 epoch 4 average training loss: 0.6715 average validation loss: 0.6885 \n",
    "current fold: 0 current epoch: 5, acc_metric: 0.5927 accuracy: 0.5593, f1score: 0.5593 epoch 5 average training loss: 0.6555 average validation loss: 0.6826 \n",
    "```\n",
    "\n",
    "- ***val_interval*** Epoch interval to investivate the model's performance on validation data. If the current performance is better than in previous epochs, the model's weights will be saved\n",
    "- ***key_metric_n_saved*** The number of model checkpoints we want to save. It it is set as 5, top 5 checkpoints/weights will be saved in 5 different ***.pth*** files  \n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "37a022e1",
   "metadata": {},
   "source": [
    "    \n",
    "def getbatch_segclass(x):\n",
    "    xdvc = x.device\n",
    "    x_batchlist = torch.unbind(x, dim = 0)\n",
    "    xbatchclass = []\n",
    "    for xc in x_batchlist:\n",
    "        x_chlist = torch.unbind(xc, dim = 0)\n",
    "        xclassNoList = []\n",
    "        xvalueList = []\n",
    "        for x_i in x_chlist:\n",
    "\n",
    "            xv, xc = torch.unique(x_i, return_counts  = True)\n",
    "\n",
    "            if xc.shape[0]==1:\n",
    "                xclassNoList.append(xc[0].item())\n",
    "                xvalueList.append(xv[0].item())\n",
    "            elif: xc.shape[0]==2:\n",
    "                    if torch.any(torch.eq(xv, 1)):\n",
    "                        xclassNoList.append(xc[1].item())\n",
    "                        xvalueList.append(xv[1].item())\n",
    "                    else:\n",
    "                        print('The function only supports binarized tensor (binarized unique values, 0(n=...) and 1(n=...) only)\\n')\n",
    "            else:\n",
    "                print('The function only supports binarized tensor (binarized unique values, 0(n=...) and 1(n=...) only)\\n')\n",
    "\n",
    "\n",
    "\n",
    "        if torch.any(torch.eq(torch.tensor(xvalueList), 1)):  \n",
    "            xclass = torch.argmax(torch.tensor(xclassNoList))\n",
    "        else:\n",
    "            '''If all uniques class values are 0, we are assigning nan values as a class'''\n",
    "            xclass = torch.tensor(float('NaN'))\n",
    "\n",
    "\n",
    "        xbatchclass.append(xclass.item())\n",
    "\n",
    "\n",
    "    xbatchclass = torch.tensor(xbatchclass)\n",
    "    return torch.mode(xbatchclass.to(xdvc))[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3b41642b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#***Executed pipeline***\\\n",
    "#<img src=\"assets/ProposedIDHClass.png\" align=\"left\" width=\"1024\" height=\"1800\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b1a95bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_segclass(x, dim = 1):\n",
    "    xdvc = x.device\n",
    "    x_chlist = torch.unbind(x, dim = dim)\n",
    "    xclassNoList = []\n",
    "    xvalueList = []\n",
    "\n",
    "    for x_i in x_chlist:\n",
    "\n",
    "        xv, xc = torch.unique(x_i, return_counts  = True)\n",
    "\n",
    "        if xc.shape[0]==1:\n",
    "            if xv==0:\n",
    "                xclassNoList.append(-1)\n",
    "                xvalueList.append(xv[0].item())\n",
    "            elif xv==1:\n",
    "                xclassNoList.append(xc[0].item())\n",
    "                xvalueList.append(xv[0].item())\n",
    "            else:\n",
    "                print('The function only supports binarized tensor (binarized unique values, 0(n=...) and 1(n=...) only)\\n')\n",
    "\n",
    "\n",
    "        elif xc.shape[0]==2:\n",
    "                if torch.any(torch.eq(xv, 1)):\n",
    "                    xclassNoList.append(xc[1].item())\n",
    "                    xvalueList.append(xv[1].item())\n",
    "                else:\n",
    "                    print('The function only supports binarized tensor (binarized unique values, 0(n=...) and 1(n=...) only)\\n')\n",
    "        else:\n",
    "            print('The function only supports binarized tensor (binarized unique values, 0(n=...) and 1(n=...) only)\\n')\n",
    "\n",
    "    #pdb.set_trace()\n",
    "    #if torch.any(torch.eq(torch.tensor(xvalueList), 1)):\n",
    "\n",
    "    if xclassNoList[0]!=xclassNoList[1]: \n",
    "        xclass = torch.argmax(torch.tensor(xclassNoList).to(xdvc))\n",
    "    else:\n",
    "        xclass = torch.tensor(float('NaN')).to(xdvc)\n",
    "\n",
    "    #else:\n",
    "        '''If all uniques class values are 0, we are assigning nan values as a class'''\n",
    "    #    xclass = torch.tensor(float('NaN')).to(xdvc)\n",
    "\n",
    "\n",
    "    return xclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "afdac35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getbatch_segclass(x):\n",
    "    xdvc = x.device\n",
    "    x_batchlist = torch.unbind(x, dim = 0)\n",
    "    xbatchclass = []\n",
    "    for xc in x_batchlist:\n",
    "        xcclass = get_segclass(xc, dim = 0)            \n",
    "        xbatchclass.append(xcclass.item())\n",
    "\n",
    "\n",
    "    xbatchclass = torch.tensor(xbatchclass)\n",
    "    if torch.all(torch.isnan(xbatchclass))==True:\n",
    "\n",
    "            return torch.tensor(float('NaN')).to(xdvc)\n",
    "\n",
    "    else:\n",
    "\n",
    "        num_xbatchnanvalues = torch.isnan(xbatchclass).sum().item()\n",
    "        not_xbatchnanmask = torch.logical_not(torch.isnan(xbatchclass))\n",
    "        xbatchclass = xbatchclass[not_xbatchnanmask]\n",
    "\n",
    "        xclassVal_01, xclassCnt_01 =xbatchclass.unique(return_counts = True)\n",
    "\n",
    "        if xclassCnt_01.shape[0]==1:\n",
    "            return xclassVal_01[0].to(xdvc)\n",
    "\n",
    "\n",
    "        if xclassCnt_01.shape[0]==2:\n",
    "            if xclassCnt_01[0]!=xclassCnt_01[1]:\n",
    "                ''' xclassCnt_01 will always be two values converting [7, 8] to 1; [8, 7] to 0'''\n",
    "                return torch.argmax(xclassCnt_01).to(xdvc)  \n",
    "\n",
    "            else:\n",
    "\n",
    "                return torch.tensor(float('NaN')).to(xdvc)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6bba8baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_binarize_tensor(x, dim=1):\n",
    "    x_chlist = torch.unbind(x, dim = dim)\n",
    "    bin_x = torch.zeros_like(x_chlist[0])\n",
    "    for x_i in x_chlist:\n",
    "        bin_x = torch.logical_or(x_i, bin_x)\n",
    "    return bin_x.unsqueeze(dim=dim).to(torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11463485",
   "metadata": {},
   "source": [
    "### Starting training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "06bc1516",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_files, train_files_IDH_label, val_files, val_files_IDH_label, batch_size = 2, epochs = 10, find_lr=False, cfold = 0, transfer_modelPath=None):\n",
    "    \n",
    "\n",
    "    #     model = DenseNet201(spatial_dims=2, in_channels=3,\n",
    "    #                        out_channels=num_classes, pretrained=True).to(device)\n",
    "\n",
    "    # create spatial 3D\n",
    "    #model = MultiDenseNet(spatial_dims=3, in_channelsList=(4, 1, 1, 1, 1), out_channels=2, block_config = (6, 12, 24, 16)).to(device)\n",
    "    #model = monai.networks.nets.DenseNet121(spatial_dims=3, in_channels=4, out_channels=1).to(device)\n",
    "    #model = monai.networks.nets.DenseNet264(spatial_dims=3, in_channels=4, out_channels=1, init_features=64, growth_rate=32, block_config=(6, 12, 64, 48)).to(device)\n",
    "    #patch_size=(64, 80, 64)\n",
    "    \n",
    "    num_classes = 2\n",
    "    model = DynUOneEncodAttn(num_classes=num_classes, num_input_channels=2, base_filters=32).to(device)\n",
    "    \n",
    "    \n",
    "    \n",
    "    auc_metric = ROCAUCMetric()\n",
    "    \n",
    "\n",
    "    #train_files, train_files_IDH_label, val_files, val_files_IDH_label = train_files[:48], train_files_IDH_label[:48], val_files[:16], val_files_IDH_label[:16]\n",
    "\n",
    "    \"\"\"\n",
    "    Block for using Monai's caching mechanishm for faster training\n",
    "    \"\"\"\n",
    "    \n",
    "    file_prefixfold = file_prefix  ##or file_prefix f\"{file_prefix}_fold{cfold}\" if saving cv file\n",
    "    data_rpath = '/home/mmiv-ml/data'\n",
    "    train_cache_dir = os.path.join(data_rpath,f'cachingDataset/{file_prefixfold}/train')    \n",
    "    val_cache_dir = os.path.join(data_rpath,f'cachingDataset/{file_prefixfold}/val')\n",
    "    \n",
    "    is_done_train = removeAndcreate_cachedir(train_cache_dir)\n",
    "    is_done_val = removeAndcreate_cachedir(val_cache_dir)\n",
    "    \n",
    "\n",
    "    n_train_cache_n_trans = len(train_transforms) #15\n",
    "    n_val_cache_n_trans = len(val_transforms)\n",
    "    \n",
    "     # create a training data loader\n",
    "\n",
    "    train_dataset = monai.data.CacheNTransDataset(data=train_files, transform=train_transforms,\\\n",
    "                                               cache_n_trans = n_train_cache_n_trans, cache_dir = train_cache_dir)\n",
    "    \n",
    "    \n",
    "    \n",
    "#    train_dataset = monai.data.Dataset(data=train_files, transform=train_transforms)\n",
    "    \n",
    "#     #train_folds['fold0_IDH_label']\n",
    "\n",
    "    train_files_IDH_labels = np.array([id_lbl['IDH_label'].item() for id_lbl in train_files])\n",
    "    uval, ucnt = np.unique(train_files_IDH_labels, return_counts=True)\n",
    "    weight = 1./(ucnt/ucnt.min())\n",
    "    #weight = 1./ucnt\n",
    "    #weight = np.array([0.55, 0.45])\n",
    "    sample_weights = np.array([weight[int(t)] for t in train_files_IDH_labels])\n",
    "    sample_weights = torch.from_numpy(sample_weights)\n",
    "    sampler = WeightedRandomSampler(sample_weights, num_samples= len(sample_weights), replacement=True)\n",
    "\n",
    "\n",
    "    #train_dataset = Dataset(data=train_files, transform=train_transforms)\n",
    "    #train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=2, pin_memory=True)\n",
    "    #train_dataset = CacheDataset(data=train_files, transform=train_transforms, cache_rate = 1.0, num_workers=8)\n",
    "    #train_loader = ThreadDataLoader(train_dataset, num_workers=0, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    #shiffle = False, sampler = sampler, shuffle=True doesnot work with patch, num_workers=2\n",
    "    train_loader = monai.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=False, collate_fn=list_data_collate, sampler = sampler) \n",
    "    \n",
    "\n",
    "    \n",
    "    # create a validation data loader\n",
    "    \n",
    "    #val_dataset = monai.data.Dataset(data=val_files, transform=val_transforms)\n",
    "    #val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=2, pin_memory=True)\n",
    "    #val_dataset = CacheDataset(data=val_files, transform=val_transforms, cache_rate = 1.0, num_workers=5)\n",
    "    \n",
    "    val_dataset = monai.data.CacheNTransDataset(data=val_files, transform=val_transforms,\\\n",
    "                                            cache_n_trans = n_val_cache_n_trans, cache_dir = val_cache_dir)\n",
    "    #val_loader = ThreadDataLoader(val_dataset, num_workers=0, batch_size=1)\n",
    "    val_loader = monai.data.DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=2, pin_memory=True) ##\n",
    "    \n",
    "    \n",
    "    \n",
    "#     for ibatch in train_loader:\n",
    "#         ibatch_IDH = ibatch['IDH_label']\n",
    "#         print(torch.eq(ibatch_IDH, 0).sum(), torch.eq(ibatch_IDH, 1).sum())\n",
    "#         print('#'*50)\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    just initialising some basic steps\n",
    "    \"\"\"\n",
    "    \n",
    "    max_epochs = epochs\n",
    "    find_lr=False\n",
    "    \n",
    "    ### Calling the loss function ***CrossEntropyPlusMSELoss**,and optimizer   \n",
    "    #loss_function = nn.CrossEntropyLoss()\n",
    "    #loss_function=nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    #optimizer = torch.optim.Adam(model.parameters(), lr=1e-03, weight_decay=1e-07)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr = 1e-05, weight_decay = 1e-4)\n",
    "    #optimizer = torch.optim.SGD(model.parameters(), lr=1e-03, momentum= 0.99, nesterov=True)\n",
    "    #optimizer = torch.optim.Adam(model.parameters(), 1e-03, weight_decay=1e-04)\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    \n",
    "    \n",
    "    max_lr_init = 1e-04\n",
    "    \"\"\"\n",
    "     ###################### Block for LR finder from pytorch ignite ########################\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if find_lr:\n",
    "\n",
    "        def prepare_batch(batch, device=None, non_blocking=False):\n",
    "            return _prepare_batch((batch['image'], batch['IDH_label'].long()), device, non_blocking)\n",
    "\n",
    "        #trainer = create_supervised_trainer(model, optimizer, loss_function, device, non_blocking=False, prepare_batch=prepare_batch)\n",
    "        def train_step(engine, batch):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            x, y = batch['image'].to(device), batch['IDH_label'].to(device)  #non_blocking=True\n",
    "            with torch.cuda.amp.autocast():\n",
    "                y_pred = model(x)\n",
    "                loss4lr = loss_function(y_pred, y)\n",
    "                \n",
    "            scaler.scale(loss4lr).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            return loss4lr.item()\n",
    "\n",
    "        trainer = Engine(train_step)\n",
    "\n",
    "        ProgressBar(persist=True).attach(trainer, output_transform=lambda x: {\"batch loss\": x})\n",
    "        lr_finder = FastaiLRFinder()\n",
    "        to_save={'model': model, 'optimizer': optimizer}\n",
    "        num_iter = 100  #2*len(train_loader)\n",
    "        run_epochs = int(np.ceil(num_iter/len(train_loader)))\n",
    "        with lr_finder.attach(trainer, to_save, end_lr=10, num_iter=num_iter, diverge_th=1.5) as trainer_with_lr_finder:    ####diverge_th=1.5\n",
    "\n",
    "            trainer_with_lr_finder.run(train_loader, max_epochs=run_epochs)  #max_epochs=run_epochs or 5\n",
    "\n",
    "        ax = lr_finder.plot()\n",
    "        plt.show()\n",
    "        \n",
    "        max_lr = lr_finder.lr_suggestion() if lr_finder.lr_suggestion()<5e-03 else max_lr_init\n",
    "        #max_lr = lr_finder.lr_suggestion() ##max_lr/10 i guess not needed, ignite does itself\n",
    "        print(f'Suggested learning rate by LR finder for this fold: {lr_finder.lr_suggestion()}')\n",
    "        \n",
    "    else:\n",
    "        max_lr = max_lr_init\n",
    "        \n",
    "    #max_lr_slice = 1e01*max_lr if max_lr<5e-03 else 1e-02\n",
    "    #max_lr_slice = 1e-01*max_lr if max_lr<1e-05 else max_lr\n",
    "    \n",
    "    ''' Transfer learning section '''\n",
    "    if transfer_modelPath is not None:\n",
    "        current_model_dict = model.state_dict()\n",
    "        loaded_state_dict = torch.load(transfer_modelPath, map_location=device)\n",
    "        new_state_dict={k:v if v.size()==current_model_dict[k].size() else current_model_dict[k] for k,v in zip(current_model_dict.keys(), loaded_state_dict.values())}\n",
    "        model.load_state_dict(new_state_dict, strict=False)\n",
    "        \n",
    "    \n",
    "    \"\"\"\n",
    "    ### defining learning rate scheduler\n",
    "    \n",
    "    \"\"\"\n",
    "    #steps_per_epoch=len(train_loader)\n",
    "    #optimizer.param_groups[0]['lr'] = max_lr #*1e-01\n",
    "    #scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=max_lr_slice, steps_per_epoch=len(train_loader), epochs=max_epochs)\n",
    "    #scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda epoch: (1 - epoch / max_epochs) ** 0.9)\n",
    "    \n",
    "    #max_lr = 1e-3   \n",
    "    optimizer = Ranger21(model.parameters(), lr = max_lr, num_epochs = epochs, num_batches_per_epoch = len(train_loader))\n",
    "    \n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "     ###################### Block for native pytorch training loop and  ########################\n",
    "    \"\"\"\n",
    "\n",
    "    key_metric_n_saved = 2   ### Usually I keep it 5\n",
    "    save_last = False \n",
    "    dispformat_specs = '.4f'\n",
    "\n",
    "        \n",
    "#     file_prefix = 'ConvEffNet_Brats21_5CV'\n",
    "#     savedirname = 'ConvEffNet_Brats21'\n",
    "#     save_dir = os.path.join('/raid/brats2021/pthBraTS2021Radiogenomics', savedirname)\n",
    "#     if not os.path.exists(save_dir):\n",
    "#         os.makedirs(save_dir)\n",
    "\n",
    "    logsfile_path = f\"{save_dir}/Logs_{file_prefix}.txt\"\n",
    "\n",
    "\n",
    "    epoch_num = max_epochs #  max_epochs\n",
    "    val_interval = 1\n",
    "    valstep = 0\n",
    "    best_metric = -1\n",
    "    best_metric_epoch = -1\n",
    "    epoch_loss_values = list()\n",
    "    metric_values = list()\n",
    "\n",
    "\n",
    "    numsiters = len(train_files) // train_loader.batch_size\n",
    "\n",
    "    first_batch = monai.utils.misc.first(train_loader)\n",
    "        \n",
    "    \n",
    "    #post_pred = AsDiscrete(argmax=True, to_onehot=num_classes)  ### num_classes=num_classes\n",
    "    #post_label = AsDiscrete(to_onehot=num_classes) ###num_classes=num_classes\n",
    "    #dice_metric = monai.metrics.DiceMetric(include_background=False, reduction='mean', get_not_nans=False)\n",
    "    \n",
    "    \n",
    "    dice_metric = monai.metrics.DiceMetric(include_background=True, reduction='mean', get_not_nans=False)\n",
    "    dice_metric_batch = monai.metrics.DiceMetric(include_background=True, reduction='mean_batch', get_not_nans=False)\n",
    "    post_pred = Compose([Activations(sigmoid=True), AsDiscrete(threshold=0.5)])  \n",
    "    \n",
    "    def one_hot_permute(x):\n",
    "        return F.one_hot(x.squeeze(dim=0).long(), num_classes=num_classes).permute(3, 0, 1, 2)\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    for epoch in range(epoch_num):\n",
    "        print(\"-\" * 10)\n",
    "        print(f\"epoch {epoch + 1}/{epoch_num}\")\n",
    "        model.train()\n",
    "        epoch_loss = 0.\n",
    "        stepiter = 0\n",
    "        for batch_data in train_loader:\n",
    "            \n",
    "            stepiter += 1\n",
    "            inputs, labels, IDH_labels= (\n",
    "                batch_data['image'].to(device),\n",
    "                batch_data['label'].to(device),\n",
    "                batch_data['IDH_label'].to(device),\n",
    "            )\n",
    "            \n",
    "          \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            with torch.cuda.amp.autocast():\n",
    "\n",
    "                # compute output\n",
    "                outputs  = model(inputs)\n",
    "                loss = loss_function(outputs, labels) \n",
    "\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            print(f\"{stepiter}/{numsiters}, train_loss: {loss.item():.4f}\")\n",
    "\n",
    "            #scheduler.step() \n",
    "            \n",
    "        epoch_loss /= stepiter\n",
    "        epoch_loss_values.append(epoch_loss)\n",
    "        print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "        \n",
    "        \n",
    "        if (epoch + 1) % val_interval == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "\n",
    "                y_pred = torch.tensor([], dtype=torch.float32, device=device)\n",
    "                y = torch.tensor([], dtype=torch.long, device=device)\n",
    "                val_losses = torch.tensor([], dtype=torch.float32, device=device)\n",
    "\n",
    "\n",
    "                for val_data in val_loader:\n",
    "\n",
    "                    val_inputs, val_labels, val_IDH_labels = (\n",
    "                        val_data['image'].to(device),\n",
    "                        val_data['label'].to(device),\n",
    "                        val_data['IDH_label'].to(device),\n",
    "                    )\n",
    "                \n",
    "                    roi_size = patch_size #(32, 32, 32)\n",
    "                    sw_batch_size = 8\n",
    "                    val_overlap = 0.5\n",
    "                    mode=\"gaussian\"\n",
    "                            \n",
    "                    \n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        \n",
    "                        val_outputs = sliding_window_inference(val_inputs, roi_size, sw_batch_size, model, mode = mode, overlap = val_overlap, sw_device = device, device = device) \n",
    "                        #val_outputs = model(val_inputs)\n",
    "                        val_ce_loss = loss_function(val_outputs.unsqueeze(dim=1), val_labels)\n",
    "\n",
    "                    val_losses = torch.cat([val_losses, val_ce_loss.view(1)], dim = 0)\n",
    "                    val_outputs = torch.stack([post_pred(i) for i in torch.unbind(val_outputs, dim = 0)], dim = 0)\n",
    "                    \n",
    "                    \n",
    "                    #val_labels2hot = torch.stack([one_hot_permute(i) for i in torch.unbind(val_labels, dim = 0)], dim = 0)\n",
    "\n",
    "                    \n",
    "                    val_labels_bin = get_binarize_tensor(val_labels, dim=1)\n",
    "                    val_outputs_bin = get_binarize_tensor(val_outputs, dim=1)\n",
    "                    \n",
    "                    dice_metric(y_pred=val_outputs_bin, y=val_labels_bin)\n",
    "                    \n",
    "                    \n",
    "                    klcc = KeepLargestConnectedComponent(applied_labels = [0, 1])  ##is_onehot=True\n",
    "                    #val_labels = klcc(val_labels.squeeze(dim=0)).unsqueeze(dim=0)\n",
    "                    #val_outputs = klcc(val_outputs.squeeze(dim=0)).unsqueeze(dim=0)\n",
    "                    val_outputs = torch.stack([klcc(i) for i in torch.unbind(val_outputs, dim = 0)], dim = 0)\n",
    "                \n",
    "                    val_label4mSeg_C = get_segclass(val_outputs, dim = 1)\n",
    "                    #val_label4mSeg_C = getbatch_segclass(val_outputs)\n",
    "                    #val_surv_labels = val_surv_labels.squeeze(dim=1)  ###Squeezing from B, 1 to B if needed\n",
    "                    y_pred = torch.cat([y_pred, val_label4mSeg_C.view(1)], dim=0)\n",
    "                \n",
    "                    #pdb.set_trace()    \n",
    "                    val_IDH_labels = torch.mode(val_IDH_labels)[0].view(1)           \n",
    "                    y = torch.cat([y, val_IDH_labels], dim=0)\n",
    "\n",
    "                mdice_value = dice_metric.aggregate()\n",
    "                dice_metric.reset()\n",
    "                \n",
    "                \n",
    "                \n",
    "                y_pred, y = y_pred.cpu(), y.cpu()\n",
    "                \n",
    "                if torch.all(torch.isnan(y_pred))==True:\n",
    "                    \n",
    "                    auc_result, accscore, f1score = np.nan, np.nan, np.nan\n",
    "                    #print('acc_metric#', np.nan, ', auc#', np.nan, ', f1#', np.nan, '\\n')\n",
    "                \n",
    "                else:\n",
    "\n",
    "                    num_nanvalues = torch.isnan(y_pred).sum().item()\n",
    "                    not_nanmask = torch.logical_not(torch.isnan(y_pred))\n",
    "                    y = y[not_nanmask]\n",
    "                    y_pred = y_pred[not_nanmask]\n",
    "                    \n",
    "                    \n",
    "                    acc_value = torch.eq(y_pred, y)\n",
    "                    acc_metric = acc_value.sum().item() / len(acc_value)\n",
    "\n",
    "                    '''auc metric'''\n",
    "                    auc_metric(y_pred, y)\n",
    "                    auc_result = auc_metric.aggregate()\n",
    "                    auc_metric.reset()\n",
    "                    \n",
    "                    '''balanced accuracy and f1 score'''\n",
    "                    accscore = balanced_accuracy_score(y, y_pred)\n",
    "                    f1score = f1_score(y, y_pred, average='micro')\n",
    "                    #print('acc_metric#', acc_metric, ', auc#', auc_result, ', f1#', f1score, '\\n')\n",
    "                \n",
    "\n",
    "                del y, y_pred\n",
    "                \n",
    "            \n",
    "                epoch_val_losses=torch.mean(val_losses).detach().cpu().item()\n",
    "                #metric = auc_result\n",
    "                mdice_value = mdice_value.item()\n",
    "                #metric = mdice_value\n",
    "                metric = (mdice_value+auc_result)/2\n",
    "                metric= -1.0 if np.isnan(metric) else metric\n",
    "                metric_values.append(metric) ######List of over number of epochs\n",
    "                printstring = \"Best PMetric\"\n",
    "                \n",
    "\n",
    "                with open(logsfile_path, 'a') as file:\n",
    "                    file.write(\n",
    "                        f\"current fold: {cfold} current epoch: {epoch + 1} dice_score: {mdice_value:^{dispformat_specs}} acc_metric: {auc_result:^{dispformat_specs}}\" \n",
    "                        f\" accuracy: {accscore:^{dispformat_specs}}, f1score: {f1score:^{dispformat_specs}}\"\n",
    "                        f\" epoch {epoch + 1} average training loss: {epoch_loss:^{dispformat_specs}} average validation loss: {epoch_val_losses:^{dispformat_specs}} \\n\"\n",
    "\n",
    "                    )\n",
    "\n",
    "                if valstep < key_metric_n_saved:\n",
    "                    \n",
    "                    torch.save(model.state_dict(), os.path.join(save_dir, f\"{file_prefix}_Fold{cfold}_{metric:^{dispformat_specs}}_epoch{epoch + 1}.pth\"))\n",
    "                    print(\n",
    "                        f\"current fold: {cfold} current epoch: {epoch + 1} dice_score: {mdice_value:^{dispformat_specs}} acc_metric: {auc_result:^{dispformat_specs}}\" \n",
    "                        f\" accuracy: {accscore:^{dispformat_specs}}, f1score: {f1score:^{dispformat_specs}}\"\n",
    "                        f\" epoch {epoch + 1} average training loss: {epoch_loss:^{dispformat_specs}} average validation loss: {epoch_val_losses:^{dispformat_specs}}\"\n",
    "                        \n",
    "                    )\n",
    "\n",
    "                else:\n",
    "\n",
    "                    #sortmetric_values = sorted(metric_values[:-1], reverse=True)  ###Higher loss needs to be deleted, so sorting is reversed\n",
    "                    sortmetric_values = sorted(metric_values[:-1], reverse=False)  \n",
    "\n",
    "                    if metric>=sortmetric_values[-key_metric_n_saved]:\n",
    "                        savegood_metric = metric\n",
    "                        good_metric_epoch = epoch + 1\n",
    "\n",
    "                        #if os.path.exists(f\"{save_dir}/{file_prefix}_{sortmetric_values[-key_metric_n_saved]:.4f}.pth\"):\n",
    "                        #    os.remove(f\"{save_dir}/{file_prefix}_{sortmetric_values[-key_metric_n_saved]:.4f}.pth\")\n",
    "                        #else:\n",
    "                        #    print(\"The file does not exist\")\n",
    "                        \n",
    "                        \n",
    "                        glblist = glob.glob(f\"{save_dir}/{file_prefix}_Fold{cfold}_{sortmetric_values[-key_metric_n_saved]:^{dispformat_specs}}_*\")\n",
    "\n",
    "                        if not glblist:\n",
    "                            print(\"The file does not exist\")\n",
    "                        else:\n",
    "                            os.remove(glblist[0])\n",
    "\n",
    "\n",
    "                        torch.save(model.state_dict(), os.path.join(save_dir, f\"{file_prefix}_Fold{cfold}_{metric:^{dispformat_specs}}_epoch{epoch + 1}.pth\"))\n",
    "                        print(\"saved new best metric model\")\n",
    "                        print(\n",
    "                            f\"current fold: {cfold} current epoch: {epoch + 1} validation loss: {epoch_val_losses:^{dispformat_specs}}\"\n",
    "                            f\" dice_score: {mdice_value:^{dispformat_specs}} acc_metric: {auc_result:^{dispformat_specs}}\"\n",
    "                            f\" accuracy: {accscore:^{dispformat_specs}}, f1score: {f1score:^{dispformat_specs}}\"\n",
    "                            f\"\\n saved {printstring}: {savegood_metric:^{dispformat_specs}} at epoch: {good_metric_epoch}\"\n",
    "                        )\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        f\"current fold: {cfold} current epoch: {epoch + 1} validation loss: {epoch_val_losses:^{dispformat_specs}}\"\n",
    "                        f\" dice_score: {mdice_value:^{dispformat_specs}} acc_metric: {auc_result:^{dispformat_specs}}\"\n",
    "                        f\" accuracy: {accscore:^{dispformat_specs}}, f1score: {f1score:^{dispformat_specs}}\"\n",
    "\n",
    "                        #pass\n",
    "\n",
    "                valstep += 1\n",
    "        ####Saving last epoch\n",
    "        if epoch==epoch_num-1:\n",
    "            if save_last:\n",
    "                torch.save(model.state_dict(), os.path.join(save_dir, f\"{file_prefix}_Fold{cfold}_{metric:^{dispformat_specs}}_last_epoch{epoch + 1}.pth\"))\n",
    "                \n",
    "            #break\n",
    "            \n",
    "    # Free up GPU memory after training\n",
    "    model = None\n",
    "    train_loader, val_loader = None, None\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99dd55d4",
   "metadata": {},
   "source": [
    "### Loop to execute n_splits=3 fold cross validation\n",
    "if the model is trained and the checkpoints are saved already, just setting the start_training flag as false, to run remaining part of the programs of this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4d34db5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "68c97f32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_splits = 3\n",
    "if start_training:\n",
    "    #### Running 10 folds\n",
    "    for i in range(0, n_splits):\n",
    "        \n",
    "        #train_files_fld, train_files_fld_IDH_label, val_files_fld, val_files_fld_IDH_label  = copy.deepcopy(train_folds[f'fold{i}']), copy.deepcopy(train_folds[f'fold{i}_IDH_label']),\\\n",
    "        #copy.deepcopy(val_folds[f'fold{i}']), copy.deepcopy(val_folds[f'fold{i}_IDH_label'])\n",
    "             \n",
    "        train_files_fld, val_files_fld  = copy.deepcopy(BraTS20SubjectsIDHTrainDCT[f'fold{i}']), copy.deepcopy(BraTS20SubjectsIDHValDCT[f'fold{i}'])\n",
    "        train_files_fld_IDH_label, val_files_fld_IDH_label = None, None\n",
    "        batch_size=8\n",
    "        ### Need to change batch size if minimux training batch size == 1\n",
    "        print('fold', i, \"Bacth Investigation, minimum batch size\", len(train_files_fld)%batch_size)        \n",
    "        #train(train_files_fld, train_files_fld_IDH_label, val_files_fld, val_files_fld_IDH_label, batch_size=batch_size, epochs = 200, cfold = i)\n",
    "        train(train_files_fld, train_files_fld_IDH_label, val_files_fld, val_files_fld_IDH_label, batch_size=batch_size, epochs = 500, cfold = i, transfer_modelPath = None)\n",
    "    \n",
    "    start_training = False\n",
    "else:\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f81e07e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.datasets import make_multilabel_classification\n",
    "# from sklearn.multioutput import MultiOutputClassifier\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# X, y = make_multilabel_classification(random_state=0, n_classes=2)\n",
    "# inner_clf = LogisticRegression(solver=\"liblinear\", random_state=0)\n",
    "# clf = MultiOutputClassifier(inner_clf).fit(X, y)\n",
    "# y_score = np.transpose([y_pred[:, 1] for y_pred in clf.predict_proba(X)])\n",
    "# roc_auc_score(y, y_score, average=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c989bbd",
   "metadata": {},
   "source": [
    "## Inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1eff6698",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inferWithTA(data_loader,listmodels, prediction_folder=\"./\", topk=1, num_channels = 4,\\\n",
    "                orientation=\"LPS\", withoptimizer = False, softmaxEnsemble=False, save_inference = False, tta = False):\n",
    "    \"\"\"\n",
    "    run inference, the output folder will be \"./output\"\n",
    "    \"\"\"        \n",
    "    #device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    listmodels = listmodels[0:topk]\n",
    "    for x in listmodels:\n",
    "        print(f\"available model file: {x}.\")\n",
    "        \n",
    "    channel_nums =  monai.utils.misc.first(data_loader)['image'].shape[1] ##next(iter(val_loader[\"image\"])).shape[1]\n",
    "    channelNums = f\"{channel_nums} channels\"\n",
    "    keys = ('image',)\n",
    "    patch_size = (32, 32, 32)\n",
    "    \n",
    "    post_trans_sigbin = Compose([EnsureType(), Activations(sigmoid=True), AsDiscrete(threshold=0.5)])\n",
    "    post_trans_bin = Compose([EnsureType(), AsDiscrete(threshold=0.5)])\n",
    "    post_trans_sig = Compose([EnsureType(), Activations(sigmoid=True)])\n",
    "    \n",
    "    auc_metric = ROCAUCMetric()\n",
    "    dice_metric = monai.metrics.DiceMetric(include_background=True, reduction='mean', get_not_nans=False)\n",
    "    dice_metric_batch = monai.metrics.DiceMetric(include_background=True, reduction='mean_batch', get_not_nans=False)\n",
    "    \n",
    "    \n",
    "    HD_metric = HausdorffDistanceMetric(include_background=True, percentile = 95., reduction='mean', get_not_nans=False)\n",
    "    HD_metric_batch = HausdorffDistanceMetric(include_background=True, percentile = 95., reduction='mean_batch', get_not_nans=False)\n",
    "    \n",
    "    \n",
    "    \n",
    "    post_pred = Compose([Activations(sigmoid=True), AsDiscrete(threshold=0.5)])  \n",
    "    \n",
    "    def one_hot_permute(x):\n",
    "        return F.one_hot(x.squeeze(dim=0).long(), num_classes=num_classes).permute(3, 0, 1, 2)\n",
    "    \n",
    "    def get_binarize_tensor(x, dim=1):\n",
    "        x_chlist = torch.unbind(x, dim = dim)\n",
    "        bin_x = torch.zeros_like(x_chlist[0])\n",
    "        for x_i in x_chlist:\n",
    "            bin_x = torch.logical_or(x_i, bin_x)\n",
    "        return bin_x.unsqueeze(dim=dim).to(torch.float32)\n",
    "        \n",
    "    def get_segclass(x, dim = 1):\n",
    "        xdvc = x.device\n",
    "        x_chlist = torch.unbind(x, dim = dim)\n",
    "        xclassNoList = []\n",
    "        xvalueList = []\n",
    "\n",
    "        for x_i in x_chlist:\n",
    "\n",
    "            xv, xc = torch.unique(x_i, return_counts  = True)\n",
    "\n",
    "            if xc.shape[0]==1:\n",
    "                if xv==0:\n",
    "                    xclassNoList.append(-1)\n",
    "                    xvalueList.append(xv[0].item())\n",
    "                elif xv==1:\n",
    "                    xclassNoList.append(xc[0].item())\n",
    "                    xvalueList.append(xv[0].item())\n",
    "                else:\n",
    "                    print('The function only supports binarized tensor (binarized unique values, 0(n=...) and 1(n=...) only)\\n')\n",
    "\n",
    "\n",
    "            elif xc.shape[0]==2:\n",
    "                    if torch.any(torch.eq(xv, 1)):\n",
    "                        xclassNoList.append(xc[1].item())\n",
    "                        xvalueList.append(xv[1].item())\n",
    "                    else:\n",
    "                        print('The function only supports binarized tensor (binarized unique values, 0(n=...) and 1(n=...) only)\\n')\n",
    "            else:\n",
    "                print('The function only supports binarized tensor (binarized unique values, 0(n=...) and 1(n=...) only)\\n')\n",
    "\n",
    "        #pdb.set_trace()\n",
    "        #if torch.any(torch.eq(torch.tensor(xvalueList), 1)):\n",
    "\n",
    "        if xclassNoList[0]!=xclassNoList[1]: \n",
    "            xclass = torch.argmax(torch.tensor(xclassNoList).to(xdvc))\n",
    "        else:\n",
    "            xclass = torch.tensor(float('NaN')).to(xdvc)\n",
    "\n",
    "        #else:\n",
    "            '''If all uniques class values are 0, we are assigning nan values as a class'''\n",
    "        #    xclass = torch.tensor(float('NaN')).to(xdvc)\n",
    "\n",
    "\n",
    "        return xclass\n",
    "    \n",
    "    \n",
    "    \n",
    "    keys = (\"image\",)\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        y_pred = torch.tensor([], dtype=torch.float32, device=device)\n",
    "        y = torch.tensor([], dtype=torch.long, device=device)\n",
    "    \n",
    "        for infindx, infer_data in enumerate(tqdm(data_loader)):\n",
    "\n",
    "            \n",
    "            val_inputs, val_labels, val_IDH_labels = (\n",
    "                infer_data['image'].to(device),\n",
    "                infer_data['label'].to(device),\n",
    "                infer_data['IDH_label'].to(device),\n",
    "            )\n",
    "                \n",
    "\n",
    "            n_class = 2\n",
    "            val_outputsAll = torch.zeros(val_inputs.shape[0], n_class, val_inputs.shape[2], val_inputs.shape[3], val_inputs.shape[4]).to(device)\n",
    "            n_model = 0.\n",
    "            \n",
    "            #for mdlindx in (number+1 for number in range(topk)):\n",
    "            for mdlindx in range(topk):\n",
    "    \n",
    "                print(f'Model {mdlindx}, {listmodels[mdlindx]} is running now')\n",
    "                model = None        \n",
    "                num_classes = 2\n",
    "                model = DynUOneEncodAttn(num_classes=num_classes, num_input_channels=2, base_filters=32).to(device)\n",
    "                \n",
    "            \n",
    "                if withoptimizer ==True:\n",
    "                    \n",
    "                    state_dictsAll = torch.load(listmodels[mdlindx], map_location=device)\n",
    "                    model.load_state_dict(state_dictsAll[\"model_state_dict\"])\n",
    "                    model.eval()\n",
    "                \n",
    "                else:    \n",
    "                    model.load_state_dict(torch.load(listmodels[mdlindx], map_location=device))\n",
    "                    model.eval()\n",
    "                \n",
    "                \n",
    "                n = 1.0\n",
    "                roi_size = patch_size #(32, 32, 32)\n",
    "                sw_batch_size = 8\n",
    "                val_overlap = 0.5\n",
    "                mode=\"gaussian\"\n",
    "                \n",
    "                with torch.cuda.amp.autocast():\n",
    "\n",
    "                    preds = sliding_window_inference(val_inputs, roi_size, sw_batch_size, model, mode = mode, overlap = val_overlap, sw_device = device, device = device)\n",
    "                    \n",
    "                flip_val_inputs = torch.flip(val_inputs, dims=(2, 3, 4))\n",
    "                \n",
    "                with torch.cuda.amp.autocast():\n",
    "                    \n",
    "                    mfpred = sliding_window_inference(flip_val_inputs, roi_size, sw_batch_size, model, mode = mode, overlap = val_overlap, sw_device = device, device = device)\n",
    "                 \n",
    "                flip_pred = torch.flip(mfpred, dims=(2, 3, 4))\n",
    "                preds  = preds + flip_pred\n",
    "                n = n + 1.0\n",
    "                \n",
    "                if tta:\n",
    "                    \n",
    "                    for _ in range(4):\n",
    "                        # test time augmentations\n",
    "                        _img = RandGaussianNoised(keys[0], prob=1.0, std=0.01)(infer_data)[keys[0]]\n",
    "\n",
    "\n",
    "                        with torch.cuda.amp.autocast():\n",
    "\n",
    "                            #val_outputs = sliding_window_inference(val_inputs, roi_size, sw_batch_size, model, sw_device = device, device = device)\n",
    "                            _img_pred = sliding_window_inference(_img.to(device), roi_size, sw_batch_size, model, mode = mode, overlap = val_overlap, sw_device = device, device = device)\n",
    "                            preds = preds + _img_pred\n",
    "                            n = n + 1.0\n",
    "\n",
    "\n",
    "                        _img_flip = torch.flip(_img, dims=(2, 3, 4)) \n",
    "                        with torch.cuda.amp.autocast():\n",
    "                            _mf_flip_pred = sliding_window_inference(_img_flip.to(device), roi_size, sw_batch_size, model, mode = mode, overlap = val_overlap, sw_device = device, device = device)\n",
    "\n",
    "                        _img_flip_pred = torch.flip(_mf_flip_pred, dims=(2, 3, 4))\n",
    "                        preds = preds + _img_flip_pred\n",
    "                        n = n + 1.0\n",
    "                 \n",
    "                \n",
    "                preds = preds / n\n",
    "                \n",
    "                if softmaxEnsemble:\n",
    "                    preds = torch.stack([post_trans_sig(i) for i in torch.unbind(preds, dim = 0)], dim = 0)\n",
    "                val_outputsAll = val_outputsAll + preds\n",
    "                n_model = n_model+1.0\n",
    "                \n",
    "                # Free up GPU memory after training\n",
    "                model = None\n",
    "                del model\n",
    "                #train_loader, val_loader = None, None        \n",
    "                gc.collect()\n",
    "                torch.cuda.empty_cache()\n",
    "                           \n",
    "            val_outputsAll = val_outputsAll / n_model\n",
    "            \n",
    "            val_outputs = post_trans_bin(val_outputsAll) if softmaxEnsemble else post_trans_sigbin(val_outputsAll)\n",
    "            '''Sigmoid or logit'''\n",
    "            val_outputsSig = val_outputsAll if softmaxEnsemble else post_trans_sig(val_outputsAll)\n",
    "            #val_outputsSig = val_outputsAll\n",
    "            \n",
    "            \n",
    "\n",
    "            #val_labels2hot = torch.stack([one_hot_permute(i) for i in torch.unbind(val_labels, dim = 0)], dim = 0)\n",
    "\n",
    "\n",
    "            val_labels_bin = get_binarize_tensor(val_labels, dim=1)\n",
    "            val_outputs_bin = get_binarize_tensor(val_outputs, dim=1)\n",
    "\n",
    "            dice_metric(y_pred=val_outputs_bin, y=val_labels_bin)\n",
    "\n",
    "            klcc = KeepLargestConnectedComponent(applied_labels = [0, 1], is_onehot = True)  ##is_onehot=True or None by default\n",
    "            #val_labels = klcc(val_labels.squeeze(dim=0)).unsqueeze(dim=0)\n",
    "            val_labels = torch.stack([klcc(i) for i in torch.unbind(val_labels, dim = 0)], dim = 0)\n",
    "\n",
    "            val_label4mSeg_C = get_segclass(val_outputs)\n",
    "            #val_surv_labels = val_surv_labels.squeeze(dim=1)  ###Squeezing from B, 1 to B if needed\n",
    "            y_pred = torch.cat([y_pred, val_label4mSeg_C.view(1)], dim=0)\n",
    "            y = torch.cat([y, val_IDH_labels], dim=0)\n",
    "                \n",
    "                        \n",
    "            \n",
    "        mdice_value = dice_metric.aggregate().item()\n",
    "        dice_metric.reset()        \n",
    "        \n",
    "        \n",
    "        y_pred, y = y_pred.cpu(), y.cpu()\n",
    "\n",
    "        if torch.all(torch.isnan(y_pred))==True:\n",
    "\n",
    "            auc_result, baccscore, f1score, rscore, pscore, justaccscore = np.nan, np.nan, np.nan, np.nan, np.nan, np.nan\n",
    "            specificity_score, sensitivity_score = np.nan, np.nan\n",
    "            #print('acc_metric#', np.nan, ', auc#', np.nan, ', f1#', np.nan, '\\n')\n",
    "            num_nanvalues = len(y_pred)\n",
    "\n",
    "        else:\n",
    "\n",
    "            num_nanvalues = torch.isnan(y_pred).sum().item()\n",
    "            not_nanmask = torch.logical_not(torch.isnan(y_pred))\n",
    "            y = y[not_nanmask]\n",
    "            y_pred = y_pred[not_nanmask]\n",
    "\n",
    "\n",
    "            acc_value = torch.eq(y_pred, y)\n",
    "            acc_metric = acc_value.sum().item() / len(acc_value)\n",
    "            \n",
    "            \n",
    "            '''auc metric'''\n",
    "            auc_metric(y_pred, y)\n",
    "            auc_result = auc_metric.aggregate()\n",
    "            auc_metric.reset()\n",
    "            \n",
    "            y_pred, y = y_pred.numpy(), y.numpy()\n",
    "\n",
    "            '''balanced accuracy and f1 score'''\n",
    "            baccscore = balanced_accuracy_score(y, y_pred)\n",
    "            f1score = f1_score(y, y_pred, average='micro')\n",
    "            rscore=recall_score(y, y_pred)\n",
    "            pscore = precision_score(y, y_pred)\n",
    "            justaccscore = accuracy_score(y, y_pred)\n",
    "            #print('acc_metric#', acc_metric, ', auc#', auc_result, ', f1#', f1score, '\\n')\n",
    "            tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()\n",
    " \n",
    "            #specificity_score = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "            #sensitivity_score = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "            \n",
    "            specificity_score = tn/(tn + fp)\n",
    "            sensitivity_score = tp/(tp + fn)\n",
    "\n",
    "\n",
    "        del y, y_pred\n",
    "        \n",
    "\n",
    "        \n",
    "        #Accuracy (%) Precision (%) Sensitivity(%) Specificity(%) F1-Score(%)\n",
    "        \n",
    "        aDCT = {\"dice_score\": mdice_value,  \"Balanced Accuracy\": baccscore, 'Precision': pscore, 'Recall':rscore, 'Sensitivity':sensitivity_score, 'Specificity':specificity_score,\\\n",
    "                'F1-Score':f1score, 'Accuracy':justaccscore, 'AUC Metric':auc_result, 'NanSubjectNos':num_nanvalues}\n",
    "        \n",
    "                    \n",
    "#     dfET = pd.DataFrame({\"BraTS21ID\":Infer_idLst, \"Model\": [\"DynUnet\"]* len(ETdices), \"Channels\":[channelNums]*len(ETdices), \"Tumor regions\": [\"ET\"]*len(ETdices), \"Dice score\": ETdices, \"HD95\": ETHD95s})\n",
    "#     dfTC = pd.DataFrame({\"BraTS21ID\":Infer_idLst, \"Model\": [\"DynUnet\"]* len(TCdices), \"Channels\":[channelNums]*len(TCdices), \"Tumor regions\": [\"TC\"]*len(TCdices), \"Dice score\": TCdices, \"HD95\": TCHD95s})\n",
    "#     dfWT = pd.DataFrame({\"BraTS21ID\":Infer_idLst,\"Model\": [\"DynUnet\"]* len(WTdices), \"Channels\":[channelNums]*len(WTdices), \"Tumor regions\": [\"WT\"]*len(WTdices), \"Dice score\": WTdices, \"HD95\": WTHD95s})\n",
    "#     dfWT_TC_ET = pd.DataFrame({\"BraTS21ID\":Infer_idLst,\"Model\": [\"DynUnet\"]* len(WTdices), \"Channels\":[channelNums]*len(WTdices), \"Tumor regions\": [\"WT_TC_ET_Regions\"]*len(WTdices), \"Dice score\": Alldices, \"HD95\": AllHD95s})\n",
    "    \n",
    "#     dfRegions = pd.concat([dfTC, dfWT, dfET, dfWT_TC_ET])\n",
    "#     return dfRegions\n",
    "\n",
    "\n",
    "    return aDCT\n",
    "\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6cf92e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fold0': ['/raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth'],\n",
       " 'fold1': ['/raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold1_0.7317_epoch333.pth'],\n",
       " 'fold2': ['/raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold2_0.8145_epoch188.pth']}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_folder = f'{save_dir}/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand' \n",
    "# modelDCTList = {'fold0': [glob.glob(f'{save_dir}/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7870_epoch469.pt*')[0],\n",
    "#                           glob.glob(f'{save_dir}/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pt*')[0]],\\\n",
    "#                'fold1':[glob.glob(f'{save_dir}/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold1_0.7317_epoch333.pt*')[0],\n",
    "#                         glob.glob(f'{save_dir}/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold1_0.7479_epoch335.pt*')[0]],\\\n",
    "#                'fold2':[glob.glob(f'{save_dir}/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold2_0.8145_epoch188.pt*')[0],\n",
    "#                         glob.glob(f'{save_dir}/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold2_0.8179_epoch163.pt*')[0]]}\n",
    "\n",
    "modelDCTList = {'fold0': glob.glob(f'{save_dir}/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pt*'),\\\n",
    "               'fold1':glob.glob(f'{save_dir}/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold1_0.7317_epoch333.pt*'),\\\n",
    "               'fold2':glob.glob(f'{save_dir}/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold2_0.8145_epoch188.pt**')}\n",
    "\n",
    "modelDCTList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76d1f70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "230d6a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_inference = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4de208d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "available model file: /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Modifying image pixdim from [1. 1. 1. 1.] to [  1.           1.           1.         239.00209204]\n",
      "  0%|                                                                                                                                 | 0/122 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▉                                                                                                                        | 1/122 [00:07<15:31,  7.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▉                                                                                                                       | 2/122 [00:16<16:32,  8.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|██▉                                                                                                                      | 3/122 [00:20<12:56,  6.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|███▉                                                                                                                     | 4/122 [00:26<12:13,  6.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|████▉                                                                                                                    | 5/122 [00:29<09:55,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|█████▉                                                                                                                   | 6/122 [00:33<09:15,  4.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|██████▉                                                                                                                  | 7/122 [00:37<08:38,  4.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|███████▉                                                                                                                 | 8/122 [00:43<09:12,  4.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|████████▉                                                                                                                | 9/122 [00:47<08:26,  4.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|█████████▊                                                                                                              | 10/122 [00:51<08:25,  4.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|██████████▊                                                                                                             | 11/122 [00:55<08:09,  4.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████████▊                                                                                                            | 12/122 [01:01<08:43,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████████████▊                                                                                                           | 13/122 [01:09<10:40,  5.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█████████████▊                                                                                                          | 14/122 [01:14<10:10,  5.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████████████▊                                                                                                         | 15/122 [01:19<09:44,  5.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|███████████████▋                                                                                                        | 16/122 [01:25<09:35,  5.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████████▋                                                                                                       | 17/122 [01:30<09:13,  5.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████████████████▋                                                                                                      | 18/122 [01:36<09:53,  5.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████████████████▋                                                                                                     | 19/122 [01:42<09:58,  5.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|███████████████████▋                                                                                                    | 20/122 [01:47<09:14,  5.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|████████████████████▋                                                                                                   | 21/122 [01:52<08:55,  5.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█████████████████████▋                                                                                                  | 22/122 [01:58<09:18,  5.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|██████████████████████▌                                                                                                 | 23/122 [02:02<08:11,  4.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████████████▌                                                                                                | 24/122 [02:06<07:39,  4.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████████████▌                                                                                               | 25/122 [02:13<08:43,  5.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|█████████████████████████▌                                                                                              | 26/122 [02:18<08:35,  5.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██████████████████████████▌                                                                                             | 27/122 [02:24<08:46,  5.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|███████████████████████████▌                                                                                            | 28/122 [02:30<08:57,  5.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|████████████████████████████▌                                                                                           | 29/122 [02:37<09:15,  5.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|█████████████████████████████▌                                                                                          | 30/122 [02:42<08:33,  5.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██████████████████████████████▍                                                                                         | 31/122 [02:46<08:08,  5.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|███████████████████████████████▍                                                                                        | 32/122 [02:50<07:21,  4.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|████████████████████████████████▍                                                                                       | 33/122 [02:58<08:23,  5.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|█████████████████████████████████▍                                                                                      | 34/122 [03:02<07:47,  5.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██████████████████████████████████▍                                                                                     | 35/122 [03:07<07:20,  5.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███████████████████████████████████▍                                                                                    | 36/122 [03:10<06:43,  4.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████████████████▍                                                                                   | 37/122 [03:18<08:04,  5.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|█████████████████████████████████████▍                                                                                  | 38/122 [03:25<08:28,  6.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|██████████████████████████████████████▎                                                                                 | 39/122 [03:32<08:24,  6.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███████████████████████████████████████▎                                                                                | 40/122 [03:35<07:25,  5.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|████████████████████████████████████████▎                                                                               | 41/122 [03:44<08:44,  6.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|█████████████████████████████████████████▎                                                                              | 42/122 [03:50<08:12,  6.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|██████████████████████████████████████████▎                                                                             | 43/122 [03:54<07:12,  5.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███████████████████████████████████████████▎                                                                            | 44/122 [03:59<07:05,  5.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|████████████████████████████████████████████▎                                                                           | 45/122 [04:10<09:12,  7.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|█████████████████████████████████████████████▏                                                                          | 46/122 [04:17<08:51,  6.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|██████████████████████████████████████████████▏                                                                         | 47/122 [04:26<09:33,  7.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███████████████████████████████████████████████▏                                                                        | 48/122 [04:30<07:58,  6.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████████████████████████████████████████████████▏                                                                       | 49/122 [04:34<06:58,  5.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|█████████████████████████████████████████████████▏                                                                      | 50/122 [04:39<06:45,  5.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|██████████████████████████████████████████████████▏                                                                     | 51/122 [04:45<06:37,  5.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|███████████████████████████████████████████████████▏                                                                    | 52/122 [04:48<05:44,  4.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████████████████████████████████████████████████████▏                                                                   | 53/122 [04:58<07:31,  6.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|█████████████████████████████████████████████████████                                                                   | 54/122 [05:06<07:48,  6.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|██████████████████████████████████████████████████████                                                                  | 55/122 [05:09<06:30,  5.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|███████████████████████████████████████████████████████                                                                 | 56/122 [05:17<07:08,  6.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████████████████████████████████████████████████████████                                                                | 57/122 [05:23<06:44,  6.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|█████████████████████████████████████████████████████████                                                               | 58/122 [05:26<05:40,  5.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|██████████████████████████████████████████████████████████                                                              | 59/122 [05:30<05:06,  4.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|███████████████████████████████████████████████████████████                                                             | 60/122 [05:34<04:41,  4.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████████████████████████████████████████████████████████████                                                            | 61/122 [05:37<04:21,  4.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|████████████████████████████████████████████████████████████▉                                                           | 62/122 [05:42<04:14,  4.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████████████████████████████████████████████████████████████▉                                                          | 63/122 [05:45<03:54,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|██████████████████████████████████████████████████████████████▉                                                         | 64/122 [05:52<04:36,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|███████████████████████████████████████████████████████████████▉                                                        | 65/122 [05:55<04:06,  4.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|████████████████████████████████████████████████████████████████▉                                                       | 66/122 [06:01<04:25,  4.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████████████████████████████████████████████████████████████████▉                                                      | 67/122 [06:09<05:25,  5.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|██████████████████████████████████████████████████████████████████▉                                                     | 68/122 [06:13<04:43,  5.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|███████████████████████████████████████████████████████████████████▊                                                    | 69/122 [06:20<05:03,  5.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|████████████████████████████████████████████████████████████████████▊                                                   | 70/122 [06:25<04:49,  5.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████████████████████████████████████████████████████████████████████▊                                                  | 71/122 [06:29<04:15,  5.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|██████████████████████████████████████████████████████████████████████▊                                                 | 72/122 [06:34<04:22,  5.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|███████████████████████████████████████████████████████████████████████▊                                                | 73/122 [06:39<04:00,  4.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|████████████████████████████████████████████████████████████████████████▊                                               | 74/122 [06:43<03:53,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|█████████████████████████████████████████████████████████████████████████▊                                              | 75/122 [06:47<03:37,  4.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████████████████████████████████████████████████████████████████████████▊                                             | 76/122 [06:51<03:17,  4.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|███████████████████████████████████████████████████████████████████████████▋                                            | 77/122 [06:57<03:33,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|████████████████████████████████████████████████████████████████████████████▋                                           | 78/122 [07:03<03:45,  5.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|█████████████████████████████████████████████████████████████████████████████▋                                          | 79/122 [07:07<03:33,  4.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████████████████████████████████████████████████████████████████████████████▋                                         | 80/122 [07:11<03:11,  4.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|███████████████████████████████████████████████████████████████████████████████▋                                        | 81/122 [07:17<03:21,  4.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|████████████████████████████████████████████████████████████████████████████████▋                                       | 82/122 [07:24<03:41,  5.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|█████████████████████████████████████████████████████████████████████████████████▋                                      | 83/122 [07:28<03:22,  5.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████████████████████████████████████████████████████████████████████████████████▌                                     | 84/122 [07:33<03:19,  5.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████████████████████████████████████████████████████████████████████████████████▌                                    | 85/122 [07:39<03:14,  5.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|████████████████████████████████████████████████████████████████████████████████████▌                                   | 86/122 [07:42<02:45,  4.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|█████████████████████████████████████████████████████████████████████████████████████▌                                  | 87/122 [07:47<02:46,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|██████████████████████████████████████████████████████████████████████████████████████▌                                 | 88/122 [07:51<02:34,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████████████████████████████████████████████████████████████████████████████████████▌                                | 89/122 [07:55<02:20,  4.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|████████████████████████████████████████████████████████████████████████████████████████▌                               | 90/122 [07:59<02:21,  4.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|█████████████████████████████████████████████████████████████████████████████████████████▌                              | 91/122 [08:06<02:37,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|██████████████████████████████████████████████████████████████████████████████████████████▍                             | 92/122 [08:10<02:25,  4.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████████████████████████████████████████████████████████████████████████████████████████▍                            | 93/122 [08:15<02:17,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|████████████████████████████████████████████████████████████████████████████████████████████▍                           | 94/122 [08:19<02:10,  4.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|█████████████████████████████████████████████████████████████████████████████████████████████▍                          | 95/122 [08:24<02:04,  4.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|██████████████████████████████████████████████████████████████████████████████████████████████▍                         | 96/122 [08:28<01:56,  4.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████████████████████████████████████████████████████████████████████████████████████████████▍                        | 97/122 [08:32<01:47,  4.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████████████████████████████████████████████████████████████████████▍                       | 98/122 [08:36<01:39,  4.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|█████████████████████████████████████████████████████████████████████████████████████████████████▍                      | 99/122 [08:40<01:36,  4.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|█████████████████████████████████████████████████████████████████████████████████████████████████▌                     | 100/122 [08:44<01:28,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|██████████████████████████████████████████████████████████████████████████████████████████████████▌                    | 101/122 [08:48<01:29,  4.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|███████████████████████████████████████████████████████████████████████████████████████████████████▍                   | 102/122 [08:51<01:18,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████████████████████████████████████████████████████████████████████████████████████████████████▍                  | 103/122 [08:55<01:11,  3.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|█████████████████████████████████████████████████████████████████████████████████████████████████████▍                 | 104/122 [08:59<01:11,  3.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|██████████████████████████████████████████████████████████████████████████████████████████████████████▍                | 105/122 [09:04<01:11,  4.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|███████████████████████████████████████████████████████████████████████████████████████████████████████▍               | 106/122 [09:08<01:06,  4.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████▎              | 107/122 [09:12<01:01,  4.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▎             | 108/122 [09:17<00:58,  4.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▎            | 109/122 [09:21<00:53,  4.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▎           | 110/122 [09:24<00:48,  4.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▎          | 111/122 [09:31<00:53,  4.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▏         | 112/122 [09:36<00:47,  4.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▏        | 113/122 [09:39<00:39,  4.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▏       | 114/122 [09:48<00:44,  5.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏      | 115/122 [09:52<00:36,  5.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏     | 116/122 [09:56<00:29,  4.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████     | 117/122 [10:00<00:22,  4.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████    | 118/122 [10:05<00:19,  4.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████   | 119/122 [10:09<00:13,  4.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████  | 120/122 [10:12<00:08,  4.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████ | 121/122 [10:16<00:03,  3.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, /raid/brats2021/pthTCGA_1p19q_CoDeletion/DynUNetVariants_TCGA/AttnDynUNet_BratsTCGA_1p19q_3CV_2ChnlsMorePatch_OnlyWSampler_Infer1PatchSWIRngr21_2nRatioclass_HistStand_Fold0_0.7880_epoch430.pth is running now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 122/122 [10:20<00:00,  5.08s/it]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'confusion_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [58]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m infer_dataset_fld \u001b[38;5;241m=\u001b[39m monai\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset(data\u001b[38;5;241m=\u001b[39minfer_files_fld, transform\u001b[38;5;241m=\u001b[39mval_transforms)\n\u001b[1;32m     13\u001b[0m infer_loader_fld \u001b[38;5;241m=\u001b[39m monai\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(infer_dataset_fld, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;66;03m#num_workers=2, pin_memory=True\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m aDCTResult \u001b[38;5;241m=\u001b[39m \u001b[43minferWithTA\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minfer_loader_fld\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlistmodels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodelDCTList\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfold\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprediction_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtopk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodelDCTList\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfold\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m            \u001b[49m\u001b[43morientation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLPS\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwithoptimizer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msoftmaxEnsemble\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtta\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m aDCTResult[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTestSplitName\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     18\u001b[0m aDCTResultList\u001b[38;5;241m.\u001b[39mappend(aDCTResult\u001b[38;5;241m.\u001b[39mcopy())\n",
      "Input \u001b[0;32mIn [55]\u001b[0m, in \u001b[0;36minferWithTA\u001b[0;34m(data_loader, listmodels, prediction_folder, topk, num_channels, orientation, withoptimizer, softmaxEnsemble, save_inference, tta)\u001b[0m\n\u001b[1;32m    254\u001b[0m justaccscore \u001b[38;5;241m=\u001b[39m accuracy_score(y, y_pred)\n\u001b[1;32m    255\u001b[0m \u001b[38;5;66;03m#print('acc_metric#', acc_metric, ', auc#', auc_result, ', f1#', f1score, '\\n')\u001b[39;00m\n\u001b[0;32m--> 256\u001b[0m tn, fp, fn, tp \u001b[38;5;241m=\u001b[39m \u001b[43mconfusion_matrix\u001b[49m(y, y_pred)\u001b[38;5;241m.\u001b[39mravel()\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m#specificity_score = cm1[0,0]/(cm1[0,0]+cm1[0,1])\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m#sensitivity_score = cm1[1,1]/(cm1[1,0]+cm1[1,1])\u001b[39;00m\n\u001b[1;32m    261\u001b[0m specificity_score \u001b[38;5;241m=\u001b[39m tn\u001b[38;5;241m/\u001b[39m(tn \u001b[38;5;241m+\u001b[39m fp)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'confusion_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "n_splits = 3\n",
    "aDCTResultList = list()\n",
    "if start_inference:\n",
    "    #### Running 10 folds\n",
    "    for i in range(0, n_splits):\n",
    "        \n",
    "\n",
    "        \n",
    "        infer_files_fld = copy.deepcopy(BraTS20SubjectsIDHTestDCT[f'fold{i}'])\n",
    "        \n",
    "        infer_dataset_fld = monai.data.Dataset(data=infer_files_fld, transform=val_transforms)\n",
    "       \n",
    "        infer_loader_fld = monai.data.DataLoader(infer_dataset_fld, batch_size=1, shuffle=False) #num_workers=2, pin_memory=True\n",
    "        \n",
    "        aDCTResult = inferWithTA(data_loader = infer_loader_fld, listmodels=modelDCTList[f'fold{i}'], prediction_folder=prediction_folder, topk=len(modelDCTList[f'fold{i}']), num_channels=4,\\\n",
    "                    orientation=\"LPS\", withoptimizer = False, softmaxEnsemble= True, tta = True)\n",
    "        aDCTResult['TestSplitName'] = f\"split{i}\"\n",
    "        aDCTResultList.append(aDCTResult.copy())\n",
    "        \n",
    "    \n",
    "    start_inference = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82199d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Result on the testset (3 testsest from 3 splits)')\n",
    "DFResult = pd.DataFrame.from_dict(aDCTResultList)\n",
    "display(DFResult)\n",
    "DFResult.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472d7671",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca4e65de",
   "metadata": {},
   "source": [
    "# roc_auc_score(y, y_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77caef8",
   "metadata": {},
   "source": [
    "#### Section for testing the user-defined functions and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6079ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_permute(x):\n",
    "    return F.one_hot(x.squeeze(dim=0).long(), num_classes=3).permute(2, 0, 1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4991f64a",
   "metadata": {},
   "source": [
    "atensor = torch.tensor([[[0, 2, 0, 0],[0, 0, 0, 2],[0, 2, 0, 0]]])\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9f7f79e6",
   "metadata": {},
   "source": [
    "one_hot_permute(atensor)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b9aeca48",
   "metadata": {},
   "source": [
    "atensor = torch.tensor([[[0, 1, 0, 0],[0, 0, 0, 1],[0, 1, 0, 0]]])\n",
    "one_hot_permute(atensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b792d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xc= torch.tensor([0, 1, 0, 0, 2, 3, 10])\n",
    "if torch.any(torch.eq(xc, 11)):\n",
    "    print('Do')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de71bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "xc = torch.tensor([0, 100, 500, 10000, 5])\n",
    "torch.argmax(xc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29af25ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.argsort(xc)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe1940f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "is_onehot = True\n",
    "img = torch.ones((1, 64, 64, 64))\n",
    "is_onehot2 = img.shape[0] > 1 if is_onehot is None else is_onehot\n",
    "is_onehot2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d4058e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = np.array([[1.]])\n",
    "dd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3500f400",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = np.stack([dd, dd], axis = 0)\n",
    "dx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e456bc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate([dx, dx], axis = 0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ebe528",
   "metadata": {},
   "outputs": [],
   "source": [
    "P1=torch.tensor([[0, 1, 1, 1,  0, 0, 0, 0, 0]])\n",
    "P2=torch.tensor([[0, 1, 1, 1,   0, 0, 1, 1, 0]])\n",
    "P3=torch.tensor([[1, 0, 1, 1,   0, 0, 1, 1, 1]])\n",
    "P4=torch.tensor([[1, 0, 1, 1,   0, 0, 1, 1, 0]])\n",
    "P5=torch.tensor([[1, 0, 1, 1,   0, 0, 1, 1, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0b273b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = torch.mode(torch.cat((P1, P2, P3, P4, P5), dim=0), dim=0, keepdim=True)[0]\n",
    "cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a84857",
   "metadata": {},
   "outputs": [],
   "source": [
    "P1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3648bd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "P00=torch.tensor([1])\n",
    "torch.mode(P00)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8e1f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mode(P1)[0].view(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb03d95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "atnsr = torch.tensor((0, 0, 1, 1))\n",
    "xv, xc = torch.unique(atnsr, return_counts  = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5660613b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xc, xv[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87a2be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.any(torch.eq(xv, 1))\n",
    "xv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0965a4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "xc.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2646b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.argmax(torch.tensor([1000, 2000, 3000, float('NaN'), 5, 600]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4bdbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mode(torch.tensor([[5, 3, 3, float('NaN'),  float('NaN'), float('NaN'), float('NaN'), 0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cf87e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mode(torch.tensor([60, 60, 50, 50, 60]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d006eade",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(float('NaN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e58ca2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4454eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "xdvc = device\n",
    "def get_bin_tensor(xbatchclass):\n",
    "   \n",
    "    if torch.all(torch.isnan(xbatchclass))==True:\n",
    "            \n",
    "            return torch.tensor(float('NaN')).to(xdvc)\n",
    "        \n",
    "    else:\n",
    "\n",
    "        num_xbatchnanvalues = torch.isnan(xbatchclass).sum().item()\n",
    "        not_xbatchnanmask = torch.logical_not(torch.isnan(xbatchclass))\n",
    "        xbatchclass = xbatchclass[not_xbatchnanmask]\n",
    "\n",
    "        xclassVal_01, xclassCnt_01 =xbatchclass.unique(return_counts = True)\n",
    "\n",
    "        if xclassCnt_01.shape[0]==1:\n",
    "            return xclassVal_01[0].to(xdvc)\n",
    "\n",
    "\n",
    "        if xclassCnt_01.shape[0]==2:\n",
    "            if xclassCnt_01[0]!=xclassCnt_01[1]:\n",
    "                ''' xclassCnt_01 will always be two values converting [7, 8] to 1; [8, 7] to 0'''\n",
    "                return torch.argmax(xclassCnt_01).to(xdvc)  \n",
    "\n",
    "            else:\n",
    "                return torch.tensor(float('NaN')).to(xdvc)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e688520",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_bin_tensor(torch.tensor([float('NaN'), float('NaN'), float('NaN'), 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37fd369",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.argmax(torch.tensor([0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fc0b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "xclassVal_01, xclassCnt_01 =torch.tensor([0, 0, 0, 1]).unique(return_counts = True)\n",
    "xclassVal_01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2783b4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.argmax(xclassCnt_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a9658f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.argmax(torch.tensor([7, 8]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d657408e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_segclass(x_chlist):\n",
    "    \n",
    "    xclassNoList = list()\n",
    "    xvalueList = list()\n",
    "    \n",
    "    for x_i in x_chlist:\n",
    "    \n",
    "        xv, xc = torch.unique(x_i, return_counts  = True)\n",
    "\n",
    "        if xc.shape[0]==1:\n",
    "            if xv==0:\n",
    "                xclassNoList.append(-1)\n",
    "                xvalueList.append(xv[0].item())\n",
    "            elif xv==1:\n",
    "                xclassNoList.append(xc[0].item())\n",
    "                xvalueList.append(xv[0].item())\n",
    "            else:\n",
    "                print('The function only supports binarized tensor (binarized unique values, 0(n=...) and 1(n=...) only)\\n')\n",
    "                \n",
    "\n",
    "        elif xc.shape[0]==2:\n",
    "                if torch.any(torch.eq(xv, 1)):\n",
    "                    xclassNoList.append(xc[1].item())\n",
    "                    xvalueList.append(xv[1].item())\n",
    "                else:\n",
    "                    print('The function only supports binarized tensor (binarized unique values, 0(n=...) and 1(n=...) only)\\n')\n",
    "        else:\n",
    "            print('The function only supports binarized tensor (binarized unique values, 0(n=...) and 1(n=...) only)\\n')\n",
    "\n",
    "    #pdb.set_trace()\n",
    "    #if torch.any(torch.eq(torch.tensor(xvalueList), 1)):\n",
    "        \n",
    "    if xclassNoList[0]!=xclassNoList[1]: \n",
    "        xclass = torch.argmax(torch.tensor(xclassNoList).to(xdvc))\n",
    "    else:\n",
    "        xclass = torch.tensor(float('NaN')).to(xdvc)\n",
    "            \n",
    "    #else:\n",
    "        '''If all uniques class values are 0, we are assigning nan values as a class'''\n",
    "    #    xclass = torch.tensor(float('NaN')).to(xdvc)\n",
    "    \n",
    "    \n",
    "    return xclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936bd20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_segclass([torch.tensor([[1,1,1,1,1],[1,1,1,1,0]]), torch.tensor([[1,1,1,1,1], [1,1,1,1,0]])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35853df",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor([0, 0, 0, float('NaN'), 0]).unique(return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf8e69b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf05e529",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
